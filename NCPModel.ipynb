{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3842ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports:\n",
    "from ncps.wirings import AutoNCP\n",
    "from ncps.torch import CfC\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import matplotlib as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae4e3f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4957201, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\will\\AppData\\Local\\Temp\\ipykernel_23632\\2229332239.py:31: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  dataSet = torch.tensor(newData)\n"
     ]
    }
   ],
   "source": [
    "#PROPER FORMATTING\n",
    "#Time sequences are 10 timepoints (Messages) with 7 features per message.\n",
    "#Organized by car.\n",
    "\n",
    "#Current Simulation File\n",
    "dataFile = 'Data/CfCMultiExtension/DoS_0709.csv'\n",
    "\n",
    "dataSet = genfromtxt(dataFile, delimiter=',')\n",
    "batchSize = 64\n",
    "# Ceate dataloader and fill with (BSM, attk#). Expanding to add 0th dimension for batches.\n",
    "# Batch size should be 64 for the low density simulations and 128 for high density simulations.\n",
    "# No shuffle to keep batches on same vehicle.\n",
    "# Num_workers is set to = num CPU cores\n",
    "dataSet[0:-1,:] = dataSet[1:,:] # Get rid of the first null value of the dataset\n",
    "print(dataSet.shape)\n",
    "# count subsets per vehicle\n",
    "unq, counts = np.unique(dataSet[:, 2], return_counts = True)\n",
    "sender = 0\n",
    "lastSenderCount = 0\n",
    "newData = []\n",
    "# Organize dataset into sets of 10 messages by sender\n",
    "while sender < counts.shape[0]:\n",
    "    # Loop through sender\n",
    "    index = 0\n",
    "    while index < counts[sender] - 10:\n",
    "        # Loop through messages from sender\n",
    "        newData.append(dataSet[lastSenderCount+index:lastSenderCount +index+10])\n",
    "        index += 5\n",
    "    sender += 1\n",
    "    lastSenderCount = counts[sender-1]\n",
    "dataSet = torch.tensor(newData)\n",
    "len = dataSet.shape[0]\n",
    "trainPerc = 80\n",
    "# Create new arrays per vehicle for federated learning\n",
    "splits = np.split(dataSet, np.cumsum(counts)[:-1])\n",
    "# Create seperate datasets for testing and training, using Train Percentage as metric for split\n",
    "trainDataIn = torch.Tensor(dataSet[:int(len*(trainPerc/100)),:,1:10]).float()\n",
    "trainDataOut = torch.Tensor(np.int_(dataSet[:int(len*(trainPerc/100)),:,11])).long()\n",
    "testDataIn = torch.Tensor(dataSet[int(len*(trainPerc/100)):,:,1:10]).float()\n",
    "testDataOut = torch.Tensor(np.int_(dataSet[int(len*(trainPerc/100)):,:,11])).long()\n",
    "newsetIn = []\n",
    "newsetOut = []\n",
    "# Create dataset of 1/100th of the entries for quicker testing during development\n",
    "for index in range(0,int(len * (trainPerc/100))):\n",
    "    if not (int(index/10) % 100):\n",
    "        newsetIn.append(dataSet[index,:,1:10])\n",
    "        newsetOut.append((dataSet[index,:,11]))\n",
    "testingIn = torch.Tensor(np.array(newsetIn)).float()\n",
    "testingOut = torch.Tensor(np.array(newsetOut)).long()\n",
    "# Create Dataloaders for all the datasets\n",
    "dataLoaderTrain = data.DataLoader(data.TensorDataset(trainDataIn, trainDataOut), batch_size=batchSize, shuffle=False, num_workers=16)\n",
    "dataLoaderTest = data.DataLoader(data.TensorDataset(testDataIn, testDataOut), batch_size=batchSize, shuffle=False, num_workers=16)\n",
    "testingDataLoader = data.DataLoader(data.TensorDataset(testingIn, testingOut), batch_size=batchSize, shuffle = False, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f9ff02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([786645, 10, 9])\n",
      "torch.Size([786645, 10])\n",
      "torch.Size([7870, 10])\n",
      "torch.Size([7870, 10, 9])\n",
      "tensor([[9.3000e+01, 3.3000e+01, 2.5286e+04, 1.3507e+01, 1.0802e+01, 3.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.3000e+01, 3.3000e+01, 2.5286e+04, 1.3507e+01, 1.0802e+01, 4.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.3000e+01, 3.3000e+01, 2.5286e+04, 1.3327e+01, 1.0667e+01, 1.0000e+00,\n",
      "         8.6027e+00, 6.3077e+00, 4.3233e-01],\n",
      "        [9.3000e+01, 3.3000e+01, 2.5286e+04, 1.3327e+01, 1.0667e+01, 2.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.3000e+01, 3.3000e+01, 2.5287e+04, 1.3327e+01, 1.0667e+01, 3.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.3000e+01, 3.3000e+01, 2.5287e+04, 1.3327e+01, 1.0667e+01, 4.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.3000e+01, 3.3000e+01, 2.5287e+04, 1.3129e+01, 1.0573e+01, 1.0000e+00,\n",
      "         8.3659e+00, 6.2256e+00, 4.4146e-01],\n",
      "        [9.3000e+01, 3.3000e+01, 2.5287e+04, 1.3129e+01, 1.0573e+01, 2.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.3000e+01, 3.3000e+01, 2.5288e+04, 1.3129e+01, 1.0573e+01, 3.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.3000e+01, 3.3000e+01, 2.5288e+04, 1.3129e+01, 1.0573e+01, 4.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([[9.9000e+01, 3.3000e+01, 2.5299e+04, 1.3470e+01, 9.1235e+00, 4.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.3000e+01, 3.3000e+01, 2.5299e+04, 7.8105e+01, 1.1339e+02, 4.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.9000e+01, 3.3000e+01, 2.5299e+04, 4.6946e+00, 1.0422e+01, 1.0000e+00,\n",
      "         9.2007e+00, 1.0020e+01, 1.3499e-01],\n",
      "        [9.3000e+01, 3.3000e+01, 2.5299e+04, 9.1457e+01, 1.3268e+02, 1.0000e+00,\n",
      "         9.2007e+00, 1.0020e+01, 1.3499e-01],\n",
      "        [9.9000e+01, 3.3000e+01, 2.5299e+04, 4.6946e+00, 1.0422e+01, 2.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.3000e+01, 3.3000e+01, 2.5299e+04, 9.1457e+01, 1.3268e+02, 2.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.9000e+01, 3.3000e+01, 2.5300e+04, 4.6946e+00, 1.0422e+01, 3.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.3000e+01, 3.3000e+01, 2.5300e+04, 9.1457e+01, 1.3268e+02, 3.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.9000e+01, 3.3000e+01, 2.5300e+04, 4.6946e+00, 1.0422e+01, 4.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.3000e+01, 3.3000e+01, 2.5300e+04, 9.1457e+01, 1.3268e+02, 4.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([[[0.0000e+00, 4.5000e+01, 9.0000e+00, 2.5213e+04, 7.9360e+00,\n",
      "          9.5710e+01, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 4.5000e+01, 9.0000e+00, 2.5214e+04, 1.3297e+01,\n",
      "          1.0641e+02, 1.0000e+00, 2.2829e+00, 1.4343e+01, 2.6653e-01,\n",
      "          5.1515e-01, 0.0000e+00],\n",
      "         [2.0000e+00, 4.5000e+01, 9.0000e+00, 2.5215e+04, 1.5193e+01,\n",
      "          1.1516e+02, 1.0000e+00, 2.4971e+00, 1.4267e+01, 2.8239e-01,\n",
      "          2.7008e-01, 0.0000e+00],\n",
      "         [3.0000e+00, 4.5000e+01, 9.0000e+00, 2.5216e+04, 1.9588e+01,\n",
      "          1.2151e+02, 1.0000e+00, 2.3272e+00, 1.4307e+01, 2.2484e-03,\n",
      "          1.4123e-02, 0.0000e+00],\n",
      "         [4.0000e+00, 4.5000e+01, 9.0000e+00, 2.5217e+04, 2.0326e+01,\n",
      "          1.2625e+02, 1.0000e+00, 2.1510e+00, 1.4311e+01, 3.1886e-01,\n",
      "          2.6335e-01, 0.0000e+00],\n",
      "         [5.0000e+00, 4.5000e+01, 9.0000e+00, 2.5218e+04, 2.0655e+01,\n",
      "          1.2887e+02, 1.0000e+00, 1.8844e+00, 1.4323e+01, 3.0988e-02,\n",
      "          6.9574e-03, 0.0000e+00],\n",
      "         [6.0000e+00, 4.5000e+01, 9.0000e+00, 2.5219e+04, 2.0326e+01,\n",
      "          1.2965e+02, 1.0000e+00, 1.9998e+00, 1.4353e+01, 1.2554e-02,\n",
      "          5.4131e-02, 0.0000e+00],\n",
      "         [7.0000e+00, 4.5000e+01, 9.0000e+00, 2.5220e+04, 2.0429e+01,\n",
      "          1.2980e+02, 1.0000e+00, 2.1801e+00, 1.4353e+01, 7.1656e-02,\n",
      "          1.8487e-01, 0.0000e+00],\n",
      "         [8.0000e+00, 4.5000e+01, 9.0000e+00, 2.5221e+04, 2.0443e+01,\n",
      "          1.2995e+02, 1.0000e+00, 2.2483e+00, 1.4336e+01, 1.7053e-02,\n",
      "          1.1341e-01, 0.0000e+00],\n",
      "         [9.0000e+00, 4.5000e+01, 9.0000e+00, 2.5222e+04, 2.0162e+01,\n",
      "          1.3008e+02, 1.0000e+00, 2.2358e+00, 1.4346e+01, 5.3708e-03,\n",
      "          3.5717e-02, 0.0000e+00]],\n",
      "\n",
      "        [[5.0000e+00, 4.5000e+01, 9.0000e+00, 2.5218e+04, 2.0655e+01,\n",
      "          1.2887e+02, 1.0000e+00, 1.8844e+00, 1.4323e+01, 3.0988e-02,\n",
      "          6.9574e-03, 0.0000e+00],\n",
      "         [6.0000e+00, 4.5000e+01, 9.0000e+00, 2.5219e+04, 2.0326e+01,\n",
      "          1.2965e+02, 1.0000e+00, 1.9998e+00, 1.4353e+01, 1.2554e-02,\n",
      "          5.4131e-02, 0.0000e+00],\n",
      "         [7.0000e+00, 4.5000e+01, 9.0000e+00, 2.5220e+04, 2.0429e+01,\n",
      "          1.2980e+02, 1.0000e+00, 2.1801e+00, 1.4353e+01, 7.1656e-02,\n",
      "          1.8487e-01, 0.0000e+00],\n",
      "         [8.0000e+00, 4.5000e+01, 9.0000e+00, 2.5221e+04, 2.0443e+01,\n",
      "          1.2995e+02, 1.0000e+00, 2.2483e+00, 1.4336e+01, 1.7053e-02,\n",
      "          1.1341e-01, 0.0000e+00],\n",
      "         [9.0000e+00, 4.5000e+01, 9.0000e+00, 2.5222e+04, 2.0162e+01,\n",
      "          1.3008e+02, 1.0000e+00, 2.2358e+00, 1.4346e+01, 5.3708e-03,\n",
      "          3.5717e-02, 0.0000e+00],\n",
      "         [1.0000e+01, 4.5000e+01, 9.0000e+00, 2.5223e+04, 1.9765e+01,\n",
      "          1.3024e+02, 1.0000e+00, 2.1286e+00, 1.4368e+01, 6.9520e-02,\n",
      "          4.6442e-01, 0.0000e+00],\n",
      "         [1.1000e+01, 4.5000e+01, 9.0000e+00, 2.5224e+04, 1.9720e+01,\n",
      "          1.3040e+02, 1.0000e+00, 2.4351e+00, 1.4294e+01, 8.0537e-02,\n",
      "          5.3559e-01, 0.0000e+00],\n",
      "         [1.2000e+01, 6.3000e+01, 9.0000e+00, 2.5224e+04, 3.3856e+01,\n",
      "          2.6880e+02, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.3000e+01, 4.5000e+01, 9.0000e+00, 2.5225e+04, 1.9400e+01,\n",
      "          1.3053e+02, 1.0000e+00, 2.1025e+00, 1.4369e+01, 3.2794e-02,\n",
      "          2.1779e-01, 0.0000e+00],\n",
      "         [1.4000e+01, 6.3000e+01, 9.0000e+00, 2.5225e+04, 3.5817e+01,\n",
      "          2.8188e+02, 1.0000e+00, 2.1025e+00, 1.4369e+01, 3.2794e-02,\n",
      "          2.1779e-01, 0.0000e+00]]], dtype=torch.float64)\n",
      "torch.Size([10, 12])\n"
     ]
    }
   ],
   "source": [
    "print(trainDataIn.shape)\n",
    "print(trainDataOut.shape)\n",
    "print(testingOut.shape)\n",
    "print(testingIn.shape)\n",
    "print(trainDataIn[-1])\n",
    "print(trainDataOut[1])\n",
    "print(testDataIn[15])\n",
    "print(testingOut[0])\n",
    "print(dataSet[0:2])\n",
    "print(dataSet[90].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f4ff8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Learner\n",
    "class CfCLearner(pl.LightningModule):\n",
    "    def __init__(self, model, lr):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.lossFunc = nn.CrossEntropyLoss()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Get in and out from batch\n",
    "        inputs, target = batch\n",
    "        # Put input through model\n",
    "        output, _ = self.model.forward(inputs)\n",
    "        # Reorganize inputs for use with loss function\n",
    "        output = output.permute(0, 2, 1)\n",
    "        # Calculate Loss using Cross Entropy Loss \n",
    "        loss = self.lossFunc(output, target)\n",
    "        self.log(\"trainLoss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Get in and out from batch\n",
    "        inputs, target = batch\n",
    "        # Put input through model\n",
    "        output, _ = self.model.forward(inputs)\n",
    "        # Reorganize inputs for use with loss function\n",
    "        output = output.permute(0, 2, 1)\n",
    "        print(f\"output: {output.shape}\")\n",
    "        print(f\"target: {target.shape}\")\n",
    "        # Calculate Loss using Cross Entropy Loss \n",
    "        loss = self.lossFunc(output, target)\n",
    "        self.log(\"valLoss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.validation_step(batch, batch_idx)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Using AdamW optomizer based on info from paper\n",
    "        return torch.optim.AdamW(self.model.parameters(), lr = self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28b52804",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modena(nn.Module): \n",
    "    # CfC with feed-forward layer to classify at end.\n",
    "    def __init__(self, inputSize, unitNum, motorNum, outputDim, batchFirst = True):\n",
    "        super().__init__()\n",
    "        # Create NCP wiring for CfC\n",
    "        wiring = AutoNCP(unitNum, motorNum)\n",
    "        # Create CfC model with inputs and wiring\n",
    "        self.cfc = CfC(inputSize, wiring, batch_first=batchFirst)\n",
    "        # Create feed-forward layer\n",
    "        self.fF = nn.Linear(motorNum, outputDim)\n",
    "    \n",
    "    def forward(self, batch, hidden = None):\n",
    "        batch, hidden = self.cfc(batch, hidden) # Pass inputs through CfC\n",
    "        out = nn.functional.relu(self.fF(batch)) # pass through FeedForward Layer, then make 0 minimum\n",
    "        return out, hidden # Return the guess and the hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecad7b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBU module class to organize\n",
    "class OBU():\n",
    "    def __init__(self, inputSize = 9, units = 20, motors = 8, outputs = 20, epochs = 10, lr = 0.001, gpu = False):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.gpu = gpu\n",
    "        self.model = Modena(inputSize, units, motors, outputs)\n",
    "        self.learner = CfCLearner(self.model, lr) # tune units, lr\n",
    "        self.trainer = pl.Trainer(\n",
    "            logger = CSVLogger('log'), # Set ouput destination of logs, logging accuracy every 50 steps\n",
    "            max_epochs = epochs, # Number of epochs to train for\n",
    "            gradient_clip_val = 1, # This is said to stabilize training, but we should test if that is true\n",
    "            accelerator = \"gpu\" if gpu else \"cpu\" # Using the GPU to run training or not\n",
    "            )\n",
    "    \n",
    "    def fit(self, dataLoader):\n",
    "        # calling built in fit function\n",
    "        return self.trainer.fit(self.learner, dataLoader)\n",
    "    \n",
    "    # Function to run model through a testing dataset and calculate accuracy. Can be expanded to give more metrics and more useful metrics.\n",
    "    def test(self, dataIn, dataOut):\n",
    "        # Put input data through model and determine classification\n",
    "        with torch.no_grad():\n",
    "            outs = np.asarray(self.model(dataIn)[0])\n",
    "        outs = torch.from_numpy(outs)\n",
    "        # Get the label with the maximum confidence for determining classification\n",
    "        print(outs.shape)\n",
    "        _, res = torch.max(outs, 2)\n",
    "        countR = 0\n",
    "        numZero = 0\n",
    "        tot = outs.shape[0]\n",
    "        total = 0\n",
    "        for i in range(0, tot):\n",
    "            # Loop through sequences of 10 each\n",
    "            for t in range(0, res[i].shape[0]):\n",
    "                # Loop through the sub-sequences\n",
    "                if res[i,t] == dataOut[i,t]:\n",
    "                    # Check if label is correct, and add to count right accordingly\n",
    "                    countR += 1\n",
    "                if dataOut[i,t] == 0:\n",
    "                    # If the label is zero, increment the count of zeroes to determine if model is just outputting zeroes\n",
    "                    numZero += 1\n",
    "                total += 1\n",
    "        # Calculate percent correct and percent zero\n",
    "        perc = (countR/total) * 100\n",
    "        percZero = (numZero/total) * 100\n",
    "        print(\"Model got \" + str(countR) + \"/\" + str(total) + \" right. Accuracy of \" + str(perc) + \"%\")\n",
    "        print(str(percZero) + \"% Zeroes.\")\n",
    "        return countR, total, perc, percZero\n",
    "    \n",
    "    def testStep(self, dataLoader):\n",
    "        self.learner.validation_step(next(iter(dataLoader)), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f62e03e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "testOBU = OBU(\n",
    "    inputSize = 9,  # Number of features per BSM\n",
    "    units = 20, # Number of hidden cells\n",
    "    motors = 8, # Number of motor neurons\n",
    "    outputs = 20, # Number of possible labels\n",
    "    epochs = 100,\n",
    "    lr = 0.001,\n",
    "    gpu = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56f72121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: torch.Size([64, 20, 10])\n",
      "target: torch.Size([64, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\will\\miniconda3\\envs\\Kettering\\Lib\\site-packages\\pytorch_lightning\\core\\module.py:441: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n"
     ]
    }
   ],
   "source": [
    "testOBU.testStep(dataLoaderTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b50140ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Training:\n",
      "torch.Size([196662, 10, 20])\n",
      "Model got 0/1966620 right. Accuracy of 0.0%\n",
      "39.65916140382993% Zeroes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 1966620, 0.0, 39.65916140382993)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Before Training:\")\n",
    "testOBU.test(testDataIn, testDataOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e231a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\will\\miniconda3\\envs\\Kettering\\Lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.7 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.4 K     Trainable params\n",
      "280       Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\will\\miniconda3\\envs\\Kettering\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 123/123 [00:22<00:00,  5.40it/s, v_num=231, trainLoss=0.675]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 123/123 [00:22<00:00,  5.39it/s, v_num=231, trainLoss=0.675]\n"
     ]
    }
   ],
   "source": [
    "testOBU.fit(testingDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ba8da65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Training:\n",
      "torch.Size([196662, 10, 20])\n",
      "Model got 1186675/1966620 right. Accuracy of 60.34083859617007%\n",
      "39.65916140382993% Zeroes.\n"
     ]
    }
   ],
   "source": [
    "print(\"After Training:\")\n",
    "countR, tot, perc, percZero = testOBU.test(testDataIn, testDataOut)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kettering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
