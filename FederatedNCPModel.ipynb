{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a997a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from ncps.wirings import AutoNCP\n",
    "from ncps.torch import CfC\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from random import sample\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import sys\n",
    "import json\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "batchSize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed3cc2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4079/3986530002.py:22: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  subData = torch.Tensor(subData)\n"
     ]
    }
   ],
   "source": [
    "# FORMATTING DATASET FOR FED. LEARNING\n",
    "dataFile = 'Data/CfCMultiExtension/ConstPos_0709.csv'\n",
    "dataSet = genfromtxt(dataFile, delimiter=',')\n",
    "dataSet = np.delete(dataSet, 0, axis=0) # Remove the labels at the beginning of the dataset\n",
    "\n",
    "# Devide dataset into reciever groups\n",
    "fedDataSet = dataSet[np.argsort(dataSet[:, 1])] # Sort dataset by reciver ID\n",
    "_, counts = np.unique(fedDataSet[:,1], return_counts=True) # Get the indexes of the change in datasets.\n",
    "sum = 0\n",
    "for i in range(len(counts)): # Accumulating counts so that we can use them as indexes\n",
    "    sum += counts[i]\n",
    "    counts[i] = sum\n",
    "fedDataSet = np.split(fedDataSet, counts) # Split larger dataset into per vehicle datasets.\n",
    "\n",
    "newData = [] \n",
    "for reciever in fedDataSet: # Go through all vehicle datasets\n",
    "    subData = []\n",
    "    index = 0\n",
    "    while index < len(reciever) - 10: # organize the new dataset as a list of chuncks of 10 messages \n",
    "        subData.append(reciever[index:index+10])\n",
    "        index += 5\n",
    "    subData = torch.Tensor(subData)\n",
    "    if subData.shape[0] != 0:\n",
    "        newData.append(subData) # Create tensor from per vehicle dataset and add to list of datas.\n",
    "fedDataSet = newData\n",
    "# Final output of this cell is fedDataSet, a list of the datasets of each vehicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1794295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([56, 10, 12])\n"
     ]
    }
   ],
   "source": [
    "print(fedDataSet[25].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2491f35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# #Current Simulation File\\ndataFile = 'Data/CfCMultiExtension/RandomPos_0709.csv'\\n\\ndataSet = genfromtxt(dataFile, delimiter=',')\\n\\nbatchSize = 64\\n# Ceate dataloader and fill with (BSM, attk#). Expanding to add 0th dimension for batches.\\n# Batch size should be 64 for the low density simulations and 128 for high density simulations.\\n# No shuffle to keep batches on same vehicle.\\n# Num_workers is set to = num CPU cores\\ndataSet[0:-1,:] = dataSet[1:,:] # Get rid of the first null value of the dataset\\n# Sort Dataset by reciever id to pass on to every car.\\ndataSet = dataSet[np.argsort(dataSet[:, 1])]\\nprint(dataSet.shape)\\n# count subsets per vehicle\\nprint(dataSet[0])\\nunq, counts = np.unique(dataSet[:, 1], return_counts = True)\\nrecvr = 0\\nlastRecieverCount = 0\\nnewData = []\\nprint(counts)\\n# Organize dataset into sets of 10 messages by reciever\\nwhile recvr < counts.shape[0]:\\n    # Loop through reciever\\n    index = 0\\n    while index < counts[recvr] - 10:\\n        # Loop through messages from reciever\\n        newData.append(dataSet[lastRecieverCount+index:lastRecieverCount +index+10])\\n        index += 5\\n    recvr += 1\\n    lastRecieverCount = counts[recvr-1]\\ndataSet = torch.tensor(newData)\\nprint(dataSet.shape)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ***** DEPRECATED *****\n",
    "'''\n",
    "# #Current Simulation File\n",
    "dataFile = 'Data/CfCMultiExtension/RandomPos_0709.csv'\n",
    "\n",
    "dataSet = genfromtxt(dataFile, delimiter=',')\n",
    "\n",
    "batchSize = 64\n",
    "# Ceate dataloader and fill with (BSM, attk#). Expanding to add 0th dimension for batches.\n",
    "# Batch size should be 64 for the low density simulations and 128 for high density simulations.\n",
    "# No shuffle to keep batches on same vehicle.\n",
    "# Num_workers is set to = num CPU cores\n",
    "dataSet[0:-1,:] = dataSet[1:,:] # Get rid of the first null value of the dataset\n",
    "# Sort Dataset by reciever id to pass on to every car.\n",
    "dataSet = dataSet[np.argsort(dataSet[:, 1])]\n",
    "print(dataSet.shape)\n",
    "# count subsets per vehicle\n",
    "print(dataSet[0])\n",
    "unq, counts = np.unique(dataSet[:, 1], return_counts = True)\n",
    "recvr = 0\n",
    "lastRecieverCount = 0\n",
    "newData = []\n",
    "print(counts)\n",
    "# Organize dataset into sets of 10 messages by reciever\n",
    "while recvr < counts.shape[0]:\n",
    "    # Loop through reciever\n",
    "    index = 0\n",
    "    while index < counts[recvr] - 10:\n",
    "        # Loop through messages from reciever\n",
    "        newData.append(dataSet[lastRecieverCount+index:lastRecieverCount +index+10])\n",
    "        index += 5\n",
    "    recvr += 1\n",
    "    lastRecieverCount = counts[recvr-1]\n",
    "dataSet = torch.tensor(newData)\n",
    "print(dataSet.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65c814c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROPER FORMATTING FOR TESTING DATASETS\n",
    "#Time sequences are 10 timepoints (Messages) with 7 features per message.\n",
    "#Organized by car.\n",
    "unq, counts = np.unique(dataSet[:, 2], return_counts = True)\n",
    "sender = 0\n",
    "lastSenderCount = 0\n",
    "newData = []\n",
    "# Organize dataset into sets of 10 messages by sender\n",
    "while sender < counts.shape[0]:\n",
    "    # Loop through sender\n",
    "    index = 0\n",
    "    while index < counts[sender] - 10:\n",
    "        # Loop through messages from sender\n",
    "        newData.append(dataSet[lastSenderCount+index:lastSenderCount +index+10])\n",
    "        index += 5\n",
    "    sender += 1\n",
    "    lastSenderCount += counts[sender-1]\n",
    "dataSet = torch.tensor(newData)\n",
    "leng = dataSet.shape[0]\n",
    "trainPerc = 80\n",
    "# Create seperate datasets for testing and training, using Train Percentage as metric for split\n",
    "trainDataIn = torch.Tensor(dataSet[:int(leng*(trainPerc/100)),:,3:10]).float()\n",
    "trainDataOut = torch.Tensor(np.int_(dataSet[:int(leng*(trainPerc/100)),:,11])).long()\n",
    "testDataIn = torch.Tensor(dataSet[int(leng*(trainPerc/100)):,:,3:10]).float()\n",
    "testDataOut = torch.Tensor(np.int_(dataSet[int(leng*(trainPerc/100)):,:,11])).long()\n",
    "newsetIn = []\n",
    "newsetOut = []\n",
    "testsetIn = []\n",
    "testsetOut = []\n",
    "tinyTestIn = []\n",
    "tinyTestOut = []\n",
    "# Create tiny dataset to run verification tests\n",
    "for index in range(leng):\n",
    "    if not (int(index/10) % 300):\n",
    "        tinyTestIn.append(dataSet[index, :, 3:10])\n",
    "        tinyTestOut.append(dataSet[index, :, 11])\n",
    "# Create dataset of 1/100th of the entries for quicker testing during development\n",
    "for index in range(0,int((leng) * (trainPerc/100))):\n",
    "    if not (int(index/10) % 100):\n",
    "        newsetIn.append(dataSet[index,:,3:10])\n",
    "        newsetOut.append((dataSet[index,:,11]))\n",
    "for idx in range(int((leng) * (trainPerc/100)), leng):\n",
    "    if not (int(idx/10) % 10):\n",
    "        testsetIn.append(dataSet[idx,:,3:10])\n",
    "        testsetOut.append((dataSet[idx,:,11]))\n",
    "testingIn = torch.Tensor(np.array(newsetIn)).float()\n",
    "testingOut = torch.Tensor(np.array(newsetOut)).long()\n",
    "inTest = torch.Tensor(np.array(testsetIn)).float()\n",
    "outTest = torch.Tensor(np.array(testsetOut)).long()\n",
    "tinyTestIn = torch.Tensor(np.array(tinyTestIn)).float()\n",
    "tinyTestOut = torch.Tensor(np.array(tinyTestOut)).long()\n",
    "# Create Dataloaders for all the datasets\n",
    "dataLoaderTrain = data.DataLoader(data.TensorDataset(trainDataIn, trainDataOut), batch_size=batchSize, shuffle=False, num_workers=10, persistent_workers = True, drop_last= True)\n",
    "dataLoaderTest = data.DataLoader(data.TensorDataset(testDataIn, testDataOut), batch_size=batchSize, shuffle=False, num_workers=10, persistent_workers = True, drop_last= True)\n",
    "testingDataLoader = data.DataLoader(data.TensorDataset(testingIn, testingOut), batch_size=batchSize, shuffle = False, num_workers=10, persistent_workers = True, drop_last= True)\n",
    "testingTestData = data.DataLoader(data.TensorDataset(testingIn, testingOut), batch_size=batchSize, shuffle = False, num_workers=10, persistent_workers = True, drop_last= True)\n",
    "tinyTestLoader = data.DataLoader(data.TensorDataset(tinyTestIn, tinyTestOut), batch_size=batchSize, shuffle = False, num_workers = 10, persistent_workers= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b89ce159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73892.59168102387\n"
     ]
    }
   ],
   "source": [
    "tom = []\n",
    "for ted in fedDataSet:\n",
    "    tom.append(ted.nbytes)\n",
    "print(np.average(tom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b158270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12480, 10, 7])\n",
      "torch.Size([12480, 10])\n",
      "\n",
      "torch.Size([2080, 10, 7])\n"
     ]
    }
   ],
   "source": [
    "# TESTS\n",
    "print(inTest.shape)\n",
    "print(outTest.shape)\n",
    "print()\n",
    "print(tinyTestIn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1da521c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4]\n",
      " [9 8 7 6]\n",
      " [5 7 8 3]\n",
      " [9 8 7 3]]\n",
      "[[1 2 3 4]\n",
      " [5 7 8 3]\n",
      " [9 8 7 6]\n",
      " [9 8 7 3]]\n"
     ]
    }
   ],
   "source": [
    "#TESTING\n",
    "tom = np.array([[1,2,3,4],[9,8,7,6],[5,7,8,3],[9,8,7,3]])\n",
    "print(tom)\n",
    "tom = tom[np.argsort(tom[:, 1])]\n",
    "print(tom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01abeb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Learner\n",
    "class CfCLearner(pl.LightningModule):\n",
    "    def __init__(self, model, lr):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.lossFunc = nn.CrossEntropyLoss()\n",
    "        self.loss = None\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Get in and out from batch\n",
    "        inputs, target = batch\n",
    "        # Put input through model\n",
    "        output, _ = self.model.forward(inputs)\n",
    "        # Reorganize inputs for use with loss function\n",
    "        output = output.permute(0, 2, 1)\n",
    "        # Calculate Loss using Cross Entropy Loss \n",
    "        loss = self.lossFunc(output, target)\n",
    "        self.log(\"trainLoss\", loss, prog_bar=True)\n",
    "        self.loss = loss\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Get in and out from batch\n",
    "        inputs, target = batch\n",
    "        # Put input through model\n",
    "        output, _ = self.model.forward(inputs)\n",
    "        # Reorganize inputs for use with loss function\n",
    "        output = output.permute(0, 2, 1)\n",
    "        print(f\"output: {output.shape}\")\n",
    "        print(f\"target: {target.shape}\")\n",
    "        # Calculate Loss using Cross Entropy Loss \n",
    "        loss = self.lossFunc(output, target)\n",
    "        self.log(\"valLoss\", loss, prog_bar=True)\n",
    "        self.loss = loss\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.validation_step(batch, batch_idx)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Using AdamW optomizer based on info from paper\n",
    "        # optimizer = torch.optim.AdamW(self.model.parameters(), lr = 0.001)\n",
    "        # return ([optimizer], [torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.6)])\n",
    "        return torch.optim.AdamW(self.model.parameters(), lr = 0.01) # TESTING REMOVING THE SCHEDULER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb6cf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Model/Module\n",
    "class Modena(nn.Module): \n",
    "    # CfC with feed-forward layer to classify at end.\n",
    "    def __init__(self, inputSize, unitNum = None, motorNum = 2, outputDim = 2, batchFirst = True):\n",
    "        super().__init__()\n",
    "        #Allow for creation of a copy of another instance\n",
    "        if isinstance(inputSize, Modena):\n",
    "            self.inputSize = inputSize.inputSize\n",
    "            self.unitNum = inputSize.unitNum\n",
    "            self.motorNum = inputSize.motorNum\n",
    "            self.outputDim = inputSize.outputDim\n",
    "            self.batchFirst = inputSize.batchFirst\n",
    "            # Create NCP wiring for CfC\n",
    "            wiring = AutoNCP(self.unitNum, self.motorNum)\n",
    "            # Create CfC model with inputs and wiring\n",
    "            self.cfc = CfC(self.inputSize, wiring, batch_first=self.batchFirst)\n",
    "            # Create feed-forward layer\n",
    "            self.fF = nn.Linear(self.motorNum, self.outputDim)\n",
    "            self.fF.weight = nn.Parameter(inputSize.fF.weight)\n",
    "        else:\n",
    "            self.inputSize = inputSize\n",
    "            self.unitNum = unitNum\n",
    "            self.motorNum = motorNum\n",
    "            self.outputDim = outputDim\n",
    "            self.batchFirst = batchFirst\n",
    "            # Create NCP wiring for CfC\n",
    "            wiring = AutoNCP(unitNum, motorNum)\n",
    "            # Create CfC model with inputs and wiring\n",
    "            self.cfc = CfC(inputSize, wiring, batch_first=batchFirst)\n",
    "            # Create feed-forward layer\n",
    "            self.fF = nn.Linear(motorNum, outputDim)\n",
    "        \n",
    "\n",
    "    def forward(self, batch, hidden = None):\n",
    "        batch, hidden = self.cfc(batch, hidden) # Pass inputs through CfC\n",
    "        out = nn.functional.relu(self.fF(batch)) # pass through FeedForward Layer, then make 0 minimum\n",
    "        return out, hidden # Return the guess and the hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5406ad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating overall model Class\n",
    "class OBU():\n",
    "    def __init__(self, inputSize, units = 20, motors = 8, outputs = 20, epochs = 10, lr = 0.01, randInt = 0, gpu = False, dataset = None, evil = False):\n",
    "        if isinstance(inputSize, OBU):\n",
    "            self.lr = inputSize.lr\n",
    "            self.epochs = inputSize.epochs\n",
    "            self.gpu = inputSize.gpu\n",
    "            self.model = Modena(inputSize.model)\n",
    "            self.model.load_state_dict(inputSize.model.state_dict())\n",
    "            self.learner = CfCLearner(self.model, self.lr)\n",
    "            self.learner.load_state_dict(inputSize.learner.state_dict())\n",
    "            self.trainer = pl.Trainer(\n",
    "                logger = CSVLogger('log/Fed'), # Set ouput destination of logs, logging accuracy every 50 steps\n",
    "                max_epochs = self.epochs, # Number of epochs to train for\n",
    "                gradient_clip_val = 1, # This is said to stabilize training, but we should test if that is true\n",
    "                accelerator = \"gpu\" if self.gpu else \"cpu\" # Using the GPU to run training or not\n",
    "                )\n",
    "\n",
    "        else:\n",
    "            self.lr = lr\n",
    "            self.epochs = epochs\n",
    "            self.gpu = gpu\n",
    "            self.model = Modena(inputSize, units, motors, outputs)\n",
    "            self.learner = CfCLearner(self.model, lr) # tune units, lr\n",
    "            self.trainer = pl.Trainer(\n",
    "                logger = CSVLogger('log/Fed'), # Set ouput destination of logs, logging accuracy every 50 steps\n",
    "                max_epochs = epochs, # Number of epochs to train for\n",
    "                gradient_clip_val = 1, # This is said to stabilize training, but we should test if that is true\n",
    "                accelerator = \"gpu\" if gpu else \"cpu\" # Using the GPU to run training or not\n",
    "                )\n",
    "        # Creating variables needed for DeFL\n",
    "        self.prevAccuracy = 0\n",
    "        self.evil = evil\n",
    "        self.nearbyOBUs = []\n",
    "        self.id = None\n",
    "        self.dataset = dataset\n",
    "        self.outnum = 0\n",
    "        self.confidences = []\n",
    "        self.samplingWeights = []\n",
    "        self.priority = 0\n",
    "        self.datalen = 0\n",
    "        self.otherPriorities = []\n",
    "        self.sampling = []\n",
    "        self.curr_loss = 0\n",
    "        self.prev_loss = None\n",
    "        self.trust_loss = 0\n",
    "        self.curr_acc = 0\n",
    "        self.prev_acc = None\n",
    "        self.trust_acc = 0\n",
    "        self.backupWeights = self.learner.state_dict()\n",
    "        self.prevWeights = dict(self.learner.state_dict())\n",
    "        self.goodNeighbors = []\n",
    "        self.testing = True\n",
    "        self.toTest = []\n",
    "        self.perEpoch = 30\n",
    "        self.rounds = 0\n",
    "        self.curr_f1 = 0\n",
    "        self.prev_f1 = None\n",
    "    \n",
    "\n",
    "    # Overloading add function to create fed.avg. model\n",
    "    def __add__(self, other):\n",
    "        self.learner.load_state_dict(dict( (n, self.learner.state_dict().get(n, 0)+other.learner.state_dict().get(n, 0)) for n in set(self.learner.state_dict())|set(other.learner.state_dict()) ))\n",
    "        return self\n",
    "    \n",
    "    # Overloading multiplication function to add weights\n",
    "    def __mul__(self, i):\n",
    "        self.learner.load_state_dict(dict((n, self.learner.state_dict().get(n, 0)*i) for n in self.learner.state_dict()))\n",
    "        return self\n",
    "\n",
    "    # Overloading div. function to average model\n",
    "    def __truediv__(self, i):\n",
    "        self.learner.load_state_dict(dict((n, self.learner.state_dict().get(n, 0)/i) for n in self.learner.state_dict()))\n",
    "        return self\n",
    "    \n",
    "    def fit(self, dataLoader):\n",
    "        # calling built in fit function\n",
    "        self.trainer.fit(self.learner, dataLoader) \n",
    "        return self.learner.loss\n",
    "    \n",
    "    # Function to run model through a testing dataset and calculate accuracy. Can be expanded to give more metrics and more useful metrics.\n",
    "    def test(self, dataIn, dataOut, mathy = False):\n",
    "        # Put input data through model and determine classification\n",
    "        with torch.no_grad():\n",
    "            outs = np.asarray(self.model(dataIn)[0])\n",
    "        outs = torch.from_numpy(outs)\n",
    "        # Get the label with the maximum confidence for determining classification\n",
    "        print(outs.shape)\n",
    "        _, res = torch.max(outs, 2)\n",
    "        Pt = Pf = Nt = Nf = 0\n",
    "        countR = 0\n",
    "        numZero = 0\n",
    "        tot = outs.shape[0]\n",
    "        total = 0\n",
    "        for i in range(0, tot):\n",
    "            # Loop through sequences of 10 each\n",
    "            for t in range(0, res[i].shape[0]):\n",
    "                # Loop through the sub-sequences\n",
    "                if res[i,t] == dataOut[i,t]:\n",
    "                    if res[i,t] == 0:\n",
    "                        Nt += 1\n",
    "                        numZero += 1\n",
    "                    else:\n",
    "                        Pt += 1\n",
    "                    # Check if label is correct, and add to count right accordingly\n",
    "                    countR += 1\n",
    "                else:\n",
    "                    if dataOut[i,t] == 0:\n",
    "                        Pf += 1\n",
    "                        numZero += 1\n",
    "                    else:\n",
    "                        Nf += 1\n",
    "                total += 1\n",
    "        # Mathy determines if we want the program to output just the numbers or a string for easy readability\n",
    "        if mathy:\n",
    "            # If we have at least one true positive, we can do all the other calculations.\n",
    "            if Pt != 0:\n",
    "                # Calculate accuracy, precision, recall and f1.\n",
    "                accuracy = (Pt+Nt)/(Pt+Pf+Nf+Nt)\n",
    "                precision = (Pt)/(Pt+Pf)\n",
    "                recall = (Pt)/(Pt+Nf)\n",
    "                f1 = (2*precision*recall)/(precision+recall)\n",
    "                print(precision)\n",
    "                print(recall)\n",
    "                print(\"Model got \" + str(countR) + \"/\" + str(total) + \" right.\")\n",
    "                print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")\n",
    "                print(f\"{numZero}, {numZero/total * 100}% Zeroes, {total-numZero} Non Zero entries.\")\n",
    "                return f1, recall, precision, accuracy\n",
    "            else:\n",
    "                # At least calculate accuracy when the model predicts zero.\n",
    "                accuracy = (Pt+Nt)/(Pt+Pf+Nf+Nt)\n",
    "                print(\"Model could not complete tests.\")\n",
    "                return 0, 0, 0, accuracy \n",
    "        else:\n",
    "            # If we have at least one true positive, we can do all the other calculations.\n",
    "            if Pt != 0:\n",
    "                # Calculate accuracy, prcecision, recall and f1.\n",
    "                accuracy = (Pt+Nt)/(Pt+Pf+Nf+Nt)\n",
    "                precision = (Pt)/(Pt+Pf)\n",
    "                recall = (Pt)/(Pt+Nf)\n",
    "                f1 = (2*precision*recall)/(precision+recall)\n",
    "                print(precision)\n",
    "                print(recall)\n",
    "                print(\"Model got \" + str(countR) + \"/\" + str(total) + \" right.\")\n",
    "                print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")\n",
    "                print(f\"{numZero}, {numZero/total * 100}% Zeroes, {total-numZero} Non Zero entries.\")\n",
    "                return f\"Model got {countR}/{total} right. Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}\"\n",
    "            else:\n",
    "                print(\"Model could not complete tests.\")\n",
    "                return f\"Model could not complete tests, found 0 of misbehaviour.\"\n",
    "    \n",
    "    # Run a test step of the model.\n",
    "    def testStep(self, dataLoader):\n",
    "        self.learner.validation_step(next(iter(dataLoader)), 0)\n",
    "    \n",
    "    # Re-define the model.\n",
    "    def setModel(self, model):\n",
    "        if not model == None:\n",
    "            self.model = model\n",
    "\n",
    "    # Return the current model.\n",
    "    def getModel(self):\n",
    "        return self.model\n",
    "    \n",
    "    # Get the saved vehicle weights.\n",
    "    def getSavedState(self):\n",
    "        return self.prevWeights\n",
    "\n",
    "    # Update the saved vehicle weights.\n",
    "    def updateSavedStates(self):\n",
    "        # If this OBU is acting as malicious, we return the incorrect weights.\n",
    "        if self.evil:\n",
    "            self.prevWeights = dict((n, torch.full(self.learner.state_dict()[n].shape,10000000)) for n in self.learner.state_dict()).copy()\n",
    "            return # Never update weights, so always passing on very large weights\n",
    "        self.prevWeights = self.learner.state_dict().copy()\n",
    "    \n",
    "    # get the current state.\n",
    "    def getState(self):\n",
    "        return self.learner.state_dict()\n",
    "    \n",
    "    # Restore the OBU from the saved state.\n",
    "    def restoreFromBackup(self):\n",
    "        self.trainer.fit_loop.max_epochs = self.trainer.current_epoch - self.perEpoch\n",
    "        self.trainer.fit(self.learner, self.dataset, ckpt_path=f'log/Fed/{self.id}checkpoint.ckpt')\n",
    "\n",
    "    # Save the current state as a backup.\n",
    "    def saveBackup(self):\n",
    "        self.trainer.save_checkpoint(f'log/Fed/{self.id}checkpoint.ckpt')\n",
    "    \n",
    "    # Get malicious status of vehicle.\n",
    "    def isEvil(self):\n",
    "        return True if self.evil else False\n",
    "    \n",
    "    # Set state of learner and model. One input just sets the state, and two inputs adds them together first.\n",
    "    def setState(self, one, two = None):\n",
    "        if two:\n",
    "            tom = dict((n, one.get(n, 0)+two.get(n, 0)) for n in set(one)|set(two))\n",
    "        else:\n",
    "            tom = one\n",
    "        self.learner.load_state_dict(tom)\n",
    "        return tom\n",
    "    \n",
    "    # Run one sub-epoch of the model.\n",
    "    def step(self, epochs):\n",
    "        self.perEpoch = epochs\n",
    "        self.trainer.fit_loop.max_epochs = self.trainer.current_epoch + epochs\n",
    "        self.curr_loss = self.fit(self.dataset).item()\n",
    "        return self.curr_loss\n",
    "\n",
    "    # Update the vehicles we are sampling for this epoch.\n",
    "    # Not used by DeFL/DeFTA anymore.\n",
    "    def updateSelected(self):\n",
    "        self.sampling = []\n",
    "        count = 0\n",
    "        for idx in self.nearbyOBUs:\n",
    "            rand = np.random.randint(0, 100)\n",
    "            if rand <= int(100*self.samplingWeights[idx]): # Less than or equal, as we want 1 to be selected every time.\n",
    "                self.sampling.append(int(idx))\n",
    "                count += 1\n",
    "        return self.sampling # Returning how many vehicles were selected for training\n",
    "        \n",
    "    # Reset the trainer with a new trainer.\n",
    "    def resetTrainer(self):\n",
    "        self.trainer = pl.Trainer(\n",
    "            logger = CSVLogger('log'), # Set ouput destination of logs, logging accuracy every 50 steps\n",
    "            max_epochs = self.epochs, # Number of epochs to train for\n",
    "            gradient_clip_val = 1, # This is said to stabilize training, but we should test if that is true\n",
    "            accelerator = \"gpu\" if self.gpu else \"cpu\" # Using the GPU to run training or not\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "189ddaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class to monitor all metrics of model to generate graphs and compare.\n",
    "class OutLogger():\n",
    "    def __init__(self, path):\n",
    "        #Helpers\n",
    "        self.path = path\n",
    "        self.epochTimes = []\n",
    "        self.times = []\n",
    "\n",
    "        #Outs\n",
    "        self.avgLossVEpoch = []\n",
    "        self.avgF1VEpoch = []\n",
    "        self.avgRecallVEpoch = []\n",
    "        self.avgPrecisionVEpoch = []\n",
    "        self.avgAccuracyVEpoch = []\n",
    "        self.lossVPercEvil = None\n",
    "        self.F1VPercEvil = None\n",
    "        self.RecallVPercEvil = None\n",
    "        self.PrecisionVPercEvil = None\n",
    "        self.AccuracyVPercEvil = None\n",
    "        self.AvgVehicleTime = None\n",
    "        self.MaxVehicleTime = None\n",
    "        self.TotTime = None\n",
    "\n",
    "    # Define start and end for timing the per vehicle time.\n",
    "    def startVehicleTimer(self):\n",
    "        self.startTime = time.time()\n",
    "    def endVehicleTimer(self):\n",
    "        self.times.append(time.time()-self.startTime)\n",
    "\n",
    "    # Define start and end for timing the full epoch time.\n",
    "    def startEpochTimer(self):\n",
    "        self.startEpochTime = time.time()\n",
    "    def endEpochTimer(self):\n",
    "        self.epochTimes.append(time.time()-self.startEpochTime)\n",
    "\n",
    "    # Update the logs by running a test per vehicle. \n",
    "    def updateLogs(self, vehicles, epoch):\n",
    "        currLoss = 0\n",
    "        currF1 = 0\n",
    "        currRecall = 0\n",
    "        currPrecision = 0\n",
    "        currAccuracy = 0\n",
    "        count = 0\n",
    "        for vehicle in vehicles:\n",
    "            currLoss += vehicle.curr_loss\n",
    "            f1, recall, precision, accuracy = vehicle.test(testingIn, testingOut, True)\n",
    "            currF1 += f1\n",
    "            currRecall += recall\n",
    "            currPrecision += precision\n",
    "            currAccuracy += accuracy\n",
    "            count += 1\n",
    "        self.avgLossVEpoch.append([epoch, currLoss/count])\n",
    "        self.avgF1VEpoch.append([epoch, currF1/count])\n",
    "        self.avgRecallVEpoch.append([epoch, currRecall/count])\n",
    "        self.avgPrecisionVEpoch.append([epoch, currPrecision/count])\n",
    "        self.avgAccuracyVEpoch.append([epoch, currAccuracy/count])\n",
    "            \n",
    "    # Add the final times and values to their respective point in the log.\n",
    "    def finalLogs(self, vehicles, percEvil):\n",
    "        self.lossVPercEvil = [percEvil, self.avgLossVEpoch[-1][1]]\n",
    "        self.F1VPercEvil = [percEvil, self.avgF1VEpoch[-1][1]]\n",
    "        self.RecallVPercEvil = [percEvil, self.avgRecallVEpoch[-1][1]]\n",
    "        self.PrecisionVPercEvil = [percEvil, self.avgPrecisionVEpoch[-1][1]]\n",
    "        self.AccuracyVPercEvil = [percEvil, self.avgAccuracyVEpoch[-1][1]]\n",
    "        self.AvgVehicleTime = np.sum(self.times)/len(self.times)\n",
    "        self.MaxVehicleTime = np.max(self.times)\n",
    "        self.TotTime = np.sum(self.epochTimes)/len(self.epochTimes)\n",
    "\n",
    "    # Ouput the logged values to files.\n",
    "    def log(self):\n",
    "        path = f\"out/{self.path}\"\n",
    "        if not os.path.exists(f\"out/{self.path}\"):\n",
    "            os.makedirs(f\"out/{self.path}\")\n",
    "        with open(f'{path}avgLossVEpoch.csv', 'w', newline='') as filename:\n",
    "            writer = csv.writer(filename)\n",
    "            writer.writerow(['epoch', 'avg Loss'])\n",
    "            writer.writerows(self.avgLossVEpoch)\n",
    "        with open(f'{path}avgF1VEpoch.csv', 'w', newline='') as filename:\n",
    "            writer = csv.writer(filename)\n",
    "            writer.writerow(['epoch', 'avg F1'])\n",
    "            writer.writerows(self.avgF1VEpoch)\n",
    "        with open(f'{path}avgRecallVEpoch.csv', 'w', newline='') as filename:\n",
    "            writer = csv.writer(filename)\n",
    "            writer.writerow(['epoch', 'avg Recall'])\n",
    "            writer.writerows(self.avgRecallVEpoch)\n",
    "        with open(f'{path}avgPrecisionVEpoch.csv', 'w', newline='') as filename:\n",
    "            writer = csv.writer(filename)\n",
    "            writer.writerow(['epoch', 'avg Precision'])\n",
    "            writer.writerows(self.avgPrecisionVEpoch)\n",
    "        with open(f'{path}avgAccuracyVEpoch.csv', 'w', newline='') as filename:\n",
    "            writer = csv.writer(filename)\n",
    "            writer.writerow(['epoch', 'avg Accuracy'])\n",
    "            writer.writerows(self.avgAccuracyVEpoch)\n",
    "        others = {'Loss V PercEvil':self.lossVPercEvil, 'F1 V PercEvil':self.F1VPercEvil, 'Recall V PercEvil':self.RecallVPercEvil, 'Precision V PercEvil':self.PrecisionVPercEvil, \n",
    "                  'Accuracy V PercEvil':self.AccuracyVPercEvil, 'Max Per-Vehicle Time':self.MaxVehicleTime, 'Avg Per-Vehicle Time':self.AvgVehicleTime, 'Total Time Per Epoch':self.TotTime}\n",
    "        with open(f'{path}avgAccuracyVEpoch.csv', 'w', newline='') as filename:\n",
    "            writer = csv.writer(filename)\n",
    "            writer.writerow(['epoch', 'avg Accuracy'])\n",
    "            writer.writerows(self.avgAccuracyVEpoch)\n",
    "        with open(f'{path}ExtraData.json', 'w') as filename:\n",
    "            json.dump(others, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd58282c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1000\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  33%|███▎      | 1/3 [00:00<00:00, 35.69it/s, v_num=5044, trainLoss=0.474]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:1056\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/loops/training_epoch_loop.py:152\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/loops/training_epoch_loop.py:344\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer.lightning_module.automatic_optimization:\n\u001b[32m    343\u001b[39m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m     batch_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mautomatic_optimization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/loops/optimization/automatic.py:192\u001b[39m, in \u001b[36m_AutomaticOptimization.run\u001b[39m\u001b[34m(self, optimizer, batch_idx, kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m result = closure.consume_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/loops/optimization/automatic.py:270\u001b[39m, in \u001b[36m_AutomaticOptimization._optimizer_step\u001b[39m\u001b[34m(self, batch_idx, train_step_and_backward_closure)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moptimizer_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py:176\u001b[39m, in \u001b[36m_call_lightning_module_hook\u001b[39m\u001b[34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/core/module.py:1328\u001b[39m, in \u001b[36mLightningModule.optimizer_step\u001b[39m\u001b[34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[39m\n\u001b[32m   1304\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[32m   1305\u001b[39m \u001b[33;03mthe optimizer.\u001b[39;00m\n\u001b[32m   1306\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1326\u001b[39m \n\u001b[32m   1327\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1328\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/core/optimizer.py:154\u001b[39m, in \u001b[36mLightningOptimizer.step\u001b[39m\u001b[34m(self, closure, **kwargs)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m._on_after_step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/strategies/strategy.py:239\u001b[39m, in \u001b[36mStrategy.optimizer_step\u001b[39m\u001b[34m(self, optimizer, closure, model, **kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl.LightningModule)\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecision_plugin\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/plugins/precision/precision.py:123\u001b[39m, in \u001b[36mPrecision.optimizer_step\u001b[39m\u001b[34m(self, optimizer, model, closure, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m closure = partial(\u001b[38;5;28mself\u001b[39m._wrap_closure, model, optimizer, closure)\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/torch/optim/optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/torch/optim/optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/torch/optim/adam.py:220\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Perform a single optimization step.\u001b[39;00m\n\u001b[32m    215\u001b[39m \n\u001b[32m    216\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    217\u001b[39m \u001b[33;03m    closure (Callable, optional): A closure that reevaluates the model\u001b[39;00m\n\u001b[32m    218\u001b[39m \u001b[33;03m        and returns the loss.\u001b[39;00m\n\u001b[32m    219\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cuda_graph_capture_health_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m loss = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/torch/optim/optimizer.py:426\u001b[39m, in \u001b[36mOptimizer._cuda_graph_capture_health_check\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_cuda_graph_capture_health_check\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    413\u001b[39m     \u001b[38;5;66;03m# Note [torch.compile x capturable]\u001b[39;00m\n\u001b[32m    414\u001b[39m     \u001b[38;5;66;03m# If we are compiling, we try to take the capturable path automatically by\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    421\u001b[39m     \u001b[38;5;66;03m# Thus, when compiling, inductor will determine if cudagraphs\u001b[39;00m\n\u001b[32m    422\u001b[39m     \u001b[38;5;66;03m# can be enabled based on whether there is input mutation or CPU tensors.\u001b[39;00m\n\u001b[32m    423\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    424\u001b[39m         \u001b[38;5;129;01mnot\u001b[39;00m torch.compiler.is_compiling()\n\u001b[32m    425\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m torch.backends.cuda.is_built()\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    427\u001b[39m     ):\n\u001b[32m    428\u001b[39m         capturing = torch.cuda.is_current_stream_capturing()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/torch/cuda/__init__.py:169\u001b[39m, in \u001b[36mis_available\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _nvml_based_avail():\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The user has set an env variable to request this availability check that attempts to avoid fork poisoning by\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# using NVML at the cost of a weaker CUDA availability assessment. Note that if NVML discovery/initialization\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# fails, this assessment falls back to the default CUDA Runtime API assessment (`cudaGetDeviceCount`)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdevice_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m > \u001b[32m0\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    171\u001b[39m     \u001b[38;5;66;03m# The default availability inspection never throws and returns 0 if the driver is missing or can't\u001b[39;00m\n\u001b[32m    172\u001b[39m     \u001b[38;5;66;03m# be initialized. This uses the CUDA Runtime API `cudaGetDeviceCount` which in turn initializes the CUDA Driver\u001b[39;00m\n\u001b[32m    173\u001b[39m     \u001b[38;5;66;03m# API via `cuInit`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/torch/cuda/__init__.py:990\u001b[39m, in \u001b[36mdevice_count\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;66;03m# bypass _device_count_nvml() if rocm (not supported)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m990\u001b[39m nvml_count = _device_count_amdsmi() \u001b[38;5;28;01mif\u001b[39;00m torch.version.hip \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_device_count_nvml\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    991\u001b[39m r = torch._C._cuda_getDeviceCount() \u001b[38;5;28;01mif\u001b[39;00m nvml_count < \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m nvml_count\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/torch/cuda/__init__.py:946\u001b[39m, in \u001b[36m_device_count_nvml\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    945\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m946\u001b[39m     raw_cnt = \u001b[43m_raw_device_count_nvml\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_cnt <= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/torch/cuda/__init__.py:787\u001b[39m, in \u001b[36m_raw_device_count_nvml\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    786\u001b[39m nvml_h = CDLL(\u001b[33m\"\u001b[39m\u001b[33mlibnvidia-ml.so.1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m rc = \u001b[43mnvml_h\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnvmlInit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rc != \u001b[32m0\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 109\u001b[39m\n\u001b[32m    105\u001b[39m     models[rcvr].setState(mainModel.getState())\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Reset the trainer (should be unneeded now) to allow for further training\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# mod.resetTrainer()\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m# Actually train\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m modLoss = \u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrcvr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubEpochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m weights.append(\u001b[32m1\u001b[39m/modLoss)\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deepTest \u001b[38;5;129;01mor\u001b[39;00m doValidation:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 207\u001b[39m, in \u001b[36mOBU.step\u001b[39m\u001b[34m(self, epochs)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28mself\u001b[39m.perEpoch = epochs\n\u001b[32m    206\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.fit_loop.max_epochs = \u001b[38;5;28mself\u001b[39m.trainer.current_epoch + epochs\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m \u001b[38;5;28mself\u001b[39m.curr_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m.item()\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.curr_loss\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 78\u001b[39m, in \u001b[36mOBU.fit\u001b[39m\u001b[34m(self, dataLoader)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataLoader):\n\u001b[32m     77\u001b[39m     \u001b[38;5;66;03m# calling built in fit function\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlearner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataLoader\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.learner.loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py:65\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[32m     64\u001b[39m         launcher.kill(_get_sigkill_signal())\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     68\u001b[39m     _interrupt(trainer, exception)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "# Standard Federated Learning\n",
    "\n",
    "# With 2 epochs, 10 sub, and 0:3 models ending acc. of 0.1377%\n",
    "# With 2 epochs, 10 sub, and 0:10 models ending acc. of\n",
    "\n",
    "# Tested with weights, but weighing off of the loss leads to choosing the models trained by vehicles without attacks.\n",
    "pl.seed_everything(1000)\n",
    "results = {}\n",
    "dataSets = {}\n",
    "models = {}\n",
    "histWeights = []\n",
    "percentages = []\n",
    "cars = []\n",
    "rcvrs = []\n",
    "percs = {}\n",
    "states = {}\n",
    "subEpochs = 30 # 50\n",
    "epochs = 30 # 5\n",
    "vehicles = 1 # 50\n",
    "lr = 0.01\n",
    "motors = 8\n",
    "units = 20\n",
    "batchSize = 64\n",
    "gpu = False\n",
    "deepTest = False\n",
    "weighing = False\n",
    "randomVehicles = False\n",
    "doValidation = False\n",
    "doEvil = False\n",
    "percEvil = 20\n",
    "avgLossVEpoch = []\n",
    "avgF1VEpoch = []\n",
    "avgRecallVEpoch = []\n",
    "avgPrecisionVEpoch = []\n",
    "\n",
    "# Create starting models\n",
    "mainModel = OBU(7, epochs= subEpochs, gpu = gpu, lr = lr, motors = motors, units = units)\n",
    "nextModel = OBU(7, epochs= subEpochs, gpu = gpu, lr = lr, motors = motors, units = units)\n",
    "path = f\"FL/{doEvil}-{percEvil}-{epochs}-{subEpochs}-{vehicles}/\"\n",
    "if not os.path.exists(f\"out/{path}\"):\n",
    "    os.makedirs(f\"out/{path}\")\n",
    "\n",
    "log = OutLogger(path)\n",
    "\n",
    "if not randomVehicles:\n",
    "    # Divide dataset of recieving vehicles among OBUs\n",
    "    rcvrs = []\n",
    "    for vehicle in fedDataSet[500:vehicles+500]: # 10\n",
    "        rcvrID = int(vehicle[0,0,2].item())\n",
    "        # Add new OBU for each model\n",
    "        if np.random.randint(0,100) < percEvil:\n",
    "            models[rcvrID] = OBU(7, epochs = subEpochs, gpu=gpu, lr = lr, motors = motors, units = units, evil = True)\n",
    "        else:\n",
    "            models[rcvrID] = OBU(7, epochs = subEpochs, gpu=gpu, lr = lr, motors = motors, units = units)\n",
    "        # Create Slice of dataset\n",
    "        vehicle = data.DataLoader(data.TensorDataset(vehicle[:,:,3:10].float(), vehicle[:,:,11].long()), batch_size=batchSize, shuffle=False, num_workers=16, persistent_workers = True) # type: ignore\n",
    "        # Add sub - dataset to dataset\n",
    "        rcvrs.append(rcvrID)\n",
    "        dataSets[rcvrID]=vehicle\n",
    "        models[rcvrID].dataset = vehicle\n",
    "\n",
    "# Train individual models and combine\n",
    "for epoch in range(epochs):\n",
    "    i = 0\n",
    "    if randomVehicles:\n",
    "        # choose random assortment of vehicles to train on\n",
    "        cars = []\n",
    "        rcvrs = []\n",
    "        for ted in np.random.choice(len(fedDataSet), vehicles, replace = False):\n",
    "            cars.append(fedDataSet[ted])\n",
    "        # Divide dataset of recieving vehicles among OBUs\n",
    "        for vehicle in cars: # 10\n",
    "            rcvrID = int(vehicle[0,0,2].item())\n",
    "            # Add new OBU for each model\n",
    "            if rcvrID not in models:\n",
    "                if np.random.randint(0,100) < percEvil:\n",
    "                    models[rcvrID] = OBU(7, epochs = subEpochs, gpu=gpu, lr = lr, motors = motors, units = units, evil = True)\n",
    "                else:\n",
    "                    models[rcvrID] = OBU(7, epochs = subEpochs, gpu=gpu, lr = lr, motors = motors, units = units)\n",
    "            # Create Slice of dataset\n",
    "            vehicle = data.DataLoader(data.TensorDataset(vehicle[:,:,3:10].float(), vehicle[:,:,11].long()), batch_size=batchSize, shuffle=False, num_workers=16, persistent_workers = True)\n",
    "            # Add sub - dataset to dataset\n",
    "            rcvrs.append(rcvrID)\n",
    "            dataSets[rcvrID]=vehicle\n",
    "            models[rcvrID].dataset = vehicle\n",
    "\n",
    "    print(rcvrs, file = open('rcvrs.txt', 'w'))\n",
    "    # Baseline model to add everything to. !!Do I want this or should it be a completely new model?!! Got 0% on combination before, testing with new model for next model.\n",
    "    nextModel = OBU(7, epochs= subEpochs, gpu = gpu, lr = lr, motors = motors, units = units)\n",
    "    # Train models\n",
    "    weights = []\n",
    "    for rcvr in rcvrs:\n",
    "        log.startEpochTimer()\n",
    "        log.startVehicleTimer()\n",
    "        # Make multithreaded?\n",
    "        if doValidation and models[rcvr].prevAccuracy != 0:\n",
    "            _, _, p, _ = mainModel.test(inTest, outTest)\n",
    "            print(f\"Current Epoch: {epoch}, Reciever: {rcvr}\")\n",
    "            print(f\"Tested. main perc: {p}, my perc: {models[rcvr].prevAccuracy}\")\n",
    "            if p > models[rcvr].prevAccuracy:\n",
    "                print(\"Updating Model\")\n",
    "                # set model to main model, and train that \n",
    "                models[rcvr].setState(mainModel.getState())\n",
    "        else:\n",
    "            models[rcvr].setState(mainModel.getState())\n",
    "        # Reset the trainer (should be unneeded now) to allow for further training\n",
    "        # mod.resetTrainer()\n",
    "        # Actually train\n",
    "        modLoss = models[rcvr].step(subEpochs)\n",
    "\n",
    "        weights.append(1/modLoss)\n",
    "        if deepTest or doValidation:\n",
    "            _, _ , perc, _ = models[rcvr].test(inTest, outTest)\n",
    "            percs[rcvr] = perc\n",
    "            models[rcvr].prevAccuracy = perc\n",
    "            # Test individual model\n",
    "            print(rcvr)\n",
    "            if rcvr not in results:\n",
    "                results[rcvr] = ([epoch, i+1, perc, modLoss.item()])\n",
    "            else:\n",
    "                results[rcvr].append([epoch, i+1, perc, modLoss.item()])\n",
    "        states[rcvr] = (models[rcvr].getState())\n",
    "        i+=1\n",
    "        log.endEpochTimer()\n",
    "        log.endVehicleTimer()\n",
    "    # Create combined model\n",
    "    # combine models\n",
    "    weights = np.abs(weights)/np.sum(weights)\n",
    "\n",
    "    log.updateLogs([models[rcvr] for rcvr in rcvrs], epoch)\n",
    "\n",
    "    y=0\n",
    "    for w in weights:\n",
    "        y+= w\n",
    "    teds = [[float(weights[n]), percs[n]] for n in range(len(percs))]\n",
    "    percentages.append(teds)\n",
    "    histWeights.append([weights,y])\n",
    "    tom = 1/i\n",
    "    for rcvr in rcvrs:\n",
    "        if weighing:\n",
    "            nextState = nextModel.setState(nextModel.getState(), dict((n, states[rcvr].get(n, 0)*weights[rcvr]) for n in states[rcvr])) # Done with weights\n",
    "        else:\n",
    "            nextState = nextModel.setState(nextModel.getState(), states[rcvr]) # No Weights\n",
    "    if weighing:\n",
    "        mainModel.setState(nextState) #Weights\n",
    "    else:\n",
    "        mainModel.setState(dict((n, nextState.get(n, 0)/i) for n in nextState)) # No weights\n",
    "# Test combined model at end\n",
    "log.finalLogs([models[rcvr] for rcvr in rcvrs], percEvil)\n",
    "perc = mainModel.test(testDataIn, testDataOut)\n",
    "results['FINAL'] = [-1, -1, perc]\n",
    "evils = []\n",
    "for rcvr in rcvrs: # Create list of evil/bad vehicles\n",
    "    if models[rcvr].isEvil():\n",
    "        evils.append(models[rcvr].id)\n",
    "print(evils, file=open(f'out/{path}VehicleStatus.txt','w'))\n",
    "print(results, file = open(f'out/{path}results.txt', 'w'))\n",
    "print(histWeights, file = open(f'out/{path}Weights.txt', 'w'))\n",
    "print(percentages, file = open(f'out/{path}Percs.txt', 'w'))\n",
    "log.log()\n",
    "\n",
    "\n",
    "# 'Model got 340703/1247740 right. Accuracy: 0.27305608540240756, Precision: 0.27978235144854047, Recall: 0.919080118694362, F1 Score: 0.42897730670851897'\n",
    "# This was with scheduler, 50, 10, 100. Before accuracy with this was 96.388%, now 27.306%. \n",
    "# Running test with 50, 5, 50, w/out scheduler: 'Model got 1170620/1247740 right. Accuracy: 0.9381922515908763, Precision: 0.8443495151097161, Recall: 0.9709495548961424, F1 Score: 0.90323495386345'\n",
    "# Accuracy of 93.820% after half the vehicles and half the epochs. I think we need to rething the scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629437ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1000\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 0 now\n",
      "vehicle 0 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 1 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 2 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 3 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 4 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 5 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 6 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 7 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 8 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 9 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 10 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 11 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 12 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 13 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 14 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 15 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 16 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 17 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 18 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 19 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 20 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 21 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 22 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 23 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 24 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 25 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 26 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 27 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 28 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 29 priority: 1.0, total priority of subgroup: 1.0\n",
      "Epoch 29: 100%|██████████| 2/2 [00:00<00:00, 45.94it/s, v_num=2480, trainLoss=1.630]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 2/2 [00:00<00:00, 39.70it/s, v_num=2480, trainLoss=1.630]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 46.64it/s, v_num=2481, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 36.06it/s, v_num=2481, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 29: 100%|██████████| 2/2 [00:00<00:00, 45.81it/s, v_num=2482, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 2/2 [00:00<00:00, 39.72it/s, v_num=2482, trainLoss=9.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 39.37it/s, v_num=2483, trainLoss=2.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 30.10it/s, v_num=2483, trainLoss=2.460]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 43.54it/s, v_num=2484, trainLoss=2.200]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 34.88it/s, v_num=2484, trainLoss=2.200]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 42.85it/s, v_num=2485, trainLoss=2.440]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 32.97it/s, v_num=2485, trainLoss=2.440]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 43.65it/s, v_num=2486, trainLoss=2.850]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 33.44it/s, v_num=2486, trainLoss=2.850]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 44.65it/s, v_num=2487, trainLoss=2.500]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 34.32it/s, v_num=2487, trainLoss=2.500]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 45.74it/s, v_num=2488, trainLoss=1.080]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 36.14it/s, v_num=2488, trainLoss=1.080]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 29: 100%|██████████| 5/5 [00:00<00:00, 51.63it/s, v_num=2489, trainLoss=0.054] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 5/5 [00:00<00:00, 48.37it/s, v_num=2489, trainLoss=0.054]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6227813974387778\n",
      "0.8425531914893617\n",
      "Model got 16406/20800 right.\n",
      "Accuracy: 0.78875, Precision: 0.6227813974387778, Recall: 0.8425531914893617, F1 Score: 0.7161865392068208\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 42.81it/s, v_num=2490, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 33.95it/s, v_num=2490, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 29: 100%|██████████| 4/4 [00:00<00:00, 48.25it/s, v_num=2491, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 4/4 [00:00<00:00, 44.31it/s, v_num=2491, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 29: 100%|██████████| 3/3 [00:00<00:00, 44.48it/s, v_num=2492, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 3/3 [00:00<00:00, 40.64it/s, v_num=2492, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 29: 100%|██████████| 2/2 [00:00<00:00, 50.62it/s, v_num=2493, trainLoss=0.320]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 2/2 [00:00<00:00, 43.14it/s, v_num=2493, trainLoss=0.320]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 29: 100%|██████████| 3/3 [00:00<00:00, 53.24it/s, v_num=2494, trainLoss=0.238]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 3/3 [00:00<00:00, 47.88it/s, v_num=2494, trainLoss=0.238]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 29: 100%|██████████| 5/5 [00:00<00:00, 48.92it/s, v_num=2495, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 5/5 [00:00<00:00, 45.80it/s, v_num=2495, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 40.00it/s, v_num=2496, trainLoss=1.370]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 31.83it/s, v_num=2496, trainLoss=1.370]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 29: 100%|██████████| 2/2 [00:00<00:00, 46.08it/s, v_num=2497, trainLoss=1.490]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 2/2 [00:00<00:00, 40.53it/s, v_num=2497, trainLoss=1.490]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35663918420481666\n",
      "0.9992401215805471\n",
      "Model got 8934/20800 right.\n",
      "Accuracy: 0.42951923076923076, Precision: 0.35663918420481666, Recall: 0.9992401215805471, F1 Score: 0.5256635753118004\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 42.84it/s, v_num=2498, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 34.43it/s, v_num=2498, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 29: 100%|██████████| 2/2 [00:00<00:00, 50.47it/s, v_num=2499, trainLoss=0.486]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 2/2 [00:00<00:00, 44.28it/s, v_num=2499, trainLoss=0.486]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 52.55it/s, v_num=2500, trainLoss=1.110]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 40.08it/s, v_num=2500, trainLoss=1.110]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 43.65it/s, v_num=2501, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 33.96it/s, v_num=2501, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 48.99it/s, v_num=2502, trainLoss=0.642]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 38.19it/s, v_num=2502, trainLoss=0.642]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 49.05it/s, v_num=2503, trainLoss=0.329]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 36.63it/s, v_num=2503, trainLoss=0.329]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 46.81it/s, v_num=2504, trainLoss=1.170]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 35.95it/s, v_num=2504, trainLoss=1.170]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5947986577181208\n",
      "0.9697568389057751\n",
      "Model got 16254/20800 right.\n",
      "Accuracy: 0.7814423076923077, Precision: 0.5947986577181208, Recall: 0.9697568389057751, F1 Score: 0.7373468916108159\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 45.05it/s, v_num=2505, trainLoss=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 35.65it/s, v_num=2505, trainLoss=1.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 46.14it/s, v_num=2506, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 36.55it/s, v_num=2506, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 49.17it/s, v_num=2507, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 38.72it/s, v_num=2507, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 43.95it/s, v_num=2508, trainLoss=0.993]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 33.76it/s, v_num=2508, trainLoss=0.993]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 40.54it/s, v_num=2509, trainLoss=1.780]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 32.75it/s, v_num=2509, trainLoss=1.780]\n",
      "torch.Size([2080, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.3144\n",
      "1.0\n",
      "Model got 15720/50000 right.\n",
      "Accuracy: 0.3144, Precision: 0.3144, Recall: 1.0, F1 Score: 0.47839318320146074\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.3144\n",
      "1.0\n",
      "Model got 15720/50000 right.\n",
      "Accuracy: 0.3144, Precision: 0.3144, Recall: 1.0, F1 Score: 0.47839318320146074\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.3144\n",
      "1.0\n",
      "Model got 15720/50000 right.\n",
      "Accuracy: 0.3144, Precision: 0.3144, Recall: 1.0, F1 Score: 0.47839318320146074\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.3144\n",
      "1.0\n",
      "Model got 15720/50000 right.\n",
      "Accuracy: 0.3144, Precision: 0.3144, Recall: 1.0, F1 Score: 0.47839318320146074\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.3144\n",
      "1.0\n",
      "Model got 15720/50000 right.\n",
      "Accuracy: 0.3144, Precision: 0.3144, Recall: 1.0, F1 Score: 0.47839318320146074\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.3144\n",
      "1.0\n",
      "Model got 15720/50000 right.\n",
      "Accuracy: 0.3144, Precision: 0.3144, Recall: 1.0, F1 Score: 0.47839318320146074\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.610181341490059\n",
      "0.888295165394402\n",
      "Model got 39323/50000 right.\n",
      "Accuracy: 0.78646, Precision: 0.610181341490059, Recall: 0.888295165394402, F1 Score: 0.723429607563787\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.3144\n",
      "1.0\n",
      "Model got 15720/50000 right.\n",
      "Accuracy: 0.3144, Precision: 0.3144, Recall: 1.0, F1 Score: 0.47839318320146074\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.35796192864470533\n",
      "0.998854961832061\n",
      "Model got 21819/50000 right.\n",
      "Accuracy: 0.43638, Precision: 0.35796192864470533, Recall: 0.998854961832061, F1 Score: 0.5270453973315431\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.3144\n",
      "1.0\n",
      "Model got 15720/50000 right.\n",
      "Accuracy: 0.3144, Precision: 0.3144, Recall: 1.0, F1 Score: 0.47839318320146074\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.6162818566749221\n",
      "0.9814249363867684\n",
      "Model got 40102/50000 right.\n",
      "Accuracy: 0.80204, Precision: 0.6162818566749221, Recall: 0.9814249363867684, F1 Score: 0.7571281346616282\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.3144\n",
      "1.0\n",
      "Model got 15720/50000 right.\n",
      "Accuracy: 0.3144, Precision: 0.3144, Recall: 1.0, F1 Score: 0.47839318320146074\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2480/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Starting Epoch 1 now\n",
      "vehicle 0 priority: 0.3141592920353982, total priority of subgroup: 1.0\n",
      "vehicle 1 priority: 0.125, total priority of subgroup: 1.0\n",
      "vehicle 2 priority: 0.3205574912891986, total priority of subgroup: 1.0\n",
      "vehicle 3 priority: 0.9215686274509803, total priority of subgroup: 1.0\n",
      "vehicle 4 priority: 0.9354838709677419, total priority of subgroup: 1.0\n",
      "vehicle 5 priority: 0.14705882352941177, total priority of subgroup: 1.0\n",
      "vehicle 6 priority: 0.375, total priority of subgroup: 1.0\n",
      "vehicle 7 priority: 0.24468085106382978, total priority of subgroup: 1.0\n",
      "vehicle 8 priority: 0.3333333333333333, total priority of subgroup: 1.0\n",
      "vehicle 9 priority: 0.8571428571428571, total priority of subgroup: 1.0\n",
      "vehicle 10 priority: 0.4878048780487805, total priority of subgroup: 1.0\n",
      "vehicle 11 priority: 0.7303370786516854, total priority of subgroup: 1.0\n",
      "vehicle 12 priority: 0.8806818181818182, total priority of subgroup: 1.0\n",
      "vehicle 13 priority: 0.7386363636363636, total priority of subgroup: 1.0\n",
      "vehicle 14 priority: 0.8711656441717791, total priority of subgroup: 1.0\n",
      "vehicle 15 priority: 0.928082191780822, total priority of subgroup: 1.0\n",
      "vehicle 16 priority: 0.9047619047619048, total priority of subgroup: 1.0\n",
      "vehicle 17 priority: 0.9256198347107438, total priority of subgroup: 1.0\n",
      "vehicle 18 priority: 0.05244755244755245, total priority of subgroup: 1.0\n",
      "vehicle 19 priority: 0.2099125364431487, total priority of subgroup: 1.0\n",
      "vehicle 20 priority: 0.6666666666666666, total priority of subgroup: 1.0\n",
      "vehicle 21 priority: 0.7241379310344828, total priority of subgroup: 1.0\n",
      "vehicle 22 priority: 0.17391304347826086, total priority of subgroup: 1.0\n",
      "vehicle 23 priority: 0.09722222222222222, total priority of subgroup: 1.0\n",
      "vehicle 24 priority: 0.20103092783505155, total priority of subgroup: 1.0\n",
      "vehicle 25 priority: 0.5894736842105263, total priority of subgroup: 1.0\n",
      "vehicle 26 priority: 0.5, total priority of subgroup: 1.0\n",
      "vehicle 27 priority: 0.034482758620689655, total priority of subgroup: 1.0\n",
      "vehicle 28 priority: 0.6973684210526315, total priority of subgroup: 1.0\n",
      "vehicle 29 priority: 0.7540983606557377, total priority of subgroup: 1.0\n",
      "Epoch 59: 100%|██████████| 2/2 [00:00<00:00, 51.56it/s, v_num=2480, trainLoss=5.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 2/2 [00:00<00:00, 44.90it/s, v_num=2480, trainLoss=5.460]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2481/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 53.23it/s, v_num=2481, trainLoss=0.0756]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 39.00it/s, v_num=2481, trainLoss=0.0756]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2482/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 59: 100%|██████████| 2/2 [00:00<00:00, 46.87it/s, v_num=2482, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 2/2 [00:00<00:00, 41.14it/s, v_num=2482, trainLoss=9.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2483/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 41.19it/s, v_num=2483, trainLoss=2.130]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 32.79it/s, v_num=2483, trainLoss=2.130]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2484/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.413903743315508\n",
      "0.9998480243161094\n",
      "Model got 11483/20800 right.\n",
      "Accuracy: 0.5520673076923077, Precision: 0.413903743315508, Recall: 0.9998480243161094, F1 Score: 0.5854505005561735\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 44.48it/s, v_num=2484, trainLoss=1.050]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 35.06it/s, v_num=2484, trainLoss=1.050]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2485/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 49.86it/s, v_num=2485, trainLoss=0.754]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 37.81it/s, v_num=2485, trainLoss=0.754]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2486/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 48.20it/s, v_num=2486, trainLoss=2.800]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 37.81it/s, v_num=2486, trainLoss=2.800]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2487/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 45.80it/s, v_num=2487, trainLoss=5.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 36.23it/s, v_num=2487, trainLoss=5.460]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2488/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 50.13it/s, v_num=2488, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 37.49it/s, v_num=2488, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.31634615384615383, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 46.00it/s, v_num=2488, trainLoss=5.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 36.47it/s, v_num=2488, trainLoss=5.460]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2489/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 5/5 [00:00<00:00, 48.58it/s, v_num=2489, trainLoss=3.260]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 5/5 [00:00<00:00, 45.88it/s, v_num=2489, trainLoss=3.260]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.78875, Current Acc: 0.6836538461538462\n",
      "Loading From Backup\n",
      "Epoch 89: 100%|██████████| 5/5 [00:00<00:00, 48.57it/s, v_num=2489, trainLoss=3.120]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 5/5 [00:00<00:00, 45.92it/s, v_num=2489, trainLoss=3.120]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2490/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 46.68it/s, v_num=2490, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 36.27it/s, v_num=2490, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2491/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 59: 100%|██████████| 4/4 [00:00<00:00, 52.29it/s, v_num=2491, trainLoss=5.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 4/4 [00:00<00:00, 48.65it/s, v_num=2491, trainLoss=5.460]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2492/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 59: 100%|██████████| 3/3 [00:00<00:00, 48.39it/s, v_num=2492, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 3/3 [00:00<00:00, 44.34it/s, v_num=2492, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2493/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 59: 100%|██████████| 2/2 [00:00<00:00, 52.16it/s, v_num=2493, trainLoss=5.090]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 2/2 [00:00<00:00, 45.62it/s, v_num=2493, trainLoss=5.090]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.31634615384615383, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 89: 100%|██████████| 2/2 [00:00<00:00, 49.50it/s, v_num=2493, trainLoss=5.290]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 2/2 [00:00<00:00, 43.36it/s, v_num=2493, trainLoss=5.290]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2494/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 3/3 [00:00<00:00, 50.09it/s, v_num=2494, trainLoss=0.0644]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 3/3 [00:00<00:00, 45.41it/s, v_num=2494, trainLoss=0.0644]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2495/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5664144968332161\n",
      "0.9785714285714285\n",
      "Model got 15730/20800 right.\n",
      "Accuracy: 0.75625, Precision: 0.5664144968332161, Recall: 0.9785714285714285, F1 Score: 0.7175172721194563\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 59: 100%|██████████| 5/5 [00:00<00:00, 48.66it/s, v_num=2495, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 5/5 [00:00<00:00, 46.13it/s, v_num=2495, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2496/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 47.90it/s, v_num=2496, trainLoss=0.573]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 36.12it/s, v_num=2496, trainLoss=0.573]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2497/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5675726160455776\n",
      "0.9235562310030395\n",
      "Model got 15667/20800 right.\n",
      "Accuracy: 0.7532211538461538, Precision: 0.5675726160455776, Recall: 0.9235562310030395, F1 Score: 0.7030716723549487\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 59: 100%|██████████| 2/2 [00:00<00:00, 49.30it/s, v_num=2497, trainLoss=0.516]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 2/2 [00:00<00:00, 43.15it/s, v_num=2497, trainLoss=0.516]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2498/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8063774777362827\n",
      "0.8531914893617021\n",
      "Model got 18486/20800 right.\n",
      "Accuracy: 0.88875, Precision: 0.8063774777362827, Recall: 0.8531914893617021, F1 Score: 0.8291242061733864\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 47.75it/s, v_num=2498, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 37.78it/s, v_num=2498, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2499/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 59: 100%|██████████| 2/2 [00:00<00:00, 52.36it/s, v_num=2499, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 2/2 [00:00<00:00, 45.81it/s, v_num=2499, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 89: 100%|██████████| 2/2 [00:00<00:00, 48.93it/s, v_num=2499, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 2/2 [00:00<00:00, 43.05it/s, v_num=2499, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2500/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 47.78it/s, v_num=2500, trainLoss=0.763]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 37.22it/s, v_num=2500, trainLoss=0.763]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2501/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 42.72it/s, v_num=2501, trainLoss=5.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 34.24it/s, v_num=2501, trainLoss=5.460]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2502/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 52.73it/s, v_num=2502, trainLoss=0.0444]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 38.39it/s, v_num=2502, trainLoss=0.0444]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2503/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 44.44it/s, v_num=2503, trainLoss=2.770]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 34.97it/s, v_num=2503, trainLoss=2.770]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 49.46it/s, v_num=2503, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 35.29it/s, v_num=2503, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2504/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 46.39it/s, v_num=2504, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 36.50it/s, v_num=2504, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2505/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 44.72it/s, v_num=2505, trainLoss=2.950]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 33.98it/s, v_num=2505, trainLoss=2.950]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.31634615384615383\n",
      "Loading From Backup\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 47.02it/s, v_num=2505, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 35.99it/s, v_num=2505, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2506/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 43.46it/s, v_num=2506, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 34.82it/s, v_num=2506, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2507/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 52.81it/s, v_num=2507, trainLoss=0.136]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 39.54it/s, v_num=2507, trainLoss=0.136]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2508/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 45.75it/s, v_num=2508, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 34.77it/s, v_num=2508, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/.conda/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:658: Checkpoint directory log/Fed/lightning_logs/version_2509/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 42.42it/s, v_num=2509, trainLoss=5.150]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=60` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 33.44it/s, v_num=2509, trainLoss=5.150]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.31634615384615383\n",
      "Loading From Backup\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 40.48it/s, v_num=2509, trainLoss=5.150]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 32.08it/s, v_num=2509, trainLoss=5.150]\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.4229734094089784\n",
      "0.9997455470737914\n",
      "Model got 28556/50000 right.\n",
      "Accuracy: 0.57112, Precision: 0.4229734094089784, Recall: 0.9997455470737914, F1 Score: 0.594447386337847\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.3144\n",
      "1.0\n",
      "Model got 15720/50000 right.\n",
      "Accuracy: 0.3144, Precision: 0.3144, Recall: 1.0, F1 Score: 0.47839318320146074\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.3144\n",
      "1.0\n",
      "Model got 15720/50000 right.\n",
      "Accuracy: 0.3144, Precision: 0.3144, Recall: 1.0, F1 Score: 0.47839318320146074\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.593447677779919\n",
      "0.9794529262086514\n",
      "Model got 39129/50000 right.\n",
      "Accuracy: 0.78258, Precision: 0.593447677779919, Recall: 0.9794529262086514, F1 Score: 0.7390855634225368\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.5818304868824395\n",
      "0.92970737913486\n",
      "Model got 38391/50000 right.\n",
      "Accuracy: 0.76782, Precision: 0.5818304868824395, Recall: 0.92970737913486, F1 Score: 0.7157374078699281\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.8176613462873005\n",
      "0.8994274809160305\n",
      "Model got 45266/50000 right.\n",
      "Accuracy: 0.90532, Precision: 0.8176613462873005, Recall: 0.8994274809160305, F1 Score: 0.85659760087241\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.3144\n",
      "1.0\n",
      "Model got 15720/50000 right.\n",
      "Accuracy: 0.3144, Precision: 0.3144, Recall: 1.0, F1 Score: 0.47839318320146074\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Starting Epoch 2 now\n",
      "vehicle 0 priority: 0.8875, total priority of subgroup: 1.0\n",
      "vehicle 1 priority: 0.27586206896551724, total priority of subgroup: 1.0\n",
      "vehicle 2 priority: 0.2534435261707989, total priority of subgroup: 1.0\n",
      "vehicle 3 priority: 0.7580645161290323, total priority of subgroup: 1.0\n",
      "vehicle 4 priority: 0.7945205479452054, total priority of subgroup: 1.0\n",
      "vehicle 5 priority: 0.09803921568627451, total priority of subgroup: 1.0\n",
      "vehicle 6 priority: 0.47368421052631576, total priority of subgroup: 1.0\n",
      "vehicle 7 priority: 0.71875, total priority of subgroup: 1.0\n",
      "vehicle 8 priority: 0.3088235294117647, total priority of subgroup: 1.0\n",
      "vehicle 9 priority: 0.7988668555240793, total priority of subgroup: 1.0\n",
      "vehicle 10 priority: 0.6349206349206349, total priority of subgroup: 1.0\n",
      "vehicle 11 priority: 0.5571428571428572, total priority of subgroup: 1.0\n",
      "vehicle 12 priority: 0.9748427672955975, total priority of subgroup: 1.0\n",
      "vehicle 13 priority: 0.3140096618357488, total priority of subgroup: 1.0\n",
      "vehicle 14 priority: 0.7717391304347826, total priority of subgroup: 1.0\n",
      "vehicle 15 priority: 0.8713826366559485, total priority of subgroup: 1.0\n",
      "vehicle 16 priority: 0.7037037037037037, total priority of subgroup: 1.0\n",
      "vehicle 17 priority: 0.9655172413793104, total priority of subgroup: 1.0\n",
      "vehicle 18 priority: 0.2112676056338028, total priority of subgroup: 1.0\n",
      "vehicle 19 priority: 0.5625, total priority of subgroup: 1.0\n",
      "vehicle 20 priority: 0.1839080459770115, total priority of subgroup: 1.0\n",
      "vehicle 21 priority: 0.9130434782608695, total priority of subgroup: 1.0\n",
      "vehicle 22 priority: 0.27586206896551724, total priority of subgroup: 1.0\n",
      "vehicle 23 priority: 0.3333333333333333, total priority of subgroup: 1.0\n",
      "vehicle 24 priority: 0.6290322580645161, total priority of subgroup: 1.0\n",
      "vehicle 25 priority: 0.7272727272727273, total priority of subgroup: 1.0\n",
      "vehicle 26 priority: 0.24867724867724866, total priority of subgroup: 1.0\n",
      "vehicle 27 priority: 0.3076923076923077, total priority of subgroup: 1.0\n",
      "vehicle 28 priority: 0.5698924731182796, total priority of subgroup: 1.0\n",
      "vehicle 29 priority: 0.4946236559139785, total priority of subgroup: 1.0\n",
      "Epoch 89: 100%|██████████| 2/2 [00:00<00:00, 44.94it/s, v_num=2480, trainLoss=5.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 2/2 [00:00<00:00, 39.55it/s, v_num=2480, trainLoss=5.460]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 49.37it/s, v_num=2481, trainLoss=2.780]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 38.72it/s, v_num=2481, trainLoss=2.780]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 89: 100%|██████████| 2/2 [00:00<00:00, 45.95it/s, v_num=2482, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 2/2 [00:00<00:00, 39.97it/s, v_num=2482, trainLoss=9.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 41.28it/s, v_num=2483, trainLoss=2.650]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 33.30it/s, v_num=2483, trainLoss=2.650]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Previous Acc: 0.5520673076923077, Current Acc: 0.31634615384615383\n",
      "Loading From Backup\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 47.29it/s, v_num=2483, trainLoss=2.650]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 36.41it/s, v_num=2483, trainLoss=2.650]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 47.45it/s, v_num=2484, trainLoss=1.250]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 36.78it/s, v_num=2484, trainLoss=1.250]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 46.94it/s, v_num=2485, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 36.61it/s, v_num=2485, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 47.42it/s, v_num=2486, trainLoss=3.610]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 37.56it/s, v_num=2486, trainLoss=3.610]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 39.77it/s, v_num=2487, trainLoss=4.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 32.24it/s, v_num=2487, trainLoss=4.460]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 41.74it/s, v_num=2488, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 33.10it/s, v_num=2488, trainLoss=9.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 119: 100%|██████████| 5/5 [00:00<00:00, 50.22it/s, v_num=2489, trainLoss=4.170]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 5/5 [00:00<00:00, 47.18it/s, v_num=2489, trainLoss=4.170]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 44.73it/s, v_num=2490, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 34.82it/s, v_num=2490, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 40.20it/s, v_num=2490, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 31.67it/s, v_num=2490, trainLoss=9.390]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 4/4 [00:00<00:00, 42.86it/s, v_num=2491, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 4/4 [00:00<00:00, 40.38it/s, v_num=2491, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 89: 100%|██████████| 3/3 [00:00<00:00, 46.88it/s, v_num=2492, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 3/3 [00:00<00:00, 42.64it/s, v_num=2492, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 119: 100%|██████████| 2/2 [00:00<00:00, 49.71it/s, v_num=2493, trainLoss=2.780]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 2/2 [00:00<00:00, 43.74it/s, v_num=2493, trainLoss=2.780]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 89: 100%|██████████| 3/3 [00:00<00:00, 52.00it/s, v_num=2494, trainLoss=1.830]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 3/3 [00:00<00:00, 46.81it/s, v_num=2494, trainLoss=1.830]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.75625, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 119: 100%|██████████| 3/3 [00:00<00:00, 46.06it/s, v_num=2494, trainLoss=3.030]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 3/3 [00:00<00:00, 41.35it/s, v_num=2494, trainLoss=3.030]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 5/5 [00:00<00:00, 48.72it/s, v_num=2495, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 5/5 [00:00<00:00, 45.98it/s, v_num=2495, trainLoss=9.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 40.38it/s, v_num=2496, trainLoss=0.334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 32.46it/s, v_num=2496, trainLoss=0.334]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5906486786176307\n",
      "0.9714285714285714\n",
      "Model got 16182/20800 right.\n",
      "Accuracy: 0.7779807692307692, Precision: 0.5906486786176307, Recall: 0.9714285714285714, F1 Score: 0.7346282036547522\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 89: 100%|██████████| 2/2 [00:00<00:00, 43.15it/s, v_num=2497, trainLoss=0.0155]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 2/2 [00:00<00:00, 38.18it/s, v_num=2497, trainLoss=0.0155]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8662214126695001\n",
      "0.6504559270516718\n",
      "Model got 17839/20800 right.\n",
      "Accuracy: 0.8576442307692308, Precision: 0.8662214126695001, Recall: 0.6504559270516718, F1 Score: 0.7429910598038365\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 48.93it/s, v_num=2498, trainLoss=2.950]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 37.48it/s, v_num=2498, trainLoss=2.950]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 49.98it/s, v_num=2498, trainLoss=6.060]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 37.33it/s, v_num=2498, trainLoss=6.060]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 2/2 [00:00<00:00, 51.76it/s, v_num=2499, trainLoss=5.980]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 2/2 [00:00<00:00, 43.78it/s, v_num=2499, trainLoss=5.980]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 48.46it/s, v_num=2500, trainLoss=5.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 38.22it/s, v_num=2500, trainLoss=5.460]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 44.93it/s, v_num=2501, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 34.82it/s, v_num=2501, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 46.67it/s, v_num=2502, trainLoss=5.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 36.89it/s, v_num=2502, trainLoss=5.460]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 49.74it/s, v_num=2503, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 38.33it/s, v_num=2503, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 42.76it/s, v_num=2504, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 33.61it/s, v_num=2504, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 44.79it/s, v_num=2505, trainLoss=1.610]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 34.88it/s, v_num=2505, trainLoss=1.610]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 41.06it/s, v_num=2506, trainLoss=2.840]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 32.89it/s, v_num=2506, trainLoss=2.840]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 48.02it/s, v_num=2507, trainLoss=4.120]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 37.36it/s, v_num=2507, trainLoss=4.120]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 47.09it/s, v_num=2508, trainLoss=6.780]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 37.22it/s, v_num=2508, trainLoss=6.780]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 42.54it/s, v_num=2509, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 33.83it/s, v_num=2509, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.3144\n",
      "1.0\n",
      "Model got 15720/50000 right.\n",
      "Accuracy: 0.3144, Precision: 0.3144, Recall: 1.0, F1 Score: 0.47839318320146074\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.6124024804960992\n",
      "0.9737277353689567\n",
      "Model got 39899/50000 right.\n",
      "Accuracy: 0.79798, Precision: 0.6124024804960992, Recall: 0.9737277353689567, F1 Score: 0.7519096156207786\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.8891202932355882\n",
      "0.6789440203562341\n",
      "Model got 43622/50000 right.\n",
      "Accuracy: 0.87244, Precision: 0.8891202932355882, Recall: 0.6789440203562341, F1 Score: 0.769946616649834\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Starting Epoch 3 now\n",
      "vehicle 0 priority: 0.5220588235294118, total priority of subgroup: 1.0\n",
      "vehicle 1 priority: 0.47058823529411764, total priority of subgroup: 1.0\n",
      "vehicle 2 priority: 0.8, total priority of subgroup: 1.0\n",
      "vehicle 3 priority: 0.8545454545454545, total priority of subgroup: 1.0\n",
      "vehicle 4 priority: 0.5918367346938775, total priority of subgroup: 1.0\n",
      "vehicle 5 priority: 0.17857142857142858, total priority of subgroup: 1.0\n",
      "vehicle 6 priority: 0.054878048780487805, total priority of subgroup: 1.0\n",
      "vehicle 7 priority: 0.17037037037037037, total priority of subgroup: 1.0\n",
      "vehicle 8 priority: 0.12883435582822086, total priority of subgroup: 1.0\n",
      "vehicle 9 priority: 0.8294117647058824, total priority of subgroup: 1.0\n",
      "vehicle 10 priority: 0.12422360248447205, total priority of subgroup: 1.0\n",
      "vehicle 11 priority: 0.9558823529411765, total priority of subgroup: 1.0\n",
      "vehicle 12 priority: 0.6275303643724697, total priority of subgroup: 1.0\n",
      "vehicle 13 priority: 0.4140127388535032, total priority of subgroup: 1.0\n",
      "vehicle 14 priority: 0.7553191489361702, total priority of subgroup: 1.0\n",
      "vehicle 15 priority: 0.5815450643776824, total priority of subgroup: 1.0\n",
      "vehicle 16 priority: 0.11875, total priority of subgroup: 1.0\n",
      "vehicle 17 priority: 0.5490196078431373, total priority of subgroup: 1.0\n",
      "vehicle 18 priority: 0.2727272727272727, total priority of subgroup: 1.0\n",
      "vehicle 19 priority: 0.2033898305084746, total priority of subgroup: 1.0\n",
      "vehicle 20 priority: 0.8, total priority of subgroup: 1.0\n",
      "vehicle 21 priority: 0.4421052631578947, total priority of subgroup: 1.0\n",
      "vehicle 22 priority: 0.4444444444444444, total priority of subgroup: 1.0\n",
      "vehicle 23 priority: 0.22826086956521738, total priority of subgroup: 1.0\n",
      "vehicle 24 priority: 0.29770992366412213, total priority of subgroup: 1.0\n",
      "vehicle 25 priority: 0.1712538226299694, total priority of subgroup: 1.0\n",
      "vehicle 26 priority: 0.9215686274509803, total priority of subgroup: 1.0\n",
      "vehicle 27 priority: 0.09090909090909091, total priority of subgroup: 1.0\n",
      "vehicle 28 priority: 0.7162162162162162, total priority of subgroup: 1.0\n",
      "vehicle 29 priority: 0.2911392405063291, total priority of subgroup: 1.0\n",
      "Epoch 119: 100%|██████████| 2/2 [00:00<00:00, 48.50it/s, v_num=2480, trainLoss=3.110]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 2/2 [00:00<00:00, 42.61it/s, v_num=2480, trainLoss=3.110]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 46.10it/s, v_num=2480, trainLoss=1.910]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 40.82it/s, v_num=2480, trainLoss=1.910]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 48.29it/s, v_num=2481, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 38.02it/s, v_num=2481, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 50.54it/s, v_num=2481, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 39.35it/s, v_num=2481, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 2/2 [00:00<00:00, 50.59it/s, v_num=2482, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 2/2 [00:00<00:00, 43.20it/s, v_num=2482, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 38.90it/s, v_num=2483, trainLoss=2.860]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 31.37it/s, v_num=2483, trainLoss=2.860]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.31634615384615383, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 40.43it/s, v_num=2483, trainLoss=2.860]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 31.60it/s, v_num=2483, trainLoss=2.860]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 45.51it/s, v_num=2484, trainLoss=2.950]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 35.43it/s, v_num=2484, trainLoss=2.950]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 51.42it/s, v_num=2485, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 39.42it/s, v_num=2485, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 49.54it/s, v_num=2486, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 38.75it/s, v_num=2486, trainLoss=9.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 49.45it/s, v_num=2486, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 38.85it/s, v_num=2486, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 47.87it/s, v_num=2487, trainLoss=2.360]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 36.77it/s, v_num=2487, trainLoss=2.360]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.31634615384615383\n",
      "Loading From Backup\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 45.73it/s, v_num=2487, trainLoss=2.200]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 35.19it/s, v_num=2487, trainLoss=2.200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 47.32it/s, v_num=2488, trainLoss=2.940]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 36.12it/s, v_num=2488, trainLoss=2.940]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 149: 100%|██████████| 5/5 [00:00<00:00, 45.90it/s, v_num=2489, trainLoss=2.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 5/5 [00:00<00:00, 43.46it/s, v_num=2489, trainLoss=2.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 179: 100%|██████████| 5/5 [00:00<00:00, 45.34it/s, v_num=2489, trainLoss=3.230]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 5/5 [00:00<00:00, 42.71it/s, v_num=2489, trainLoss=3.230]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 43.33it/s, v_num=2490, trainLoss=3.250]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 34.32it/s, v_num=2490, trainLoss=3.250]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 119: 100%|██████████| 4/4 [00:00<00:00, 46.51it/s, v_num=2491, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 4/4 [00:00<00:00, 43.43it/s, v_num=2491, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 119: 100%|██████████| 3/3 [00:00<00:00, 44.66it/s, v_num=2492, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 3/3 [00:00<00:00, 40.44it/s, v_num=2492, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 149: 100%|██████████| 3/3 [00:00<00:00, 49.98it/s, v_num=2492, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 3/3 [00:00<00:00, 44.84it/s, v_num=2492, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 53.94it/s, v_num=2493, trainLoss=4.960]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 45.88it/s, v_num=2493, trainLoss=4.960]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.31634615384615383\n",
      "Loading From Backup\n",
      "Epoch 179: 100%|██████████| 2/2 [00:00<00:00, 54.80it/s, v_num=2493, trainLoss=2.280]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 2/2 [00:00<00:00, 46.77it/s, v_num=2493, trainLoss=2.280]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 3/3 [00:00<00:00, 47.85it/s, v_num=2494, trainLoss=1.760]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 3/3 [00:00<00:00, 43.85it/s, v_num=2494, trainLoss=1.760]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 119: 100%|██████████| 5/5 [00:00<00:00, 50.57it/s, v_num=2495, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 5/5 [00:00<00:00, 47.69it/s, v_num=2495, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 49.96it/s, v_num=2496, trainLoss=4.260]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 38.87it/s, v_num=2496, trainLoss=4.260]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 119: 100%|██████████| 2/2 [00:00<00:00, 50.08it/s, v_num=2497, trainLoss=1.790]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 2/2 [00:00<00:00, 43.74it/s, v_num=2497, trainLoss=1.790]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.8576442307692308, Current Acc: 0.6836538461538462\n",
      "Loading From Backup\n",
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 49.22it/s, v_num=2497, trainLoss=2.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 42.62it/s, v_num=2497, trainLoss=2.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 51.09it/s, v_num=2498, trainLoss=6.360]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 39.73it/s, v_num=2498, trainLoss=6.360]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 50.65it/s, v_num=2499, trainLoss=4.210]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 43.97it/s, v_num=2499, trainLoss=4.210]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 48.31it/s, v_num=2500, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 37.46it/s, v_num=2500, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 42.14it/s, v_num=2501, trainLoss=4.150]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 33.51it/s, v_num=2501, trainLoss=4.150]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 53.95it/s, v_num=2502, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 40.22it/s, v_num=2502, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 52.50it/s, v_num=2502, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 39.83it/s, v_num=2502, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 50.80it/s, v_num=2503, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 39.50it/s, v_num=2503, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.31634615384615383\n",
      "Loading From Backup\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 49.59it/s, v_num=2503, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 39.05it/s, v_num=2503, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 40.75it/s, v_num=2504, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 32.75it/s, v_num=2504, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 44.90it/s, v_num=2505, trainLoss=8.690]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 35.12it/s, v_num=2505, trainLoss=8.690]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.31634615384615383\n",
      "Loading From Backup\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 47.07it/s, v_num=2505, trainLoss=10.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 36.60it/s, v_num=2505, trainLoss=10.60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 44.45it/s, v_num=2506, trainLoss=2.890]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 35.08it/s, v_num=2506, trainLoss=2.890]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 53.11it/s, v_num=2507, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 39.59it/s, v_num=2507, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 47.57it/s, v_num=2508, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=120` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 36.79it/s, v_num=2508, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 47.99it/s, v_num=2508, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 37.95it/s, v_num=2508, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 40.70it/s, v_num=2509, trainLoss=5.030]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 32.94it/s, v_num=2509, trainLoss=5.030]\n",
      "torch.Size([2080, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.3144\n",
      "1.0\n",
      "Model got 15720/50000 right.\n",
      "Accuracy: 0.3144, Precision: 0.3144, Recall: 1.0, F1 Score: 0.47839318320146074\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.3144\n",
      "1.0\n",
      "Model got 15720/50000 right.\n",
      "Accuracy: 0.3144, Precision: 0.3144, Recall: 1.0, F1 Score: 0.47839318320146074\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Starting Epoch 4 now\n",
      "vehicle 0 priority: 0.6283185840707964, total priority of subgroup: 1.0\n",
      "vehicle 1 priority: 0.25806451612903225, total priority of subgroup: 1.0\n",
      "vehicle 2 priority: 0.7022900763358778, total priority of subgroup: 1.0\n",
      "vehicle 3 priority: 0.6714285714285714, total priority of subgroup: 1.0\n",
      "vehicle 4 priority: 0.8787878787878788, total priority of subgroup: 1.0\n",
      "vehicle 5 priority: 0.38461538461538464, total priority of subgroup: 1.0\n",
      "vehicle 6 priority: 0.1875, total priority of subgroup: 1.0\n",
      "vehicle 7 priority: 0.35384615384615387, total priority of subgroup: 1.0\n",
      "vehicle 8 priority: 0.22826086956521738, total priority of subgroup: 1.0\n",
      "vehicle 9 priority: 0.8417910447761194, total priority of subgroup: 1.0\n",
      "vehicle 10 priority: 0.12861736334405144, total priority of subgroup: 1.0\n",
      "vehicle 11 priority: 0.7330827067669173, total priority of subgroup: 1.0\n",
      "vehicle 12 priority: 0.7673267326732673, total priority of subgroup: 1.0\n",
      "vehicle 13 priority: 0.5803571428571429, total priority of subgroup: 1.0\n",
      "vehicle 14 priority: 0.9466666666666667, total priority of subgroup: 1.0\n",
      "vehicle 15 priority: 0.8548895899053628, total priority of subgroup: 1.0\n",
      "vehicle 16 priority: 0.40425531914893614, total priority of subgroup: 1.0\n",
      "vehicle 17 priority: 0.8296296296296296, total priority of subgroup: 1.0\n",
      "vehicle 18 priority: 0.09554140127388536, total priority of subgroup: 1.0\n",
      "vehicle 19 priority: 0.8275862068965517, total priority of subgroup: 1.0\n",
      "vehicle 20 priority: 0.6153846153846154, total priority of subgroup: 1.0\n",
      "vehicle 21 priority: 0.6666666666666666, total priority of subgroup: 1.0\n",
      "vehicle 22 priority: 0.25806451612903225, total priority of subgroup: 1.0\n",
      "vehicle 23 priority: 0.4772727272727273, total priority of subgroup: 1.0\n",
      "vehicle 24 priority: 0.8125, total priority of subgroup: 1.0\n",
      "vehicle 25 priority: 0.7088607594936709, total priority of subgroup: 1.0\n",
      "vehicle 26 priority: 0.6911764705882353, total priority of subgroup: 1.0\n",
      "vehicle 27 priority: 0.16, total priority of subgroup: 1.0\n",
      "vehicle 28 priority: 0.7681159420289855, total priority of subgroup: 1.0\n",
      "vehicle 29 priority: 0.7419354838709677, total priority of subgroup: 1.0\n",
      "Epoch 179: 100%|██████████| 2/2 [00:00<00:00, 54.86it/s, v_num=2480, trainLoss=2.780]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 2/2 [00:00<00:00, 47.55it/s, v_num=2480, trainLoss=2.780]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 48.87it/s, v_num=2481, trainLoss=4.300]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 38.33it/s, v_num=2481, trainLoss=4.300]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 52.70it/s, v_num=2482, trainLoss=2.770]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 45.08it/s, v_num=2482, trainLoss=2.770]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 41.51it/s, v_num=2483, trainLoss=2.150]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 33.10it/s, v_num=2483, trainLoss=2.150]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 40.51it/s, v_num=2484, trainLoss=2.780]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 32.28it/s, v_num=2484, trainLoss=2.780]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 47.67it/s, v_num=2485, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 37.46it/s, v_num=2485, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 47.23it/s, v_num=2486, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 37.20it/s, v_num=2486, trainLoss=9.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 41.18it/s, v_num=2487, trainLoss=5.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 32.34it/s, v_num=2487, trainLoss=5.460]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 47.80it/s, v_num=2488, trainLoss=2.210]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 36.82it/s, v_num=2488, trainLoss=2.210]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.31634615384615383\n",
      "Loading From Backup\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 42.29it/s, v_num=2488, trainLoss=1.990]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 33.60it/s, v_num=2488, trainLoss=1.990]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 5/5 [00:00<00:00, 48.99it/s, v_num=2489, trainLoss=2.070]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 5/5 [00:00<00:00, 46.15it/s, v_num=2489, trainLoss=2.070]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 52.03it/s, v_num=2490, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 39.46it/s, v_num=2490, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 149: 100%|██████████| 4/4 [00:00<00:00, 56.88it/s, v_num=2491, trainLoss=0.696]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 4/4 [00:00<00:00, 52.66it/s, v_num=2491, trainLoss=0.696]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 179: 100%|██████████| 3/3 [00:00<00:00, 54.58it/s, v_num=2492, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 3/3 [00:00<00:00, 49.40it/s, v_num=2492, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 209: 100%|██████████| 2/2 [00:00<00:00, 57.95it/s, v_num=2493, trainLoss=8.110]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 2/2 [00:00<00:00, 49.33it/s, v_num=2493, trainLoss=8.110]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 179: 100%|██████████| 3/3 [00:00<00:00, 54.05it/s, v_num=2494, trainLoss=1.600]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 3/3 [00:00<00:00, 49.22it/s, v_num=2494, trainLoss=1.600]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 209: 100%|██████████| 3/3 [00:00<00:00, 54.38it/s, v_num=2494, trainLoss=3.800]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 3/3 [00:00<00:00, 49.49it/s, v_num=2494, trainLoss=3.800]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 5/5 [00:00<00:00, 54.53it/s, v_num=2495, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 5/5 [00:00<00:00, 51.43it/s, v_num=2495, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 49.15it/s, v_num=2496, trainLoss=9.100]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 38.43it/s, v_num=2496, trainLoss=9.100]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 179: 100%|██████████| 2/2 [00:00<00:00, 51.96it/s, v_num=2497, trainLoss=3.410]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 2/2 [00:00<00:00, 45.25it/s, v_num=2497, trainLoss=3.410]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.31634615384615383\n",
      "Loading From Backup\n",
      "Epoch 209: 100%|██████████| 2/2 [00:00<00:00, 49.51it/s, v_num=2497, trainLoss=0.846]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 2/2 [00:00<00:00, 42.93it/s, v_num=2497, trainLoss=0.846]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 52.65it/s, v_num=2498, trainLoss=2.810]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 40.63it/s, v_num=2498, trainLoss=2.810]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 179: 100%|██████████| 2/2 [00:00<00:00, 56.05it/s, v_num=2499, trainLoss=5.010]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 2/2 [00:00<00:00, 48.57it/s, v_num=2499, trainLoss=5.010]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 54.46it/s, v_num=2500, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 42.10it/s, v_num=2500, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 51.22it/s, v_num=2501, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 39.77it/s, v_num=2501, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 52.92it/s, v_num=2502, trainLoss=6.840]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 41.02it/s, v_num=2502, trainLoss=6.840]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 49.56it/s, v_num=2503, trainLoss=5.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 38.34it/s, v_num=2503, trainLoss=5.460]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.31634615384615383, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 45.07it/s, v_num=2503, trainLoss=2.950]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 36.07it/s, v_num=2503, trainLoss=2.950]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 48.47it/s, v_num=2504, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 38.16it/s, v_num=2504, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 47.69it/s, v_num=2505, trainLoss=9.610]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 37.50it/s, v_num=2505, trainLoss=9.610]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 43.94it/s, v_num=2506, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 35.09it/s, v_num=2506, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 55.16it/s, v_num=2507, trainLoss=2.710]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 42.22it/s, v_num=2507, trainLoss=2.710]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 52.40it/s, v_num=2508, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 40.87it/s, v_num=2508, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 50.05it/s, v_num=2509, trainLoss=2.780]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 39.38it/s, v_num=2509, trainLoss=2.780]\n",
      "torch.Size([2080, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.3144\n",
      "1.0\n",
      "Model got 15720/50000 right.\n",
      "Accuracy: 0.3144, Precision: 0.3144, Recall: 1.0, F1 Score: 0.47839318320146074\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Starting Epoch 5 now\n",
      "vehicle 0 priority: 0.7717391304347826, total priority of subgroup: 1.0\n",
      "vehicle 1 priority: 0.17391304347826086, total priority of subgroup: 1.0\n",
      "vehicle 2 priority: 0.9583333333333334, total priority of subgroup: 1.0\n",
      "vehicle 3 priority: 0.8392857142857143, total priority of subgroup: 1.0\n",
      "vehicle 4 priority: 0.5576923076923077, total priority of subgroup: 1.0\n",
      "vehicle 5 priority: 0.17543859649122806, total priority of subgroup: 1.0\n",
      "vehicle 6 priority: 0.5294117647058824, total priority of subgroup: 1.0\n",
      "vehicle 7 priority: 0.0782312925170068, total priority of subgroup: 1.0\n",
      "vehicle 8 priority: 0.84, total priority of subgroup: 1.0\n",
      "vehicle 9 priority: 0.9657534246575342, total priority of subgroup: 1.0\n",
      "vehicle 10 priority: 0.30303030303030304, total priority of subgroup: 1.0\n",
      "vehicle 11 priority: 0.8227848101265823, total priority of subgroup: 1.0\n",
      "vehicle 12 priority: 0.6858407079646017, total priority of subgroup: 1.0\n",
      "vehicle 13 priority: 0.8666666666666667, total priority of subgroup: 1.0\n",
      "vehicle 14 priority: 0.7845303867403315, total priority of subgroup: 1.0\n",
      "vehicle 15 priority: 0.8522012578616353, total priority of subgroup: 1.0\n",
      "vehicle 16 priority: 0.4523809523809524, total priority of subgroup: 1.0\n",
      "vehicle 17 priority: 0.6120218579234973, total priority of subgroup: 1.0\n",
      "vehicle 18 priority: 0.24193548387096775, total priority of subgroup: 1.0\n",
      "vehicle 19 priority: 0.5255474452554745, total priority of subgroup: 1.0\n",
      "vehicle 20 priority: 0.2222222222222222, total priority of subgroup: 1.0\n",
      "vehicle 21 priority: 0.3925233644859813, total priority of subgroup: 1.0\n",
      "vehicle 22 priority: 0.1702127659574468, total priority of subgroup: 1.0\n",
      "vehicle 23 priority: 0.84, total priority of subgroup: 1.0\n",
      "vehicle 24 priority: 0.65, total priority of subgroup: 1.0\n",
      "vehicle 25 priority: 0.3783783783783784, total priority of subgroup: 1.0\n",
      "vehicle 26 priority: 0.5280898876404494, total priority of subgroup: 1.0\n",
      "vehicle 27 priority: 0.020100502512562814, total priority of subgroup: 1.0\n",
      "vehicle 28 priority: 0.53, total priority of subgroup: 1.0\n",
      "vehicle 29 priority: 0.6666666666666666, total priority of subgroup: 1.0\n",
      "Epoch 209: 100%|██████████| 2/2 [00:00<00:00, 58.72it/s, v_num=2480, trainLoss=0.696]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 2/2 [00:00<00:00, 50.11it/s, v_num=2480, trainLoss=0.696]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 239: 100%|██████████| 2/2 [00:00<00:00, 59.93it/s, v_num=2480, trainLoss=5.200]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 2/2 [00:00<00:00, 51.44it/s, v_num=2480, trainLoss=5.200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 48.60it/s, v_num=2481, trainLoss=0.790]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 38.35it/s, v_num=2481, trainLoss=0.790]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 179: 100%|██████████| 2/2 [00:00<00:00, 54.03it/s, v_num=2482, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 2/2 [00:00<00:00, 46.85it/s, v_num=2482, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 50.26it/s, v_num=2483, trainLoss=1.900]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 37.33it/s, v_num=2483, trainLoss=1.900]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 50.63it/s, v_num=2484, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 39.20it/s, v_num=2484, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 56.03it/s, v_num=2485, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 42.45it/s, v_num=2485, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 50.37it/s, v_num=2486, trainLoss=9.370]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 39.46it/s, v_num=2486, trainLoss=9.370]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 44.84it/s, v_num=2487, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 35.40it/s, v_num=2487, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 45.41it/s, v_num=2488, trainLoss=3.620]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 35.71it/s, v_num=2488, trainLoss=3.620]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 239: 100%|██████████| 5/5 [00:00<00:00, 58.75it/s, v_num=2489, trainLoss=2.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 5/5 [00:00<00:00, 54.89it/s, v_num=2489, trainLoss=2.460]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 44.75it/s, v_num=2490, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 35.60it/s, v_num=2490, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 179: 100%|██████████| 4/4 [00:00<00:00, 57.64it/s, v_num=2491, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 4/4 [00:00<00:00, 53.32it/s, v_num=2491, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 209: 100%|██████████| 3/3 [00:00<00:00, 55.85it/s, v_num=2492, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 3/3 [00:00<00:00, 50.28it/s, v_num=2492, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 239: 100%|██████████| 2/2 [00:00<00:00, 58.65it/s, v_num=2493, trainLoss=2.770]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 2/2 [00:00<00:00, 50.01it/s, v_num=2493, trainLoss=2.770]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 269: 100%|██████████| 2/2 [00:00<00:00, 58.80it/s, v_num=2493, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 2/2 [00:00<00:00, 50.19it/s, v_num=2493, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 3/3 [00:00<00:00, 55.25it/s, v_num=2494, trainLoss=2.650]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 3/3 [00:00<00:00, 50.30it/s, v_num=2494, trainLoss=2.650]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 179: 100%|██████████| 5/5 [00:00<00:00, 58.15it/s, v_num=2495, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 5/5 [00:00<00:00, 54.77it/s, v_num=2495, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 52.57it/s, v_num=2496, trainLoss=0.765]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 40.92it/s, v_num=2496, trainLoss=0.765]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 239: 100%|██████████| 2/2 [00:00<00:00, 52.79it/s, v_num=2497, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 2/2 [00:00<00:00, 45.92it/s, v_num=2497, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.31634615384615383, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 269: 100%|██████████| 2/2 [00:00<00:00, 51.18it/s, v_num=2497, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 2/2 [00:00<00:00, 44.60it/s, v_num=2497, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 54.39it/s, v_num=2498, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 41.60it/s, v_num=2498, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 209: 100%|██████████| 2/2 [00:00<00:00, 58.97it/s, v_num=2499, trainLoss=6.500]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 2/2 [00:00<00:00, 50.58it/s, v_num=2499, trainLoss=6.500]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 55.14it/s, v_num=2500, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 42.21it/s, v_num=2500, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 51.09it/s, v_num=2501, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 39.62it/s, v_num=2501, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 48.44it/s, v_num=2501, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 37.98it/s, v_num=2501, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 57.77it/s, v_num=2502, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 43.95it/s, v_num=2502, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 44.85it/s, v_num=2503, trainLoss=5.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 35.33it/s, v_num=2503, trainLoss=5.460]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 46.99it/s, v_num=2504, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 37.26it/s, v_num=2504, trainLoss=9.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.31634615384615383\n",
      "Loading From Backup\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 51.30it/s, v_num=2504, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 39.71it/s, v_num=2504, trainLoss=9.390]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 48.56it/s, v_num=2505, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 38.21it/s, v_num=2505, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 50.44it/s, v_num=2506, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 39.08it/s, v_num=2506, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 54.29it/s, v_num=2507, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 41.56it/s, v_num=2507, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 43.86it/s, v_num=2508, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 34.59it/s, v_num=2508, trainLoss=9.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 47.03it/s, v_num=2508, trainLoss=5.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 37.38it/s, v_num=2508, trainLoss=5.460]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 51.15it/s, v_num=2509, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 39.73it/s, v_num=2509, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.3144\n",
      "1.0\n",
      "Model got 15720/50000 right.\n",
      "Accuracy: 0.3144, Precision: 0.3144, Recall: 1.0, F1 Score: 0.47839318320146074\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Starting Epoch 6 now\n",
      "vehicle 0 priority: 0.4965034965034965, total priority of subgroup: 1.0\n",
      "vehicle 1 priority: 0.14814814814814814, total priority of subgroup: 1.0\n",
      "vehicle 2 priority: 0.9108910891089109, total priority of subgroup: 1.0\n",
      "vehicle 3 priority: 0.23267326732673269, total priority of subgroup: 1.0\n",
      "vehicle 4 priority: 0.5087719298245614, total priority of subgroup: 1.0\n",
      "vehicle 5 priority: 0.06060606060606061, total priority of subgroup: 1.0\n",
      "vehicle 6 priority: 0.13846153846153847, total priority of subgroup: 1.0\n",
      "vehicle 7 priority: 0.7419354838709677, total priority of subgroup: 1.0\n",
      "vehicle 8 priority: 0.5833333333333334, total priority of subgroup: 1.0\n",
      "vehicle 9 priority: 0.7157360406091371, total priority of subgroup: 1.0\n",
      "vehicle 10 priority: 0.46511627906976744, total priority of subgroup: 1.0\n",
      "vehicle 11 priority: 0.8091286307053942, total priority of subgroup: 1.0\n",
      "vehicle 12 priority: 0.7673267326732673, total priority of subgroup: 1.0\n",
      "vehicle 13 priority: 0.5803571428571429, total priority of subgroup: 1.0\n",
      "vehicle 14 priority: 0.4781144781144781, total priority of subgroup: 1.0\n",
      "vehicle 15 priority: 0.6561743341404358, total priority of subgroup: 1.0\n",
      "vehicle 16 priority: 0.2923076923076923, total priority of subgroup: 1.0\n",
      "vehicle 17 priority: 0.28426395939086296, total priority of subgroup: 1.0\n",
      "vehicle 18 priority: 0.6521739130434783, total priority of subgroup: 1.0\n",
      "vehicle 19 priority: 0.6101694915254238, total priority of subgroup: 1.0\n",
      "vehicle 20 priority: 0.0935672514619883, total priority of subgroup: 1.0\n",
      "vehicle 21 priority: 0.5185185185185185, total priority of subgroup: 1.0\n",
      "vehicle 22 priority: 0.10126582278481013, total priority of subgroup: 1.0\n",
      "vehicle 23 priority: 0.7241379310344828, total priority of subgroup: 1.0\n",
      "vehicle 24 priority: 0.12149532710280374, total priority of subgroup: 1.0\n",
      "vehicle 25 priority: 0.7777777777777778, total priority of subgroup: 1.0\n",
      "vehicle 26 priority: 0.5465116279069767, total priority of subgroup: 1.0\n",
      "vehicle 27 priority: 0.07017543859649122, total priority of subgroup: 1.0\n",
      "vehicle 28 priority: 0.2548076923076923, total priority of subgroup: 1.0\n",
      "vehicle 29 priority: 0.3333333333333333, total priority of subgroup: 1.0\n",
      "Epoch 269: 100%|██████████| 2/2 [00:00<00:00, 58.06it/s, v_num=2480, trainLoss=2.110]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 2/2 [00:00<00:00, 49.73it/s, v_num=2480, trainLoss=2.110]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 57.23it/s, v_num=2481, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 43.66it/s, v_num=2481, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.31634615384615383\n",
      "Loading From Backup\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 55.94it/s, v_num=2481, trainLoss=4.240]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 42.66it/s, v_num=2481, trainLoss=4.240]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 2/2 [00:00<00:00, 55.21it/s, v_num=2482, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 2/2 [00:00<00:00, 47.76it/s, v_num=2482, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 47.92it/s, v_num=2483, trainLoss=2.770]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 37.28it/s, v_num=2483, trainLoss=2.770]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 31.48it/s, v_num=2484, trainLoss=2.780]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 24.87it/s, v_num=2484, trainLoss=2.780]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 51.45it/s, v_num=2485, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 36.59it/s, v_num=2485, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 46.97it/s, v_num=2486, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 36.62it/s, v_num=2486, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 49.66it/s, v_num=2487, trainLoss=2.770]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 38.65it/s, v_num=2487, trainLoss=2.770]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 49.35it/s, v_num=2488, trainLoss=0.693]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 37.84it/s, v_num=2488, trainLoss=0.693]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.31634615384615383\n",
      "Loading From Backup\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 49.42it/s, v_num=2488, trainLoss=0.694]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 38.74it/s, v_num=2488, trainLoss=0.694]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 5/5 [00:00<00:00, 55.14it/s, v_num=2489, trainLoss=1.410]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 5/5 [00:00<00:00, 51.79it/s, v_num=2489, trainLoss=1.410]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 42.60it/s, v_num=2490, trainLoss=4.110]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 33.88it/s, v_num=2490, trainLoss=4.110]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 209: 100%|██████████| 4/4 [00:00<00:00, 52.22it/s, v_num=2491, trainLoss=6.400]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 4/4 [00:00<00:00, 48.76it/s, v_num=2491, trainLoss=6.400]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 239: 100%|██████████| 3/3 [00:00<00:00, 47.59it/s, v_num=2492, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 3/3 [00:00<00:00, 43.10it/s, v_num=2492, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 299: 100%|██████████| 2/2 [00:00<00:00, 53.06it/s, v_num=2493, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 2/2 [00:00<00:00, 46.23it/s, v_num=2493, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 269: 100%|██████████| 3/3 [00:00<00:00, 55.78it/s, v_num=2494, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 3/3 [00:00<00:00, 50.41it/s, v_num=2494, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 209: 100%|██████████| 5/5 [00:00<00:00, 45.84it/s, v_num=2495, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 5/5 [00:00<00:00, 43.18it/s, v_num=2495, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 239: 100%|██████████| 5/5 [00:00<00:00, 58.22it/s, v_num=2495, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 5/5 [00:00<00:00, 54.68it/s, v_num=2495, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 47.39it/s, v_num=2496, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 36.92it/s, v_num=2496, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 299: 100%|██████████| 2/2 [00:00<00:00, 50.39it/s, v_num=2497, trainLoss=2.780]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 2/2 [00:00<00:00, 43.89it/s, v_num=2497, trainLoss=2.780]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 54.25it/s, v_num=2498, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 40.84it/s, v_num=2498, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 239: 100%|██████████| 2/2 [00:00<00:00, 55.17it/s, v_num=2499, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 2/2 [00:00<00:00, 47.86it/s, v_num=2499, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 269: 100%|██████████| 2/2 [00:00<00:00, 53.26it/s, v_num=2499, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 2/2 [00:00<00:00, 46.33it/s, v_num=2499, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 53.60it/s, v_num=2500, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 41.27it/s, v_num=2500, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 43.64it/s, v_num=2501, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 34.69it/s, v_num=2501, trainLoss=9.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 54.57it/s, v_num=2502, trainLoss=1.660]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 41.23it/s, v_num=2502, trainLoss=1.660]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 46.33it/s, v_num=2503, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 36.46it/s, v_num=2503, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 49.48it/s, v_num=2504, trainLoss=1.580]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 38.93it/s, v_num=2504, trainLoss=1.580]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 37.75it/s, v_num=2505, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 30.17it/s, v_num=2505, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 42.00it/s, v_num=2506, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 33.70it/s, v_num=2506, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 55.19it/s, v_num=2507, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=210` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 42.13it/s, v_num=2507, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 46.26it/s, v_num=2508, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 36.07it/s, v_num=2508, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 41.63it/s, v_num=2509, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 33.09it/s, v_num=2509, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Starting Epoch 7 now\n",
      "vehicle 0 priority: 0.5503875968992248, total priority of subgroup: 1.0\n",
      "vehicle 1 priority: 0.3333333333333333, total priority of subgroup: 1.0\n",
      "vehicle 2 priority: 0.6618705035971223, total priority of subgroup: 1.0\n",
      "vehicle 3 priority: 0.41964285714285715, total priority of subgroup: 1.0\n",
      "vehicle 4 priority: 0.3411764705882353, total priority of subgroup: 1.0\n",
      "vehicle 5 priority: 0.30303030303030304, total priority of subgroup: 1.0\n",
      "vehicle 6 priority: 0.3, total priority of subgroup: 1.0\n",
      "vehicle 7 priority: 0.5227272727272727, total priority of subgroup: 1.0\n",
      "vehicle 8 priority: 0.28378378378378377, total priority of subgroup: 1.0\n",
      "vehicle 9 priority: 0.9724137931034482, total priority of subgroup: 1.0\n",
      "vehicle 10 priority: 0.7272727272727273, total priority of subgroup: 1.0\n",
      "vehicle 11 priority: 0.4184549356223176, total priority of subgroup: 1.0\n",
      "vehicle 12 priority: 0.36384976525821594, total priority of subgroup: 1.0\n",
      "vehicle 13 priority: 0.7558139534883721, total priority of subgroup: 1.0\n",
      "vehicle 14 priority: 0.6859903381642513, total priority of subgroup: 1.0\n",
      "vehicle 15 priority: 0.636150234741784, total priority of subgroup: 1.0\n",
      "vehicle 16 priority: 0.6440677966101694, total priority of subgroup: 1.0\n",
      "vehicle 17 priority: 0.875, total priority of subgroup: 1.0\n",
      "vehicle 18 priority: 0.07142857142857142, total priority of subgroup: 1.0\n",
      "vehicle 19 priority: 0.7741935483870968, total priority of subgroup: 1.0\n",
      "vehicle 20 priority: 0.25396825396825395, total priority of subgroup: 1.0\n",
      "vehicle 21 priority: 0.84, total priority of subgroup: 1.0\n",
      "vehicle 22 priority: 0.16, total priority of subgroup: 1.0\n",
      "vehicle 23 priority: 0.2441860465116279, total priority of subgroup: 1.0\n",
      "vehicle 24 priority: 0.12580645161290321, total priority of subgroup: 1.0\n",
      "vehicle 25 priority: 0.16568047337278108, total priority of subgroup: 1.0\n",
      "vehicle 26 priority: 0.47, total priority of subgroup: 1.0\n",
      "vehicle 27 priority: 0.05333333333333334, total priority of subgroup: 1.0\n",
      "vehicle 28 priority: 0.4774774774774775, total priority of subgroup: 1.0\n",
      "vehicle 29 priority: 0.8214285714285714, total priority of subgroup: 1.0\n",
      "Epoch 299: 100%|██████████| 2/2 [00:00<00:00, 54.75it/s, v_num=2480, trainLoss=2.780]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 2/2 [00:00<00:00, 47.35it/s, v_num=2480, trainLoss=2.780]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 49.34it/s, v_num=2481, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 38.54it/s, v_num=2481, trainLoss=9.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 239: 100%|██████████| 2/2 [00:00<00:00, 51.64it/s, v_num=2482, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 2/2 [00:00<00:00, 44.56it/s, v_num=2482, trainLoss=9.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 48.07it/s, v_num=2483, trainLoss=2.770]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 37.67it/s, v_num=2483, trainLoss=2.770]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 47.41it/s, v_num=2484, trainLoss=2.840]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 37.42it/s, v_num=2484, trainLoss=2.840]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 46.61it/s, v_num=2484, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 35.88it/s, v_num=2484, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 49.08it/s, v_num=2485, trainLoss=2.770]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 38.05it/s, v_num=2485, trainLoss=2.770]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 51.09it/s, v_num=2486, trainLoss=6.280]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 38.99it/s, v_num=2486, trainLoss=6.280]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 46.02it/s, v_num=2487, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 36.22it/s, v_num=2487, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 48.48it/s, v_num=2487, trainLoss=2.780]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 37.51it/s, v_num=2487, trainLoss=2.780]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 47.58it/s, v_num=2488, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 37.40it/s, v_num=2488, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 299: 100%|██████████| 5/5 [00:00<00:00, 54.13it/s, v_num=2489, trainLoss=5.030]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 5/5 [00:00<00:00, 50.95it/s, v_num=2489, trainLoss=5.030]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 43.71it/s, v_num=2490, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 34.67it/s, v_num=2490, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 239: 100%|██████████| 4/4 [00:00<00:00, 57.12it/s, v_num=2491, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 4/4 [00:00<00:00, 52.92it/s, v_num=2491, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 269: 100%|██████████| 3/3 [00:00<00:00, 53.40it/s, v_num=2492, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 3/3 [00:00<00:00, 48.33it/s, v_num=2492, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 299: 100%|██████████| 3/3 [00:00<00:00, 54.49it/s, v_num=2492, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 3/3 [00:00<00:00, 49.14it/s, v_num=2492, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 2/2 [00:00<00:00, 55.63it/s, v_num=2493, trainLoss=8.110]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 2/2 [00:00<00:00, 47.99it/s, v_num=2493, trainLoss=8.110]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 299: 100%|██████████| 3/3 [00:00<00:00, 55.99it/s, v_num=2494, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 3/3 [00:00<00:00, 50.83it/s, v_num=2494, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 269: 100%|██████████| 5/5 [00:00<00:00, 50.36it/s, v_num=2495, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 5/5 [00:00<00:00, 47.24it/s, v_num=2495, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 37.85it/s, v_num=2496, trainLoss=2.770]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 27.02it/s, v_num=2496, trainLoss=2.770]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 329: 100%|██████████| 2/2 [00:00<00:00, 49.77it/s, v_num=2497, trainLoss=6.220]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 2/2 [00:00<00:00, 42.96it/s, v_num=2497, trainLoss=6.220]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 359: 100%|██████████| 2/2 [00:00<00:00, 42.44it/s, v_num=2497, trainLoss=2.840]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 2/2 [00:00<00:00, 37.19it/s, v_num=2497, trainLoss=2.840]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 54.59it/s, v_num=2498, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 41.48it/s, v_num=2498, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 52.29it/s, v_num=2498, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 39.86it/s, v_num=2498, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 2/2 [00:00<00:00, 52.80it/s, v_num=2499, trainLoss=5.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 2/2 [00:00<00:00, 45.92it/s, v_num=2499, trainLoss=5.460]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 44.70it/s, v_num=2500, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 36.06it/s, v_num=2500, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 42.97it/s, v_num=2501, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 34.21it/s, v_num=2501, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 56.47it/s, v_num=2502, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 42.96it/s, v_num=2502, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 51.40it/s, v_num=2503, trainLoss=2.770]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 40.03it/s, v_num=2503, trainLoss=2.770]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 42.57it/s, v_num=2503, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 31.44it/s, v_num=2503, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 50.14it/s, v_num=2504, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 38.69it/s, v_num=2504, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 43.72it/s, v_num=2504, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 32.55it/s, v_num=2504, trainLoss=9.390]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 43.52it/s, v_num=2505, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 34.22it/s, v_num=2505, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 44.59it/s, v_num=2506, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 34.63it/s, v_num=2506, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 49.59it/s, v_num=2506, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 38.55it/s, v_num=2506, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 55.69it/s, v_num=2507, trainLoss=5.200]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=240` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 42.17it/s, v_num=2507, trainLoss=5.200]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 52.26it/s, v_num=2507, trainLoss=2.320]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 40.13it/s, v_num=2507, trainLoss=2.320]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 47.45it/s, v_num=2508, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 37.23it/s, v_num=2508, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 50.73it/s, v_num=2509, trainLoss=2.770]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 39.09it/s, v_num=2509, trainLoss=2.770]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 40.79it/s, v_num=2509, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 32.17it/s, v_num=2509, trainLoss=3.000]\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.3144\n",
      "1.0\n",
      "Model got 15720/50000 right.\n",
      "Accuracy: 0.3144, Precision: 0.3144, Recall: 1.0, F1 Score: 0.47839318320146074\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.3144\n",
      "1.0\n",
      "Model got 15720/50000 right.\n",
      "Accuracy: 0.3144, Precision: 0.3144, Recall: 1.0, F1 Score: 0.47839318320146074\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Starting Epoch 8 now\n",
      "vehicle 0 priority: 0.9466666666666667, total priority of subgroup: 1.0\n",
      "vehicle 1 priority: 0.027586206896551724, total priority of subgroup: 1.0\n",
      "vehicle 2 priority: 0.5859872611464968, total priority of subgroup: 1.0\n",
      "vehicle 3 priority: 0.5, total priority of subgroup: 1.0\n",
      "vehicle 4 priority: 0.5523809523809524, total priority of subgroup: 1.0\n",
      "vehicle 5 priority: 0.3225806451612903, total priority of subgroup: 1.0\n",
      "vehicle 6 priority: 0.16071428571428573, total priority of subgroup: 1.0\n",
      "vehicle 7 priority: 0.3333333333333333, total priority of subgroup: 1.0\n",
      "vehicle 8 priority: 0.5, total priority of subgroup: 1.0\n",
      "vehicle 9 priority: 0.9494949494949495, total priority of subgroup: 1.0\n",
      "vehicle 10 priority: 0.45977011494252873, total priority of subgroup: 1.0\n",
      "vehicle 11 priority: 0.9605911330049262, total priority of subgroup: 1.0\n",
      "vehicle 12 priority: 0.9451219512195121, total priority of subgroup: 1.0\n",
      "vehicle 13 priority: 0.8904109589041096, total priority of subgroup: 1.0\n",
      "vehicle 14 priority: 0.7171717171717171, total priority of subgroup: 1.0\n",
      "vehicle 15 priority: 0.9442508710801394, total priority of subgroup: 1.0\n",
      "vehicle 16 priority: 0.7916666666666666, total priority of subgroup: 1.0\n",
      "vehicle 17 priority: 0.8818897637795275, total priority of subgroup: 1.0\n",
      "vehicle 18 priority: 0.24193548387096775, total priority of subgroup: 1.0\n",
      "vehicle 19 priority: 0.9473684210526315, total priority of subgroup: 1.0\n",
      "vehicle 20 priority: 0.19753086419753085, total priority of subgroup: 1.0\n",
      "vehicle 21 priority: 0.8235294117647058, total priority of subgroup: 1.0\n",
      "vehicle 22 priority: 0.03940886699507389, total priority of subgroup: 1.0\n",
      "vehicle 23 priority: 0.31343283582089554, total priority of subgroup: 1.0\n",
      "vehicle 24 priority: 0.9069767441860465, total priority of subgroup: 1.0\n",
      "vehicle 25 priority: 0.5436893203883495, total priority of subgroup: 1.0\n",
      "vehicle 26 priority: 0.19421487603305784, total priority of subgroup: 1.0\n",
      "vehicle 27 priority: 0.09302325581395349, total priority of subgroup: 1.0\n",
      "vehicle 28 priority: 0.8688524590163934, total priority of subgroup: 1.0\n",
      "vehicle 29 priority: 0.24468085106382978, total priority of subgroup: 1.0\n",
      "Epoch 329: 100%|██████████| 2/2 [00:00<00:00, 54.17it/s, v_num=2480, trainLoss=5.200]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 2/2 [00:00<00:00, 46.81it/s, v_num=2480, trainLoss=5.200]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 359: 100%|██████████| 2/2 [00:00<00:00, 54.77it/s, v_num=2480, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 2/2 [00:00<00:00, 46.99it/s, v_num=2480, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 53.23it/s, v_num=2481, trainLoss=2.840] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 40.31it/s, v_num=2481, trainLoss=2.840]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 269: 100%|██████████| 2/2 [00:00<00:00, 53.59it/s, v_num=2482, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 2/2 [00:00<00:00, 46.41it/s, v_num=2482, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 47.52it/s, v_num=2483, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 36.83it/s, v_num=2483, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 40.70it/s, v_num=2484, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 32.49it/s, v_num=2484, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 54.82it/s, v_num=2485, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 41.57it/s, v_num=2485, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 51.59it/s, v_num=2486, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 39.30it/s, v_num=2486, trainLoss=9.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.31634615384615383, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 53.74it/s, v_num=2486, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 40.88it/s, v_num=2486, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 49.56it/s, v_num=2487, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 38.08it/s, v_num=2487, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 49.77it/s, v_num=2488, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 38.08it/s, v_num=2488, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 31.18it/s, v_num=2488, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=390` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 25.67it/s, v_num=2488, trainLoss=9.390]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 5/5 [00:00<00:00, 54.18it/s, v_num=2489, trainLoss=6.710]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 5/5 [00:00<00:00, 50.88it/s, v_num=2489, trainLoss=6.710]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 43.30it/s, v_num=2490, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 33.99it/s, v_num=2490, trainLoss=9.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 269: 100%|██████████| 4/4 [00:00<00:00, 57.91it/s, v_num=2491, trainLoss=2.770]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 4/4 [00:00<00:00, 53.54it/s, v_num=2491, trainLoss=2.770]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 299: 100%|██████████| 4/4 [00:00<00:00, 47.17it/s, v_num=2491, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 4/4 [00:00<00:00, 43.95it/s, v_num=2491, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 3/3 [00:00<00:00, 54.86it/s, v_num=2492, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 3/3 [00:00<00:00, 49.46it/s, v_num=2492, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 359: 100%|██████████| 2/2 [00:00<00:00, 53.63it/s, v_num=2493, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 2/2 [00:00<00:00, 46.71it/s, v_num=2493, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 329: 100%|██████████| 3/3 [00:00<00:00, 58.25it/s, v_num=2494, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 3/3 [00:00<00:00, 52.59it/s, v_num=2494, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 359: 100%|██████████| 3/3 [00:00<00:00, 52.56it/s, v_num=2494, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 3/3 [00:00<00:00, 47.85it/s, v_num=2494, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 5/5 [00:00<00:00, 54.62it/s, v_num=2495, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 5/5 [00:00<00:00, 51.51it/s, v_num=2495, trainLoss=9.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 46.37it/s, v_num=2496, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 36.20it/s, v_num=2496, trainLoss=9.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 389: 100%|██████████| 2/2 [00:00<00:00, 53.12it/s, v_num=2497, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=390` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389: 100%|██████████| 2/2 [00:00<00:00, 45.70it/s, v_num=2497, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 49.93it/s, v_num=2498, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 38.88it/s, v_num=2498, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 329: 100%|██████████| 2/2 [00:00<00:00, 54.21it/s, v_num=2499, trainLoss=2.780]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 2/2 [00:00<00:00, 47.00it/s, v_num=2499, trainLoss=2.780]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 55.15it/s, v_num=2500, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=270` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 42.16it/s, v_num=2500, trainLoss=9.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 50.73it/s, v_num=2501, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 39.51it/s, v_num=2501, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 47.40it/s, v_num=2502, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 36.74it/s, v_num=2502, trainLoss=9.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 50.09it/s, v_num=2503, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=390` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 38.21it/s, v_num=2503, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 46.65it/s, v_num=2504, trainLoss=9.100]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 36.40it/s, v_num=2504, trainLoss=9.100]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 46.70it/s, v_num=2505, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 35.93it/s, v_num=2505, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 45.66it/s, v_num=2506, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 35.40it/s, v_num=2506, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 49.71it/s, v_num=2507, trainLoss=9.100]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 38.80it/s, v_num=2507, trainLoss=9.100]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 41.93it/s, v_num=2508, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 33.15it/s, v_num=2508, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 48.98it/s, v_num=2508, trainLoss=5.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 37.63it/s, v_num=2508, trainLoss=5.460]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 46.64it/s, v_num=2509, trainLoss=5.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 35.97it/s, v_num=2509, trainLoss=5.460]\n",
      "torch.Size([2080, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Starting Epoch 9 now\n",
      "vehicle 0 priority: 0.6068376068376068, total priority of subgroup: 1.0\n",
      "vehicle 1 priority: 0.14545454545454545, total priority of subgroup: 1.0\n",
      "vehicle 2 priority: 0.8141592920353983, total priority of subgroup: 1.0\n",
      "vehicle 3 priority: 0.29559748427672955, total priority of subgroup: 1.0\n",
      "vehicle 4 priority: 0.58, total priority of subgroup: 1.0\n",
      "vehicle 5 priority: 0.04878048780487805, total priority of subgroup: 1.0\n",
      "vehicle 6 priority: 0.3, total priority of subgroup: 1.0\n",
      "vehicle 7 priority: 0.8518518518518519, total priority of subgroup: 1.0\n",
      "vehicle 8 priority: 0.7241379310344828, total priority of subgroup: 1.0\n",
      "vehicle 9 priority: 0.9724137931034482, total priority of subgroup: 1.0\n",
      "vehicle 10 priority: 0.8, total priority of subgroup: 1.0\n",
      "vehicle 11 priority: 0.7862903225806451, total priority of subgroup: 1.0\n",
      "vehicle 12 priority: 0.7711442786069652, total priority of subgroup: 1.0\n",
      "vehicle 13 priority: 0.5284552845528455, total priority of subgroup: 1.0\n",
      "vehicle 14 priority: 0.9044585987261147, total priority of subgroup: 1.0\n",
      "vehicle 15 priority: 0.7465564738292011, total priority of subgroup: 1.0\n",
      "vehicle 16 priority: 0.8260869565217391, total priority of subgroup: 1.0\n",
      "vehicle 17 priority: 0.41947565543071164, total priority of subgroup: 1.0\n",
      "vehicle 18 priority: 0.4166666666666667, total priority of subgroup: 1.0\n",
      "vehicle 19 priority: 0.8780487804878049, total priority of subgroup: 1.0\n",
      "vehicle 20 priority: 0.05574912891986063, total priority of subgroup: 1.0\n",
      "vehicle 21 priority: 0.47191011235955055, total priority of subgroup: 1.0\n",
      "vehicle 22 priority: 0.27586206896551724, total priority of subgroup: 1.0\n",
      "vehicle 23 priority: 0.11931818181818182, total priority of subgroup: 1.0\n",
      "vehicle 24 priority: 0.8297872340425532, total priority of subgroup: 1.0\n",
      "vehicle 25 priority: 0.8484848484848485, total priority of subgroup: 1.0\n",
      "vehicle 26 priority: 0.3381294964028777, total priority of subgroup: 1.0\n",
      "vehicle 27 priority: 0.06451612903225806, total priority of subgroup: 1.0\n",
      "vehicle 28 priority: 0.5353535353535354, total priority of subgroup: 1.0\n",
      "vehicle 29 priority: 0.1402439024390244, total priority of subgroup: 1.0\n",
      "Epoch 389: 100%|██████████| 2/2 [00:00<00:00, 48.21it/s, v_num=2480, trainLoss=5.200]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=390` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389: 100%|██████████| 2/2 [00:00<00:00, 41.69it/s, v_num=2480, trainLoss=5.200]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 53.33it/s, v_num=2481, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 40.03it/s, v_num=2481, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 299: 100%|██████████| 2/2 [00:00<00:00, 52.08it/s, v_num=2482, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 2/2 [00:00<00:00, 44.85it/s, v_num=2482, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 50.40it/s, v_num=2483, trainLoss=5.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 39.25it/s, v_num=2483, trainLoss=5.460]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 48.96it/s, v_num=2484, trainLoss=2.770]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 37.77it/s, v_num=2484, trainLoss=2.770]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 52.58it/s, v_num=2485, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 40.12it/s, v_num=2485, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 46.66it/s, v_num=2486, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 37.07it/s, v_num=2486, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 51.53it/s, v_num=2487, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 39.44it/s, v_num=2487, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 42.75it/s, v_num=2488, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=420` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 33.69it/s, v_num=2488, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 359: 100%|██████████| 5/5 [00:00<00:00, 53.23it/s, v_num=2489, trainLoss=6.710]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 5/5 [00:00<00:00, 49.98it/s, v_num=2489, trainLoss=6.710]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 43.43it/s, v_num=2490, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 34.38it/s, v_num=2490, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 329: 100%|██████████| 4/4 [00:00<00:00, 55.57it/s, v_num=2491, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 4/4 [00:00<00:00, 51.48it/s, v_num=2491, trainLoss=9.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 359: 100%|██████████| 3/3 [00:00<00:00, 56.08it/s, v_num=2492, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 3/3 [00:00<00:00, 50.64it/s, v_num=2492, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 389: 100%|██████████| 2/2 [00:00<00:00, 58.16it/s, v_num=2493, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=390` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389: 100%|██████████| 2/2 [00:00<00:00, 49.06it/s, v_num=2493, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 419: 100%|██████████| 2/2 [00:00<00:00, 57.77it/s, v_num=2493, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=420` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419: 100%|██████████| 2/2 [00:00<00:00, 49.71it/s, v_num=2493, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389: 100%|██████████| 3/3 [00:00<00:00, 57.50it/s, v_num=2494, trainLoss=5.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=390` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389: 100%|██████████| 3/3 [00:00<00:00, 51.90it/s, v_num=2494, trainLoss=5.460]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 329: 100%|██████████| 5/5 [00:00<00:00, 58.11it/s, v_num=2495, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 5/5 [00:00<00:00, 54.53it/s, v_num=2495, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 50.01it/s, v_num=2496, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 38.76it/s, v_num=2496, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 419: 100%|██████████| 2/2 [00:00<00:00, 54.32it/s, v_num=2497, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=420` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419: 100%|██████████| 2/2 [00:00<00:00, 46.93it/s, v_num=2497, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 49.92it/s, v_num=2498, trainLoss=2.770]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 38.42it/s, v_num=2498, trainLoss=2.770]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 51.03it/s, v_num=2498, trainLoss=2.770]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=390` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 38.95it/s, v_num=2498, trainLoss=2.770]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 2/2 [00:00<00:00, 54.28it/s, v_num=2499, trainLoss=2.780]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 2/2 [00:00<00:00, 47.07it/s, v_num=2499, trainLoss=2.780]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 50.42it/s, v_num=2500, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 38.71it/s, v_num=2500, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 48.53it/s, v_num=2501, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 37.77it/s, v_num=2501, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 56.13it/s, v_num=2502, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 42.69it/s, v_num=2502, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 41.48it/s, v_num=2503, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=420` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 32.99it/s, v_num=2503, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 47.86it/s, v_num=2504, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 36.68it/s, v_num=2504, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 45.45it/s, v_num=2505, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 35.41it/s, v_num=2505, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 42.60it/s, v_num=2505, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=390` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 33.74it/s, v_num=2505, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 45.97it/s, v_num=2506, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 35.88it/s, v_num=2506, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 49.31it/s, v_num=2507, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 37.72it/s, v_num=2507, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 47.36it/s, v_num=2508, trainLoss=5.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=390` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 35.22it/s, v_num=2508, trainLoss=5.460]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 42.15it/s, v_num=2509, trainLoss=6.220]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 33.52it/s, v_num=2509, trainLoss=6.220]\n",
      "torch.Size([2080, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Starting Epoch 10 now\n",
      "vehicle 0 priority: 0.7553191489361702, total priority of subgroup: 1.0\n",
      "vehicle 1 priority: 0.16666666666666666, total priority of subgroup: 1.0\n",
      "vehicle 2 priority: 0.5609756097560976, total priority of subgroup: 1.0\n",
      "vehicle 3 priority: 0.14779874213836477, total priority of subgroup: 1.0\n",
      "vehicle 4 priority: 0.8656716417910447, total priority of subgroup: 1.0\n",
      "vehicle 5 priority: 0.5263157894736842, total priority of subgroup: 1.0\n",
      "vehicle 6 priority: 0.0743801652892562, total priority of subgroup: 1.0\n",
      "vehicle 7 priority: 0.6052631578947368, total priority of subgroup: 1.0\n",
      "vehicle 8 priority: 0.6774193548387096, total priority of subgroup: 1.0\n",
      "vehicle 9 priority: 0.7540106951871658, total priority of subgroup: 1.0\n",
      "vehicle 10 priority: 0.36036036036036034, total priority of subgroup: 1.0\n",
      "vehicle 11 priority: 0.9605911330049262, total priority of subgroup: 1.0\n",
      "vehicle 12 priority: 0.8806818181818182, total priority of subgroup: 1.0\n",
      "vehicle 13 priority: 0.8125, total priority of subgroup: 1.0\n",
      "vehicle 14 priority: 0.8606060606060606, total priority of subgroup: 1.0\n",
      "vehicle 15 priority: 0.8364197530864198, total priority of subgroup: 1.0\n",
      "vehicle 16 priority: 0.7169811320754716, total priority of subgroup: 1.0\n",
      "vehicle 17 priority: 0.8421052631578947, total priority of subgroup: 1.0\n",
      "vehicle 18 priority: 0.6521739130434783, total priority of subgroup: 1.0\n",
      "vehicle 19 priority: 0.391304347826087, total priority of subgroup: 1.0\n",
      "vehicle 20 priority: 0.2909090909090909, total priority of subgroup: 1.0\n",
      "vehicle 21 priority: 0.3684210526315789, total priority of subgroup: 1.0\n",
      "vehicle 22 priority: 0.1095890410958904, total priority of subgroup: 1.0\n",
      "vehicle 23 priority: 0.15789473684210525, total priority of subgroup: 1.0\n",
      "vehicle 24 priority: 0.2154696132596685, total priority of subgroup: 1.0\n",
      "vehicle 25 priority: 0.22310756972111553, total priority of subgroup: 1.0\n",
      "vehicle 26 priority: 0.3983050847457627, total priority of subgroup: 1.0\n",
      "vehicle 27 priority: 0.08695652173913043, total priority of subgroup: 1.0\n",
      "vehicle 28 priority: 0.4274193548387097, total priority of subgroup: 1.0\n",
      "vehicle 29 priority: 0.8363636363636363, total priority of subgroup: 1.0\n",
      "Epoch 419: 100%|██████████| 2/2 [00:00<00:00, 47.58it/s, v_num=2480, trainLoss=5.200]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=420` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419: 100%|██████████| 2/2 [00:00<00:00, 41.89it/s, v_num=2480, trainLoss=5.200]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 54.68it/s, v_num=2481, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=390` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 41.18it/s, v_num=2481, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 329: 100%|██████████| 2/2 [00:00<00:00, 56.19it/s, v_num=2482, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 2/2 [00:00<00:00, 48.36it/s, v_num=2482, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 41.89it/s, v_num=2483, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=390` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 33.46it/s, v_num=2483, trainLoss=9.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 49.71it/s, v_num=2484, trainLoss=2.770]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 22.28it/s, v_num=2484, trainLoss=2.770]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 51.11it/s, v_num=2485, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 38.25it/s, v_num=2485, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 53.35it/s, v_num=2486, trainLoss=2.770]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=390` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 40.68it/s, v_num=2486, trainLoss=2.770]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 55.17it/s, v_num=2486, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=420` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 41.85it/s, v_num=2486, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 48.76it/s, v_num=2487, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=390` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 38.06it/s, v_num=2487, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 38.96it/s, v_num=2488, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=450` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 31.46it/s, v_num=2488, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 389: 100%|██████████| 5/5 [00:00<00:00, 54.66it/s, v_num=2489, trainLoss=4.910]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=390` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389: 100%|██████████| 5/5 [00:00<00:00, 51.46it/s, v_num=2489, trainLoss=4.910]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 419: 100%|██████████| 5/5 [00:00<00:00, 55.01it/s, v_num=2489, trainLoss=6.220]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=420` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419: 100%|██████████| 5/5 [00:00<00:00, 51.75it/s, v_num=2489, trainLoss=6.220]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 48.23it/s, v_num=2490, trainLoss=2.080]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 37.54it/s, v_num=2490, trainLoss=2.080]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 359: 100%|██████████| 4/4 [00:00<00:00, 57.68it/s, v_num=2491, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 4/4 [00:00<00:00, 53.29it/s, v_num=2491, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 389: 100%|██████████| 3/3 [00:00<00:00, 55.06it/s, v_num=2492, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=390` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389: 100%|██████████| 3/3 [00:00<00:00, 49.55it/s, v_num=2492, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 419: 100%|██████████| 3/3 [00:00<00:00, 54.74it/s, v_num=2492, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=420` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419: 100%|██████████| 3/3 [00:00<00:00, 49.51it/s, v_num=2492, trainLoss=9.390]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449: 100%|██████████| 2/2 [00:00<00:00, 51.51it/s, v_num=2493, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=450` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449: 100%|██████████| 2/2 [00:00<00:00, 45.16it/s, v_num=2493, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 419: 100%|██████████| 3/3 [00:00<00:00, 54.28it/s, v_num=2494, trainLoss=5.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=420` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419: 100%|██████████| 3/3 [00:00<00:00, 49.26it/s, v_num=2494, trainLoss=5.460]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 359: 100%|██████████| 5/5 [00:00<00:00, 53.41it/s, v_num=2495, trainLoss=2.770]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 5/5 [00:00<00:00, 50.42it/s, v_num=2495, trainLoss=2.770]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 50.26it/s, v_num=2496, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 38.92it/s, v_num=2496, trainLoss=9.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 449: 100%|██████████| 2/2 [00:00<00:00, 55.73it/s, v_num=2497, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=450` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449: 100%|██████████| 2/2 [00:00<00:00, 48.13it/s, v_num=2497, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 51.51it/s, v_num=2498, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=420` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 39.74it/s, v_num=2498, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 389: 100%|██████████| 2/2 [00:00<00:00, 52.29it/s, v_num=2499, trainLoss=5.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=390` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389: 100%|██████████| 2/2 [00:00<00:00, 45.38it/s, v_num=2499, trainLoss=5.460]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 54.98it/s, v_num=2500, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=330` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 41.98it/s, v_num=2500, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 51.13it/s, v_num=2501, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 39.61it/s, v_num=2501, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 51.76it/s, v_num=2502, trainLoss=2.770]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 39.94it/s, v_num=2502, trainLoss=2.770]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 48.61it/s, v_num=2503, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=450` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 37.81it/s, v_num=2503, trainLoss=9.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 51.64it/s, v_num=2504, trainLoss=2.780]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=390` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 40.13it/s, v_num=2504, trainLoss=2.780]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Previous Acc: 0.6836538461538462, Current Acc: 0.0\n",
      "Loading From Backup\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 48.35it/s, v_num=2504, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=420` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 37.42it/s, v_num=2504, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 42.56it/s, v_num=2505, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=420` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 33.52it/s, v_num=2505, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 49.46it/s, v_num=2506, trainLoss=9.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 38.02it/s, v_num=2506, trainLoss=9.390]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 56.36it/s, v_num=2507, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=360` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 42.76it/s, v_num=2507, trainLoss=3.000]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model could not complete tests.\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 49.29it/s, v_num=2508, trainLoss=2.890]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=420` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 38.80it/s, v_num=2508, trainLoss=2.890]\n",
      "torch.Size([2080, 10, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31634615384615383\n",
      "1.0\n",
      "Model got 6580/20800 right.\n",
      "Accuracy: 0.31634615384615383, Precision: 0.31634615384615383, Recall: 1.0, F1 Score: 0.4806428049671293\n",
      "14220, 68.36538461538461% Zeroes, 6580 Non Zero entries.\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 47.57it/s, v_num=2509, trainLoss=6.500]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=390` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 37.17it/s, v_num=2509, trainLoss=6.500]\n",
      "torch.Size([2080, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "torch.Size([5000, 10, 20])\n",
      "0.3144\n",
      "1.0\n",
      "Model got 15720/50000 right.\n",
      "Accuracy: 0.3144, Precision: 0.3144, Recall: 1.0, F1 Score: 0.47839318320146074\n",
      "34280, 68.56% Zeroes, 15720 Non Zero entries.\n",
      "torch.Size([5000, 10, 20])\n",
      "Model could not complete tests.\n",
      "Starting Epoch 11 now\n",
      "vehicle 0 priority: 1.0, total priority of subgroup: 1.0\n",
      "vehicle 1 priority: 0.1095890410958904, total priority of subgroup: 1.0\n",
      "vehicle 2 priority: 0.9019607843137255, total priority of subgroup: 1.0\n",
      "vehicle 3 priority: 0.6497695852534563, total priority of subgroup: 1.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not generator",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 215\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(totEpochs):\n\u001b[32m    214\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStarting Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m now\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m     \u001b[43mupdatePriorities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvehicles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m vehicle \u001b[38;5;129;01min\u001b[39;00m vehicles:\n\u001b[32m    217\u001b[39m         vehicle.updateSavedStates() \u001b[38;5;66;03m# Save current model as model to send to others, so that they are getting the latest after each loop\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 178\u001b[39m, in \u001b[36mupdatePriorities\u001b[39m\u001b[34m(vehicles)\u001b[39m\n\u001b[32m    176\u001b[39m dum = vehicles[i].datalen/vehicles[i].outnum\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m vehicles[i].sampling:\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     \u001b[38;5;28msum\u001b[39m += \u001b[43mvehicles\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m.datalen/vehicles[j].outnum\n\u001b[32m    179\u001b[39m vehicles[i].priority = (vehicles[i].datalen/vehicles[i].outnum)/(\u001b[38;5;28msum\u001b[39m)\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m vehicles[i].sampling:\n",
      "\u001b[31mTypeError\u001b[39m: list indices must be integers or slices, not generator"
     ]
    }
   ],
   "source": [
    "# DeFTA: Decentralized Federalized Training\n",
    "\n",
    "pl.seed_everything(1000)\n",
    "\n",
    "vehicleNumTot = 200 # 50 # 50\n",
    "subNetworkNum = 45 # 15 # 15\n",
    "totEpochs = 60 # 30 # 5\n",
    "stepsPerEpoch = 10 # 5 # 30\n",
    "stepsPerTestingEpoch = 15\n",
    "firstSteps = 50\n",
    "minConnnectedVehicles = 25 # 10\n",
    "backupThreshold = 0.1\n",
    "lossBackupThreshold = 3\n",
    "vehicles = []\n",
    "selectionWeights = {}\n",
    "gpu = False\n",
    "doEvil = True\n",
    "percEvil = 20\n",
    "lr = 0.01\n",
    "phiGain = 1\n",
    "phiGainLoss = 1\n",
    "testingRoundNum = 10\n",
    "\n",
    "path = f\"DeFTA/{doEvil}-{percEvil}-{vehicleNumTot}-{subNetworkNum}-{totEpochs}-{stepsPerEpoch}-{stepsPerTestingEpoch}-{minConnnectedVehicles}-{backupThreshold}-{phiGain}/\"\n",
    "if not os.path.exists(f\"out/{path}\"):\n",
    "    os.makedirs(f\"out/{path}\")\n",
    "\n",
    "log = OutLogger(path)\n",
    "# Function to update sampling weights and confidence values\n",
    "def phi(vehicle):\n",
    "    m = [0 for n in range(vehicleNumTot)]\n",
    "    for t in vehicle.sampling:\n",
    "        m[t] += 1  # define matrix m that contains weather the vehicle is in the sampled set, and how many times it is in the set.\n",
    "    _, _, _, vehicle.curr_acc = vehicle.test(tinyTestIn, tinyTestOut, True)\n",
    "    if vehicle.curr_acc != 0: # If the model doesn't just test to 0\n",
    "        '''RUN TEST, use result of this test and change to use prev_acc, curr_acc, and create a backup Threshold for the accuracy.'''\n",
    "        if vehicle.prev_acc != None: # If it isn't the first iteration:\n",
    "            if vehicle.prev_acc-vehicle.curr_acc > backupThreshold: # If this training round broke the model\n",
    "                print(f\"Previous Acc: {vehicle.prev_acc}, Current Acc: {vehicle.curr_acc}\")\n",
    "                print(\"Loading From Backup\")\n",
    "                vehicle.restoreFromBackup() # Restore backup weights\n",
    "                vehicle.step(stepsPerEpoch) # Training Step\n",
    "                vehicle.trust_acc = -4 # set loss to infinity, as this model is destroyed\n",
    "            else:\n",
    "                if vehicle.curr_acc > vehicle.prev_acc: # If this is new best model\n",
    "                    vehicle.saveBackup() # Save model as new backup\n",
    "                vehicle.trust_acc = vehicle.curr_acc - vehicle.prev_acc # Set change in trust\n",
    "                vehicle.prev_acc = vehicle.curr_acc # Update previous loss to stay current\n",
    "            print(vehicle.confidences)\n",
    "            for i in range(len(vehicle.confidences)):\n",
    "                if m[i]*vehicle.otherPriorities[i]*vehicle.trust_acc > 0:\n",
    "                    add = m[i]*vehicle.otherPriorities[i]*vehicle.trust_acc\n",
    "                else:\n",
    "                    add = phiGain*m[i]*vehicle.otherPriorities[i]*vehicle.trust_acc\n",
    "                vehicle.confidences[i] = vehicle.confidences[i] + (add) # Update confidences based on what vehicles are contributing to the training and the size of their contribution\n",
    "                print(f'{i}: {add}')\n",
    "            for i in range(len(vehicle.confidences)):\n",
    "                if vehicle.confidences[i] > 5:\n",
    "                    vehicle.confidences[i] = 5 # Add max to the sampling weights\n",
    "            for i in range(len(vehicle.samplingWeights)):\n",
    "                vehicle.samplingWeights[i] = (0.2 * vehicle.confidences[i]) if (vehicle.confidences[i] > 0) else (vehicle.confidences[i]) # Perform cRELU on C, with weighting a as 0.2 as per the findings of the DeFTA paper\n",
    "            # vehicle.samplingWeights = np.exp(vehicle.samplingWeights)/np.sum(np.exp(vehicle.samplingWeights)) # Implementation of the softMax function to align the theta values properly. Trying without this to have everything sampled unless issue.\n",
    "            for i in range(len(vehicle.samplingWeights)):\n",
    "                if vehicle.samplingWeights[i] > 1:\n",
    "                    vehicle.samplingWeights[i] = 1 # Add max to the sampling weights\n",
    "        else:\n",
    "            vehicle.prev_acc = vehicle.curr_acc # Update previous loss while allowing for one epoch of randomness\n",
    "        vehicle.prev_loss = vehicle.curr_loss\n",
    "    else: # If the model tests to zero, revert to previous loss-based method\n",
    "        if vehicle.prev_loss != None: # If it isn't the first iteration:\n",
    "            if vehicle.curr_loss > vehicle.prev_loss * lossBackupThreshold: # If this training round broke the model\n",
    "                print(f\"Previous Loss: {vehicle.prev_loss}, Current loss: {vehicle.curr_loss}\")\n",
    "                print(\"Loading From Backup\")\n",
    "                vehicle.restoreFromBackup() # Restore backup weights\n",
    "                vehicle.step(stepsPerEpoch) # Training Step\n",
    "                vehicle.trust_loss = 10 # set loss to infinity, as this model is destroyed\n",
    "            else:\n",
    "                if vehicle.curr_loss < vehicle.prev_loss: # If this is new best model\n",
    "                    vehicle.saveBackup() # Save model as new backup\n",
    "                vehicle.trust_loss = vehicle.curr_loss - vehicle.prev_loss # Set change in trust\n",
    "                vehicle.prev_loss = vehicle.curr_loss # Update previous loss to stay current\n",
    "            print(vehicle.confidences)\n",
    "            for i in range(len(vehicle.confidences)):\n",
    "                if m[i]*vehicle.otherPriorities[i]*vehicle.trust_loss < 0:\n",
    "                    add = m[i]*vehicle.otherPriorities[i]*vehicle.trust_loss\n",
    "                else:\n",
    "                    add = phiGainLoss*m[i]*vehicle.otherPriorities[i]*vehicle.trust_loss\n",
    "                vehicle.confidences[i] = vehicle.confidences[i] - (add) # Update confidences based on what vehicles are contributing to the training and the size of their contribution\n",
    "                print(f'{i}: {add}')\n",
    "            for i in range(len(vehicle.confidences)):\n",
    "                if vehicle.confidences[i] > 5:\n",
    "                    vehicle.confidences[i] = 5 # Add max to the sampling weights\n",
    "            for i in range(len(vehicle.samplingWeights)):\n",
    "                vehicle.samplingWeights[i] = (0.2 * vehicle.confidences[i]) if (vehicle.confidences[i] > 0) else (vehicle.confidences[i]) # Perform cRELU on C, with weighting a as 0.2 as per the findings of the DeFTA paper\n",
    "            # vehicle.samplingWeights = np.exp(vehicle.samplingWeights)/np.sum(np.exp(vehicle.samplingWeights)) # Implementation of the softMax function to align the theta values properly. Trying without this to have everything sampled unless issue.\n",
    "            for i in range(len(vehicle.samplingWeights)):\n",
    "                if vehicle.samplingWeights[i] > 1:\n",
    "                    vehicle.samplingWeights[i] = 1 # Add max to the sampling weights\n",
    "        else:\n",
    "            vehicle.prev_loss = vehicle.curr_loss # Update previous loss while allowing for one epoch of randomness.\n",
    "    if vehicle.id in selectionWeights:\n",
    "        selectionWeights[vehicle.id].append([vehicle.samplingWeights[:]])\n",
    "    else:\n",
    "        selectionWeights[vehicle.id] = [[vehicle.samplingWeights[:]]]\n",
    "    # Returns nothing, since all operations are done inside the vehicle\n",
    "\n",
    "def noLuckPhi(vehicle):\n",
    "    m = [0 for n in range(vehicleNumTot)]\n",
    "    for t in vehicle.sampling:\n",
    "        m[t] += 1  # define matrix m that contains whether the vehicle is in the sampled set, and how many times it is in the set.\n",
    "    vehicle.curr_f1, _, _, vehicle.curr_acc = vehicle.test(tinyTestIn, tinyTestOut, True)\n",
    "    if vehicle.testing:\n",
    "        print(\"TESTING ROUND\")\n",
    "        vehicle.rounds = 0\n",
    "        if vehicle.prev_f1:\n",
    "            if vehicle.curr_f1 >= vehicle.prev_f1-0.05: # If vehicle helps our model\n",
    "                for i in range(vehicleNumTot):\n",
    "                    if m[i] != 0:\n",
    "                        vehicle.goodNeighbors.append(i)\n",
    "                print(vehicle.goodNeighbors)\n",
    "            # Keep prev_accuracy and backup constant during testing phase\n",
    "            vehicle.restoreFromBackup() # Restore backup weights in order to keep best model during testing \n",
    "            print(\"Restored\")\n",
    "        else:\n",
    "            vehicle.prev_acc = vehicle.curr_acc\n",
    "            vehicle.prev_f1 = vehicle.curr_f1\n",
    "            print('Saved')\n",
    "            vehicle.saveBackup() # Save Backup for when we run training.\n",
    "\n",
    "\n",
    "        if len(vehicle.toTest):\n",
    "            vehicle.sampling = [vehicle.toTest.pop()]\n",
    "        else:\n",
    "            vehicle.testing = False\n",
    "            vehicle.sampling = vehicle.goodNeighbors.copy()\n",
    "    else:\n",
    "        vehicle.rounds += 1\n",
    "        print(\"PREDICTING ROUND\")\n",
    "        if vehicle.prev_f1: # If we have previous data to go off of\n",
    "            if vehicle.curr_f1 >= vehicle.prev_f1: # If model gets better or stays the same\n",
    "                vehicle.saveBackup() # Save model\n",
    "                vehicle.prev_f1 = vehicle.curr_f1 # update acc\n",
    "                vehicle.prev_acc = vehicle.curr_acc\n",
    "            elif vehicle.curr_f1 > vehicle.prev_f1 - 0.1: # Update model but do not update saved backup model\n",
    "                vehicle.prev_f1 = vehicle.curr_f1\n",
    "            else: # If model is ruined\n",
    "                print(f\"Previous f1: {vehicle.prev_f1}, Current f1: {vehicle.curr_f1}\")\n",
    "                print(\"Loading From Backup\")\n",
    "                vehicle.restoreFromBackup() # Restore backup weights\n",
    "                vehicle.step(stepsPerEpoch) # Training Step\n",
    "                vehicle.prev_f1 = vehicle.curr_f1 # update acc\n",
    "                vehicle.prev_acc = vehicle.curr_acc\n",
    "                # Run tests early as we have a bad-actor\n",
    "                vehicle.toTest = [i for i in vehicle.nearbyOBUs] # Only test those that contributed to this model\n",
    "                vehicle.sampling = [vehicle.toTest.pop()] # Initialize first sample\n",
    "                vehicle.testing = True # Start testing\n",
    "                vehicle.goodNeighbors = [] # Reset known good\n",
    "        else:\n",
    "            vehicle.prev_acc = vehicle.curr_acc\n",
    "            vehicle.prev_f1 = vehicle.curr_f1\n",
    "            vehicle.saveBackup() # Save Backup for when we run training.`\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "        if vehicle.rounds > 60:\n",
    "            vehicle.toTest = [i for i in vehicle.nearbyOBUs] # Test all nearby OBUs\n",
    "            vehicle.sampling = [vehicle.toTest.pop()] # Sample the first OBU\n",
    "            vehicle.testing = True # Start test\n",
    "            vehicle.goodNeighbors = [] # reset known good\n",
    "        else:\n",
    "            vehicle.sampling = vehicle.goodNeighbors # Sample all known good\n",
    "        \n",
    "    if vehicle.id in selections:\n",
    "        selections[vehicle.id].append([vehicle.sampling[:]])\n",
    "    else:\n",
    "        selections[vehicle.id] = [[vehicle.sampling[:]]]\n",
    "\n",
    "\n",
    "\n",
    "def updatePriorities(vehicles):\n",
    "    for i in range(vehicleNumTot):\n",
    "        vehicles[i].outnum = len(vehicles[i].sampling) + 1# Update useful outnumber of each vehicle in the simulation by having outnum = num sampled vehicles\n",
    "\n",
    "    for i in range(vehicleNumTot): # Loop through vehicles and add priority of vehicle, done in separete loop as it requires info from other vehicles\n",
    "        sum = vehicles[i].datalen/vehicles[i].outnum # Start out by including this vehicle's priority\n",
    "        dum = vehicles[i].datalen/vehicles[i].outnum\n",
    "        if len(vehicles[i].sampling) != 0:\n",
    "            for j in vehicles[i].sampling:\n",
    "                sum += vehicles[j].datalen/vehicles[j].outnum\n",
    "            vehicles[i].priority = (vehicles[i].datalen/vehicles[i].outnum)/(sum)\n",
    "        else:\n",
    "            vehicles[i].priority = 1\n",
    "        if len(vehicles[i].sampling) != 0:\n",
    "            for j in vehicles[i].sampling:\n",
    "                vehicles[i].otherPriorities[j] = (vehicles[j].datalen/vehicles[j].outnum)/sum # fill out standard list of other priorities\n",
    "                dum += vehicles[j].datalen/vehicles[j].outnum\n",
    "            print(f\"vehicle {i} priority: {vehicles[i].priority}, total priority of subgroup: {dum/sum}\")\n",
    "        else:\n",
    "            print(f'Vehicle {i} not sampling any vehicles this cycle.')\n",
    "\n",
    "for i in range(vehicleNumTot):\n",
    "    set = data.DataLoader(data.TensorDataset(fedDataSet[i][:,:,3:10].float(), fedDataSet[i][:,:,11].long()), batch_size=batchSize, shuffle=False, num_workers=10, persistent_workers = True) # Create datasets\n",
    "    if doEvil:\n",
    "        if np.random.randint(0,100) < percEvil:\n",
    "            vehicles.append(OBU(inputSize=7, units=20, motors=8, outputs=20, lr=lr, randInt=i, gpu=gpu, dataset=set, evil=True)) # Create evil vehicles\n",
    "        else:\n",
    "            vehicles.append(OBU(inputSize=7, units=20, motors=8, outputs=20, lr=lr, randInt=i, gpu=gpu, dataset=set)) # Create vehicles\n",
    "    else:\n",
    "        vehicles.append(OBU(inputSize=7, units=20, motors=8, outputs=20, lr=lr, randInt=i, gpu=gpu, dataset=set)) # Create vehicles\n",
    "    vehicles[i].prevWeights = vehicles[i].getState() # Save previous state, so that we can do it in iterations\n",
    "    vehicles[i].datalen = fedDataSet[i].shape[0]\n",
    "    vehicles[i].outnum = np.random.randint(minConnnectedVehicles, subNetworkNum) # Get number of vehicles in sub network, at least #x so that vehicle has some use.\n",
    "    range1 = np.arange(0, i).tolist()\n",
    "    range2 = np.arange(i+1, vehicleNumTot).tolist()\n",
    "    vehicles[i].nearbyOBUs = np.random.choice(range1 + range2, vehicles[i].outnum, replace=False) # Create subnetworks and add them to the vehicle\n",
    "    vehicles[i].confidences = np.full((vehicleNumTot), 3.) # Initialize confidence values for all vehicles - can be shifted to a dict later to allow for varying number/discovery of vehicles\n",
    "    vehicles[i].samplingWeights = np.full((vehicleNumTot), .5) # Initialize the sampling weights to 0.5 - similarly, can be switched to a dict\n",
    "    vehicles[i].otherPriorities = np.zeros((vehicleNumTot)) # Initialize list of priorities\n",
    "    vehicles[i].sampling = [] # Start by sampling no vehicles\n",
    "    vehicles[i].id = i # Save vehicles id\n",
    "    vehicles[i].toTest = [t for t in vehicles[i].nearbyOBUs]\n",
    "    vehicles[i].testing = True\n",
    "    vehicles[i].goodNeighbors = []\n",
    "\n",
    "historicLoss = {}\n",
    "selections = {}\n",
    "results = {}\n",
    "\n",
    "for epoch in range(totEpochs):\n",
    "    print(f\"Starting Epoch {epoch} now\")\n",
    "    updatePriorities(vehicles)\n",
    "    for vehicle in vehicles:\n",
    "        vehicle.updateSavedStates() # Save current model as model to send to others, so that they are getting the latest after each loop\n",
    "    for vehicle in vehicles:\n",
    "        log.startEpochTimer()\n",
    "        log.startVehicleTimer()\n",
    "         # Model aggregation - Sum weights of all participating models weighted by their priority\n",
    "        sum = None\n",
    "        for i in vehicle.sampling:\n",
    "            if not sum:\n",
    "                state = vehicles[i].getSavedState()\n",
    "                sum = dict((n, state.get(n, 0)*vehicle.otherPriorities[i]) for n in state) # Multiplying weights and priority\n",
    "            else:\n",
    "                state = vehicles[i].getSavedState()\n",
    "                add = dict((n, state.get(n, 0)*vehicle.otherPriorities[i]) for n in state) # Multiply weights and priority\n",
    "                sum = dict( (n, add.get(n, 0)+sum.get(n, 0)) for n in sum) # Add this models weights to the sum\n",
    "        state = vehicle.getSavedState()\n",
    "        add = dict((n, state.get(n, 0)*vehicle.priority) for n in state)\n",
    "        if sum:\n",
    "            sum = dict((n, add.get(n, 0)+sum.get(n, 0)) for n in sum) # Add this vehicles model to the aggregation\n",
    "        else:\n",
    "            sum = add\n",
    "        vehicle.setState(sum)\n",
    "        if epoch == 0:\n",
    "            loss = vehicle.step(firstSteps)\n",
    "        elif vehicle.testing:\n",
    "            loss = vehicle.step(stepsPerTestingEpoch) # Run training step to progress model\n",
    "        else:\n",
    "            loss = vehicle.step(stepsPerEpoch) # Run training step to progress model\n",
    "        if vehicle.id in historicLoss:\n",
    "            historicLoss[vehicle.id].append(loss)\n",
    "        else:\n",
    "            historicLoss[vehicle.id] = [loss]\n",
    "        noLuckPhi(vehicle) # Update theta and confidence matrix\n",
    "        log.endEpochTimer()\n",
    "        log.endVehicleTimer()\n",
    "    log.updateLogs(vehicles, epoch)\n",
    "\n",
    "sampleSizes = {}\n",
    "for id in selections:\n",
    "    for epoch in selections[id]:\n",
    "        if id in sampleSizes:\n",
    "            sampleSizes[id].append(len(epoch))\n",
    "        else:\n",
    "            sampleSizes[id] = [len(epoch)] # Printing number of vehicles sampled by each vehicle each iteration\n",
    "print(sampleSizes, file=open(f'out/{path}SampleSizes.txt', 'w'))\n",
    "print(historicLoss, file=open(f'out/{path}HistoricLoss.txt', 'w'))\n",
    "print(selections, file=open(f'out/{path}SelectedVehicles.txt', 'w'))\n",
    "avgF1 = 0\n",
    "evils = []\n",
    "log.finalLogs(vehicles, percEvil)\n",
    "for vehicle in vehicles: # Create list of evil/bad vehicles\n",
    "    if vehicle.isEvil():\n",
    "        evils.append(vehicle.id)\n",
    "print(evils, file=open(f'out/{path}VehicleStatus.txt','w'))\n",
    "print(selectionWeights, file = open(f'out/{path}SelectionWeights.txt', 'w')) # Print out the chances of selecting each vehicle\n",
    "log.log()\n",
    "\n",
    "'''\n",
    "Results:\n",
    "- 0 Starting weight: Accuracy: 0.2970971516501835, Precision: 0.2970971516501835, Recall: 1.0, F1 Score: 0.4580954499394479\n",
    "-.5 Starting weight: Accuracy: 0.2970971516501835, Precision: 0.2970971516501835, Recall: 1.0, F1 Score: 0.4580954499394479\n",
    "'''\n",
    "\n",
    "'''\n",
    "Pseudocode:\n",
    "nodes = list of nodes in simulation\n",
    "    every node has: N = list of nodes in network; C = list of confidence values; theta = list of weights for each vehicles contribution; D = local dataset; d = outdegree; w = local weights for model\n",
    "N = list of networks (each node i has a list of attached nodes) * At some point make this vary per iteration?\n",
    "for each node in simulation in parrallel:\n",
    "    Initialize list of nodes to be sampled - S\n",
    "        *** How do we do this ***\n",
    "    for each epoch:\n",
    "        collect weights from each node in N\n",
    "        new w = sum(sample weight * model weight) for model in sampled models - aggregate w\n",
    "        w = w - (learning rate) * (Loss function (model)) - Local optimizing (training step)\n",
    "        C_i, theta_i = phi(c, model) - update c and theta\n",
    "        Update S? - WeightedSample(W, theta)\n",
    "        Send local data to other models - maybe not necessary depending on how I do this\n",
    "        wait for the rest of peers to finish this loop\n",
    "\n",
    "        c is based on the training loss, ie. c_i_j increases if the training loss of w_i decreases (from their paper, they suggest coming up with your own)\n",
    "        theta = softmax(cRELU(c))\n",
    "        cRELU = {x; x<= 0, ax; x >0} They suggest a = 0.2 from their findings\n",
    "\n",
    "        phi(c, w_i):\n",
    "            m is binary matrix where its j-th entry is 1 iff j is in the set of used models (S) - m has all values on different columns\n",
    "            p is the set of aggregation weights for all nodes in the network - P has all values on different rows\n",
    "            if w_i is bad:\n",
    "                w = w_backup - don't allow bad training to mess up model\n",
    "                do training step on w\n",
    "                loss_trust = inf.\n",
    "            else:\n",
    "                if loss_curr is lowest:\n",
    "                    w_backup = w - create backup\n",
    "                loss_trust = loss_curr - loss_last\n",
    "                loss_last = loss_curr\n",
    "            c = c_prev - (m composite multipied by p) * loss_trust - update c\n",
    "            theta = softmax(cRELU(c)) - Update sample weights\n",
    "            Update S with subset of N, random sampling using weights to randomize selection size as well as selected values\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fff3c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94284057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "d = {'a': 1, 'b': 2, 'c': 3}\n",
    "e = ['a','b']\n",
    "print([d[x] for x in e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae882c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10002457 0.09977863 0.10002469 0.10002465 0.10002414 0.10002459\n",
      " 0.10002469 0.10002469 0.10002468 0.10002469]\n",
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "print(weights)\n",
    "i=0\n",
    "for w in weights:\n",
    "    i+= w\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2739aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([[-0.9981, -1.0000,  1.0000, -0.8293, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6075,  0.0442,  0.7163,  0.6767,  0.7933,  0.7151,  0.5629,  0.9533,\n",
      "         -0.8753,  0.7856, -0.5999, -0.2247],\n",
      "        [-0.9155, -1.0000,  1.0000, -0.7490, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5863,  0.0659,  0.7266,  0.6708,  0.7904,  0.7140,  0.5576,  0.9531,\n",
      "         -0.8754,  0.7839, -0.6045, -0.2218],\n",
      "        [-0.9489, -1.0000,  1.0000, -0.8079, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6044,  0.0083,  0.7259,  0.6747,  0.8049,  0.7217,  0.5656,  0.9527,\n",
      "         -0.8770,  0.7812, -0.5921, -0.2208],\n",
      "        [-0.9244, -1.0000,  1.0000, -0.8202, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5903,  0.0450,  0.7244,  0.6746,  0.7943,  0.7130,  0.5605,  0.9540,\n",
      "         -0.8758,  0.7817, -0.6040, -0.2236],\n",
      "        [-0.8204, -1.0000,  1.0000, -0.8306, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5760,  0.0688,  0.7257,  0.6738,  0.7918,  0.7142,  0.5560,  0.9537,\n",
      "         -0.8759,  0.7806, -0.6065, -0.2197],\n",
      "        [-0.9052, -1.0000,  1.0000, -0.8287, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6007,  0.0619,  0.7186,  0.6713,  0.7910,  0.7146,  0.5613,  0.9531,\n",
      "         -0.8752,  0.7856, -0.6016, -0.2228],\n",
      "        [-0.9171, -1.0000,  1.0000, -0.7736, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5861,  0.0592,  0.7295,  0.6732,  0.7919,  0.7156,  0.5582,  0.9522,\n",
      "         -0.8768,  0.7824, -0.6066, -0.2217],\n",
      "        [-0.9011, -1.0000,  1.0000, -0.8475, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5786,  0.0812,  0.7179,  0.6703,  0.7889,  0.7076,  0.5549,  0.9542,\n",
      "         -0.8750,  0.7827, -0.6045, -0.2219],\n",
      "        [-0.8631, -1.0000,  1.0000, -0.7902, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5965,  0.0589,  0.7250,  0.6712,  0.7918,  0.7152,  0.5585,  0.9532,\n",
      "         -0.8754,  0.7846, -0.6021, -0.2216],\n",
      "        [-0.9376, -1.0000,  1.0000, -0.8336, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6009,  0.0534,  0.7154,  0.6759,  0.7930,  0.7149,  0.5618,  0.9533,\n",
      "         -0.8752,  0.7852, -0.6004, -0.2241],\n",
      "        [-0.9918, -1.0000,  1.0000, -0.7738, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6079,  0.0590,  0.7221,  0.6598,  0.7916,  0.7140,  0.5577,  0.9529,\n",
      "         -0.8750,  0.7859, -0.6021, -0.2236],\n",
      "        [-0.9324, -1.0000,  1.0000, -0.8054, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6019,  0.0490,  0.7242,  0.6739,  0.7940,  0.7152,  0.5615,  0.9533,\n",
      "         -0.8758,  0.7848, -0.6005, -0.2245],\n",
      "        [-0.9729, -1.0000,  1.0000, -0.8740, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6004,  0.0527,  0.7156,  0.6718,  0.7918,  0.7144,  0.5609,  0.9533,\n",
      "         -0.8754,  0.7845, -0.6022, -0.2225],\n",
      "        [-0.9392, -1.0000,  1.0000, -0.7578, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6012,  0.0588,  0.7272,  0.6672,  0.7925,  0.7125,  0.5599,  0.9530,\n",
      "         -0.8754,  0.7839, -0.6021, -0.2222],\n",
      "        [-0.9753, -1.0000,  1.0000, -0.8987, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6006,  0.0513,  0.7112,  0.6751,  0.7920,  0.7149,  0.5619,  0.9533,\n",
      "         -0.8752,  0.7849, -0.6016, -0.2230],\n",
      "        [-0.9694, -1.0000,  1.0000, -0.8849, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6046,  0.0526,  0.7158,  0.6742,  0.7929,  0.7148,  0.5624,  0.9533,\n",
      "         -0.8754,  0.7853, -0.6007, -0.2234],\n",
      "        [-0.9733, -1.0000,  1.0000, -0.8345, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6086,  0.0414,  0.7199,  0.6723,  0.7945,  0.7157,  0.5638,  0.9532,\n",
      "         -0.8756,  0.7850, -0.5993, -0.2237],\n",
      "        [-0.9559, -1.0000,  1.0000, -0.8139, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6064,  0.0446,  0.7236,  0.6764,  0.7946,  0.7156,  0.5635,  0.9533,\n",
      "         -0.8757,  0.7853, -0.5992, -0.2243],\n",
      "        [-0.9895, -1.0000,  1.0000, -0.8400, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6053,  0.0515,  0.7152,  0.6766,  0.7923,  0.7138,  0.5629,  0.9533,\n",
      "         -0.8753,  0.7853, -0.6006, -0.2246],\n",
      "        [-0.9850, -1.0000,  1.0000, -0.8246, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6057,  0.0509,  0.7189,  0.6756,  0.7923,  0.7139,  0.5636,  0.9530,\n",
      "         -0.8761,  0.7846, -0.6011, -0.2232],\n",
      "        [-0.9141, -1.0000,  1.0000, -0.8038, -1.0000, -1.0000,  0.9986, -1.0000,\n",
      "          0.5877,  0.0757,  0.7221,  0.6766,  0.7851,  0.7114,  0.5568,  0.9535,\n",
      "         -0.8753,  0.7852, -0.6084, -0.2252],\n",
      "        [-1.0000, -1.0000,  1.0000, -0.7906, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6010,  0.0500,  0.7189,  0.6741,  0.7931,  0.7138,  0.5617,  0.9541,\n",
      "         -0.8750,  0.7851, -0.6002, -0.2256],\n",
      "        [-0.9512, -1.0000,  1.0000, -0.7711, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5806,  0.0660,  0.7224,  0.6653,  0.7907,  0.7124,  0.5555,  0.9528,\n",
      "         -0.8753,  0.7823, -0.6020, -0.2221],\n",
      "        [-0.9773, -1.0000,  1.0000, -0.6992, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5976,  0.0353,  0.7326,  0.6754,  0.7977,  0.7173,  0.5616,  0.9533,\n",
      "         -0.8767,  0.7812, -0.5994, -0.2206],\n",
      "        [-0.8841, -1.0000,  1.0000, -0.7073, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5803,  0.0804,  0.7310,  0.6690,  0.7865,  0.7111,  0.5568,  0.9522,\n",
      "         -0.8763,  0.7848, -0.6070, -0.2240],\n",
      "        [-0.9066, -1.0000,  1.0000, -0.8235, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5815,  0.0613,  0.7235,  0.6754,  0.7908,  0.7140,  0.5575,  0.9535,\n",
      "         -0.8758,  0.7806, -0.6078, -0.2208],\n",
      "        [-0.9674, -1.0000,  1.0000, -0.7686, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6023,  0.0395,  0.7230,  0.6756,  0.7967,  0.7166,  0.5635,  0.9533,\n",
      "         -0.8754,  0.7849, -0.5974, -0.2249],\n",
      "        [-1.0000, -1.0000,  1.0000, -0.8173, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6059,  0.0477,  0.7172,  0.6753,  0.7931,  0.7147,  0.5630,  0.9534,\n",
      "         -0.8753,  0.7853, -0.6001, -0.2245],\n",
      "        [-0.9537, -1.0000,  1.0000, -0.8257, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5943,  0.0285,  0.7231,  0.6745,  0.7992,  0.7157,  0.5622,  0.9538,\n",
      "         -0.8760,  0.7806, -0.5997, -0.2230],\n",
      "        [-0.9737, -1.0000,  1.0000, -0.7748, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6039,  0.0499,  0.7228,  0.6780,  0.7933,  0.7130,  0.5619,  0.9543,\n",
      "         -0.8753,  0.7851, -0.6001, -0.2259],\n",
      "        [-0.9677, -1.0000,  1.0000, -0.7541, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5983,  0.0546,  0.7248,  0.6760,  0.7928,  0.7140,  0.5608,  0.9534,\n",
      "         -0.8756,  0.7852, -0.6007, -0.2250],\n",
      "        [-0.9449, -1.0000,  1.0000, -0.8400, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5912,  0.0640,  0.7158,  0.6795,  0.7895,  0.7091,  0.5596,  0.9541,\n",
      "         -0.8751,  0.7837, -0.6026, -0.2254]])\n",
      "tensor([[-0.9981, -1.0000,  1.0000, -0.8293, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6075,  0.0442,  0.7163,  0.6767,  0.7933,  0.7151,  0.5629,  0.9533,\n",
      "         -0.8753,  0.7856, -0.5999, -0.2247],\n",
      "        [-0.9155, -1.0000,  1.0000, -0.7490, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5863,  0.0659,  0.7266,  0.6708,  0.7904,  0.7140,  0.5576,  0.9531,\n",
      "         -0.8754,  0.7839, -0.6045, -0.2218],\n",
      "        [-0.9489, -1.0000,  1.0000, -0.8079, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6044,  0.0083,  0.7259,  0.6747,  0.8049,  0.7217,  0.5656,  0.9527,\n",
      "         -0.8770,  0.7812, -0.5921, -0.2208],\n",
      "        [-0.9244, -1.0000,  1.0000, -0.8202, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5903,  0.0450,  0.7244,  0.6746,  0.7943,  0.7130,  0.5605,  0.9540,\n",
      "         -0.8758,  0.7817, -0.6040, -0.2236],\n",
      "        [-0.8204, -1.0000,  1.0000, -0.8306, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5760,  0.0688,  0.7257,  0.6738,  0.7918,  0.7142,  0.5560,  0.9537,\n",
      "         -0.8759,  0.7806, -0.6065, -0.2197],\n",
      "        [-0.9052, -1.0000,  1.0000, -0.8287, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6007,  0.0619,  0.7186,  0.6713,  0.7910,  0.7146,  0.5613,  0.9531,\n",
      "         -0.8752,  0.7856, -0.6016, -0.2228],\n",
      "        [-0.9171, -1.0000,  1.0000, -0.7736, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5861,  0.0592,  0.7295,  0.6732,  0.7919,  0.7156,  0.5582,  0.9522,\n",
      "         -0.8768,  0.7824, -0.6066, -0.2217],\n",
      "        [-0.9011, -1.0000,  1.0000, -0.8475, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5786,  0.0812,  0.7179,  0.6703,  0.7889,  0.7076,  0.5549,  0.9542,\n",
      "         -0.8750,  0.7827, -0.6045, -0.2219],\n",
      "        [-0.8631, -1.0000,  1.0000, -0.7902, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5965,  0.0589,  0.7250,  0.6712,  0.7918,  0.7152,  0.5585,  0.9532,\n",
      "         -0.8754,  0.7846, -0.6021, -0.2216],\n",
      "        [-0.9376, -1.0000,  1.0000, -0.8336, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6009,  0.0534,  0.7154,  0.6759,  0.7930,  0.7149,  0.5618,  0.9533,\n",
      "         -0.8752,  0.7852, -0.6004, -0.2241],\n",
      "        [-0.9918, -1.0000,  1.0000, -0.7738, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6079,  0.0590,  0.7221,  0.6598,  0.7916,  0.7140,  0.5577,  0.9529,\n",
      "         -0.8750,  0.7859, -0.6021, -0.2236],\n",
      "        [-0.9324, -1.0000,  1.0000, -0.8054, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6019,  0.0490,  0.7242,  0.6739,  0.7940,  0.7152,  0.5615,  0.9533,\n",
      "         -0.8758,  0.7848, -0.6005, -0.2245],\n",
      "        [-0.9729, -1.0000,  1.0000, -0.8740, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6004,  0.0527,  0.7156,  0.6718,  0.7918,  0.7144,  0.5609,  0.9533,\n",
      "         -0.8754,  0.7845, -0.6022, -0.2225],\n",
      "        [-0.9392, -1.0000,  1.0000, -0.7578, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6012,  0.0588,  0.7272,  0.6672,  0.7925,  0.7125,  0.5599,  0.9530,\n",
      "         -0.8754,  0.7839, -0.6021, -0.2222],\n",
      "        [-0.9753, -1.0000,  1.0000, -0.8987, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6006,  0.0513,  0.7112,  0.6751,  0.7920,  0.7149,  0.5619,  0.9533,\n",
      "         -0.8752,  0.7849, -0.6016, -0.2230],\n",
      "        [-0.9694, -1.0000,  1.0000, -0.8849, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6046,  0.0526,  0.7158,  0.6742,  0.7929,  0.7148,  0.5624,  0.9533,\n",
      "         -0.8754,  0.7853, -0.6007, -0.2234],\n",
      "        [-0.9733, -1.0000,  1.0000, -0.8345, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6086,  0.0414,  0.7199,  0.6723,  0.7945,  0.7157,  0.5638,  0.9532,\n",
      "         -0.8756,  0.7850, -0.5993, -0.2237],\n",
      "        [-0.9559, -1.0000,  1.0000, -0.8139, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6064,  0.0446,  0.7236,  0.6764,  0.7946,  0.7156,  0.5635,  0.9533,\n",
      "         -0.8757,  0.7853, -0.5992, -0.2243],\n",
      "        [-0.9895, -1.0000,  1.0000, -0.8400, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6053,  0.0515,  0.7152,  0.6766,  0.7923,  0.7138,  0.5629,  0.9533,\n",
      "         -0.8753,  0.7853, -0.6006, -0.2246],\n",
      "        [-0.9850, -1.0000,  1.0000, -0.8246, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6057,  0.0509,  0.7189,  0.6756,  0.7923,  0.7139,  0.5636,  0.9530,\n",
      "         -0.8761,  0.7846, -0.6011, -0.2232],\n",
      "        [-0.9141, -1.0000,  1.0000, -0.8038, -1.0000, -1.0000,  0.9986, -1.0000,\n",
      "          0.5877,  0.0757,  0.7221,  0.6766,  0.7851,  0.7114,  0.5568,  0.9535,\n",
      "         -0.8753,  0.7852, -0.6084, -0.2252],\n",
      "        [-1.0000, -1.0000,  1.0000, -0.7906, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6010,  0.0500,  0.7189,  0.6741,  0.7931,  0.7138,  0.5617,  0.9541,\n",
      "         -0.8750,  0.7851, -0.6002, -0.2256],\n",
      "        [-0.9512, -1.0000,  1.0000, -0.7711, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5806,  0.0660,  0.7224,  0.6653,  0.7907,  0.7124,  0.5555,  0.9528,\n",
      "         -0.8753,  0.7823, -0.6020, -0.2221],\n",
      "        [-0.9773, -1.0000,  1.0000, -0.6992, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5976,  0.0353,  0.7326,  0.6754,  0.7977,  0.7173,  0.5616,  0.9533,\n",
      "         -0.8767,  0.7812, -0.5994, -0.2206],\n",
      "        [-0.8841, -1.0000,  1.0000, -0.7073, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5803,  0.0804,  0.7310,  0.6690,  0.7865,  0.7111,  0.5568,  0.9522,\n",
      "         -0.8763,  0.7848, -0.6070, -0.2240],\n",
      "        [-0.9066, -1.0000,  1.0000, -0.8235, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5815,  0.0613,  0.7235,  0.6754,  0.7908,  0.7140,  0.5575,  0.9535,\n",
      "         -0.8758,  0.7806, -0.6078, -0.2208],\n",
      "        [-0.9674, -1.0000,  1.0000, -0.7686, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6023,  0.0395,  0.7230,  0.6756,  0.7967,  0.7166,  0.5635,  0.9533,\n",
      "         -0.8754,  0.7849, -0.5974, -0.2249],\n",
      "        [-1.0000, -1.0000,  1.0000, -0.8173, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6059,  0.0477,  0.7172,  0.6753,  0.7931,  0.7147,  0.5630,  0.9534,\n",
      "         -0.8753,  0.7853, -0.6001, -0.2245],\n",
      "        [-0.9537, -1.0000,  1.0000, -0.8257, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5943,  0.0285,  0.7231,  0.6745,  0.7992,  0.7157,  0.5622,  0.9538,\n",
      "         -0.8760,  0.7806, -0.5997, -0.2230],\n",
      "        [-0.9737, -1.0000,  1.0000, -0.7748, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6039,  0.0499,  0.7228,  0.6780,  0.7933,  0.7130,  0.5619,  0.9543,\n",
      "         -0.8753,  0.7851, -0.6001, -0.2259],\n",
      "        [-0.9677, -1.0000,  1.0000, -0.7541, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5983,  0.0546,  0.7248,  0.6760,  0.7928,  0.7140,  0.5608,  0.9534,\n",
      "         -0.8756,  0.7852, -0.6007, -0.2250],\n",
      "        [-0.9449, -1.0000,  1.0000, -0.8400, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5912,  0.0640,  0.7158,  0.6795,  0.7895,  0.7091,  0.5596,  0.9541,\n",
      "         -0.8751,  0.7837, -0.6026, -0.2254]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "1\n",
      "tensor([[-7.6004e-01,  1.0000e+00, -5.3941e-02,  1.2167e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9998e-01,  1.0000e+00,  6.8931e-01, -6.0010e-01,\n",
      "          6.2882e-01, -3.5610e-03,  6.8400e-01, -2.3380e-01,  8.4522e-01,\n",
      "          7.1126e-01, -8.9890e-01,  8.0388e-01, -7.1784e-01,  6.1549e-01],\n",
      "        [-5.2351e-01,  1.0000e+00, -6.7182e-02,  2.8477e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9999e-01,  1.0000e+00,  6.2850e-01, -5.5974e-01,\n",
      "          6.1508e-01, -2.2991e-02,  6.8370e-01, -2.2596e-01,  8.4608e-01,\n",
      "          7.0229e-01, -8.9671e-01,  7.8804e-01, -6.9764e-01,  6.0886e-01],\n",
      "        [-2.9397e-01,  1.0000e+00, -2.8543e-02,  1.2000e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9998e-01,  1.0000e+00,  5.0971e-01, -4.8665e-01,\n",
      "          6.5966e-01,  3.7812e-02,  6.7772e-01, -1.9162e-01,  8.5490e-01,\n",
      "          6.9819e-01, -8.9955e-01,  7.6936e-01, -6.5779e-01,  6.0142e-01],\n",
      "        [-3.9620e-01,  1.0000e+00, -5.8512e-02,  1.2215e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9998e-01,  1.0000e+00,  5.1087e-01, -4.9978e-01,\n",
      "          6.7652e-01,  5.1374e-02,  6.7809e-01, -1.8451e-01,  8.6169e-01,\n",
      "          7.0624e-01, -9.0138e-01,  7.8450e-01, -6.7374e-01,  6.0716e-01],\n",
      "        [-2.9606e-01,  1.0000e+00, -8.7040e-02,  1.2809e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  4.8698e-01, -4.5486e-01,\n",
      "          6.8331e-01,  7.2306e-02,  6.7520e-01, -1.7345e-01,  8.5784e-01,\n",
      "          7.0088e-01, -9.0219e-01,  7.6329e-01, -6.3902e-01,  5.9577e-01],\n",
      "        [-4.4712e-01,  1.0000e+00, -1.1246e-01,  1.2019e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  6.0078e-01, -4.8815e-01,\n",
      "          6.4848e-01,  2.2428e-03,  6.8116e-01, -1.9600e-01,  8.5029e-01,\n",
      "          7.0572e-01, -9.0013e-01,  7.7411e-01, -6.6896e-01,  6.0602e-01],\n",
      "        [-5.2847e-01,  1.0000e+00, -8.0144e-02, -2.0762e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.5270e-01,  1.0000e+00,  5.5962e-01, -5.2323e-01,\n",
      "          6.8406e-01,  5.5843e-02,  6.8117e-01, -1.9760e-01,  8.5694e-01,\n",
      "          7.0352e-01, -9.0436e-01,  7.7430e-01, -6.6449e-01,  5.9954e-01],\n",
      "        [-2.6348e-01,  1.0000e+00,  8.1390e-04,  6.0000e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.4145e-01,  1.0000e+00,  6.0004e-01, -6.2866e-01,\n",
      "          5.7918e-01,  6.1046e-02,  6.7698e-01, -2.3972e-01,  8.4279e-01,\n",
      "          6.8307e-01, -8.9095e-01,  8.2811e-01, -7.1784e-01,  6.1567e-01],\n",
      "        [-6.7680e-02,  1.0000e+00, -5.0437e-02,  3.6782e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.4083e-01,  1.0000e+00,  5.3670e-01, -4.6674e-01,\n",
      "          6.2202e-01,  5.6494e-02,  6.7147e-01, -1.9982e-01,  8.5170e-01,\n",
      "          6.8838e-01, -8.9936e-01,  7.8231e-01, -6.5704e-01,  5.9941e-01],\n",
      "        [-4.3367e-01,  1.0000e+00, -8.9936e-02,  2.7977e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.5403e-01,  1.0000e+00,  5.7070e-01, -4.7158e-01,\n",
      "          6.5662e-01,  2.8846e-02,  6.7704e-01, -1.8991e-01,  8.4506e-01,\n",
      "          6.9813e-01, -8.9968e-01,  7.7186e-01, -6.5605e-01,  5.9731e-01],\n",
      "        [-6.0301e-01,  1.0000e+00, -7.2631e-02,  3.6000e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.5549e-01,  1.0000e+00,  5.6927e-01, -5.7504e-01,\n",
      "          6.4534e-01,  1.0992e-02,  6.8178e-01, -2.2210e-01,  8.4829e-01,\n",
      "          7.0010e-01, -8.9739e-01,  7.9001e-01, -6.8685e-01,  6.0153e-01],\n",
      "        [-4.3930e-01,  1.0000e+00, -8.5803e-02,  7.1208e-02, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8491e-01,  1.0000e+00,  5.5791e-01, -5.4432e-01,\n",
      "          6.3929e-01,  3.9419e-02,  6.7974e-01, -2.3477e-01,  8.5123e-01,\n",
      "          6.9970e-01, -9.0100e-01,  7.8538e-01, -6.9074e-01,  6.0372e-01],\n",
      "        [-5.9979e-01,  1.0000e+00, -6.1506e-02,  3.7745e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9203e-01,  1.0000e+00,  6.6425e-01, -5.9383e-01,\n",
      "          5.8181e-01, -8.0496e-03,  6.8162e-01, -2.5719e-01,  8.4089e-01,\n",
      "          6.9056e-01, -8.9271e-01,  7.9174e-01, -7.2459e-01,  6.1102e-01],\n",
      "        [-4.4423e-01,  1.0000e+00, -4.7259e-02,  2.8673e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8531e-01,  1.0000e+00,  5.8550e-01, -5.8249e-01,\n",
      "          6.1849e-01,  4.4572e-02,  6.8070e-01, -2.3022e-01,  8.4594e-01,\n",
      "          6.9139e-01, -8.9603e-01,  7.9950e-01, -6.9791e-01,  6.0351e-01],\n",
      "        [-7.5322e-01,  1.0000e+00, -7.3768e-02,  2.1194e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8778e-01,  1.0000e+00,  6.3902e-01, -5.5622e-01,\n",
      "          6.3523e-01,  8.4427e-03,  6.8582e-01, -2.1038e-01,  8.3593e-01,\n",
      "          6.9710e-01, -8.9619e-01,  7.9240e-01, -6.8889e-01,  6.0078e-01],\n",
      "        [-4.9345e-01,  1.0000e+00,  6.5766e-03,  5.1921e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8768e-01,  1.0000e+00,  5.8698e-01, -5.2698e-01,\n",
      "          6.0503e-01,  2.9506e-03,  6.8361e-01, -2.1062e-01,  8.4060e-01,\n",
      "          6.8893e-01, -8.9588e-01,  7.8154e-01, -6.7393e-01,  5.9950e-01],\n",
      "        [-6.6881e-01,  1.0000e+00, -3.1412e-02,  4.4024e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9966e-01,  1.0000e+00,  6.1310e-01, -5.4831e-01,\n",
      "          6.2645e-01, -4.7085e-02,  6.8572e-01, -2.1408e-01,  8.4949e-01,\n",
      "          6.9958e-01, -8.9808e-01,  7.8380e-01, -7.1372e-01,  6.0635e-01],\n",
      "        [-4.1909e-01,  1.0000e+00, -5.1049e-02,  2.0179e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9965e-01,  1.0000e+00,  5.8603e-01, -6.2594e-01,\n",
      "          6.0999e-01,  1.7881e-02,  6.8255e-01, -2.6375e-01,  8.5572e-01,\n",
      "          7.0567e-01, -8.9712e-01,  8.1128e-01, -7.2798e-01,  6.2107e-01],\n",
      "        [-5.9088e-01,  1.0000e+00, -5.5411e-02,  4.0000e-02, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9903e-01,  1.0000e+00,  6.5655e-01, -4.9866e-01,\n",
      "          6.3798e-01, -5.6846e-02,  6.8560e-01, -1.9666e-01,  8.4262e-01,\n",
      "          7.1566e-01, -8.9689e-01,  7.6546e-01, -6.8881e-01,  6.1189e-01],\n",
      "        [-5.4756e-01,  1.0000e+00, -6.1967e-02,  2.1020e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9875e-01,  1.0000e+00,  6.2215e-01, -5.8058e-01,\n",
      "          6.2502e-01,  1.6103e-02,  6.8376e-01, -2.2923e-01,  8.5519e-01,\n",
      "          7.0094e-01, -9.0102e-01,  8.0436e-01, -7.0306e-01,  6.1677e-01],\n",
      "        [-5.6992e-01,  1.0000e+00, -2.3950e-02,  1.4307e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.6405e-01,  1.0000e+00,  5.6233e-01, -5.8091e-01,\n",
      "          6.3099e-01,  2.6197e-03,  6.8453e-01, -2.2936e-01,  8.5836e-01,\n",
      "          7.0488e-01, -9.0117e-01,  7.9474e-01, -6.9062e-01,  6.1103e-01],\n",
      "        [-5.3009e-01,  1.0000e+00, -3.0723e-02,  2.7771e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.5569e-01,  1.0000e+00,  5.7490e-01, -5.5057e-01,\n",
      "          6.0230e-01,  4.9114e-02,  6.7852e-01, -2.1473e-01,  8.5003e-01,\n",
      "          6.9782e-01, -8.9235e-01,  8.0483e-01, -6.7455e-01,  6.0922e-01],\n",
      "        [-6.1798e-01,  1.0000e+00, -5.1503e-02,  3.5995e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9021e-01,  1.0000e+00,  6.6402e-01, -5.6831e-01,\n",
      "          6.1688e-01, -4.9039e-02,  6.7791e-01, -2.4120e-01,  8.3587e-01,\n",
      "          7.0723e-01, -8.9237e-01,  7.8437e-01, -7.1962e-01,  6.0575e-01],\n",
      "        [-3.7844e-01,  1.0000e+00, -2.9048e-02,  2.9428e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9372e-01,  1.0000e+00,  6.1822e-01, -5.0393e-01,\n",
      "          6.4621e-01, -4.1931e-03,  6.7718e-01, -2.0337e-01,  8.5033e-01,\n",
      "          7.0935e-01, -8.9779e-01,  7.8667e-01, -6.9938e-01,  6.1248e-01],\n",
      "        [-4.1601e-01,  1.0000e+00,  4.9452e-02,  1.2000e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9891e-01,  1.0000e+00,  5.9406e-01, -5.7535e-01,\n",
      "          5.8266e-01,  4.3930e-03,  6.7587e-01, -2.5639e-01,  8.5471e-01,\n",
      "          6.9942e-01, -8.9558e-01,  8.0197e-01, -7.1057e-01,  6.1511e-01],\n",
      "        [-6.7404e-01,  1.0000e+00,  4.7630e-02,  3.9309e-02, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8595e-01,  1.0000e+00,  5.8779e-01, -6.3760e-01,\n",
      "          5.9105e-01,  3.1082e-02,  6.8193e-01, -2.6287e-01,  8.5132e-01,\n",
      "          7.0196e-01, -8.9649e-01,  8.0761e-01, -7.0490e-01,  6.0651e-01],\n",
      "        [-4.4523e-01,  1.0000e+00, -1.1603e-02,  2.8132e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9993e-01,  1.0000e+00,  6.2176e-01, -5.7226e-01,\n",
      "          6.1429e-01,  2.8279e-02,  6.8193e-01, -2.1611e-01,  8.4482e-01,\n",
      "          6.9787e-01, -8.9749e-01,  8.0521e-01, -6.9726e-01,  6.1018e-01],\n",
      "        [-6.5224e-01,  1.0000e+00,  4.0281e-02,  4.3995e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9975e-01,  1.0000e+00,  6.6267e-01, -5.1847e-01,\n",
      "          6.0498e-01, -3.2852e-02,  6.7972e-01, -2.0797e-01,  8.3537e-01,\n",
      "          6.9748e-01, -8.9450e-01,  7.9390e-01, -7.0511e-01,  6.0661e-01],\n",
      "        [-5.1558e-01,  1.0000e+00, -5.0434e-02,  2.1661e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8835e-01,  1.0000e+00,  5.7560e-01, -5.6287e-01,\n",
      "          6.7171e-01,  2.1279e-02,  6.8625e-01, -2.0386e-01,  8.5600e-01,\n",
      "          7.0326e-01, -9.0228e-01,  7.8934e-01, -6.8833e-01,  6.1152e-01],\n",
      "        [-6.4174e-01,  1.0000e+00, -7.9828e-02,  2.8032e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9974e-01,  1.0000e+00,  6.6740e-01, -6.2698e-01,\n",
      "          5.9974e-01,  2.2514e-02,  6.8551e-01, -2.3667e-01,  8.3939e-01,\n",
      "          6.9754e-01, -8.9532e-01,  8.1423e-01, -7.1877e-01,  6.1125e-01],\n",
      "        [-5.6957e-01,  1.0000e+00, -6.9399e-02,  2.8000e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9969e-01,  1.0000e+00,  6.4837e-01, -5.3300e-01,\n",
      "          6.1199e-01,  8.0501e-03,  6.8219e-01, -2.2560e-01,  8.4175e-01,\n",
      "          6.9821e-01, -9.0058e-01,  7.8713e-01, -6.8998e-01,  6.0448e-01],\n",
      "        [-5.1998e-01,  1.0000e+00, -6.5907e-02,  3.9899e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  6.4840e-01, -4.8928e-01,\n",
      "          6.2930e-01, -1.5987e-02,  6.7582e-01, -2.0421e-01,  8.3871e-01,\n",
      "          7.0149e-01, -8.9789e-01,  7.7371e-01, -6.8137e-01,  6.0885e-01]])\n",
      "tensor([[-7.6004e-01,  1.0000e+00, -5.3941e-02,  1.2167e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9998e-01,  1.0000e+00,  6.8931e-01, -6.0010e-01,\n",
      "          6.2882e-01, -3.5610e-03,  6.8400e-01, -2.3380e-01,  8.4522e-01,\n",
      "          7.1126e-01, -8.9890e-01,  8.0388e-01, -7.1784e-01,  6.1549e-01],\n",
      "        [-5.2351e-01,  1.0000e+00, -6.7182e-02,  2.8477e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9999e-01,  1.0000e+00,  6.2850e-01, -5.5974e-01,\n",
      "          6.1508e-01, -2.2991e-02,  6.8370e-01, -2.2596e-01,  8.4608e-01,\n",
      "          7.0229e-01, -8.9671e-01,  7.8804e-01, -6.9764e-01,  6.0886e-01],\n",
      "        [-2.9397e-01,  1.0000e+00, -2.8543e-02,  1.2000e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9998e-01,  1.0000e+00,  5.0971e-01, -4.8665e-01,\n",
      "          6.5966e-01,  3.7812e-02,  6.7772e-01, -1.9162e-01,  8.5490e-01,\n",
      "          6.9819e-01, -8.9955e-01,  7.6936e-01, -6.5779e-01,  6.0142e-01],\n",
      "        [-3.9620e-01,  1.0000e+00, -5.8512e-02,  1.2215e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9998e-01,  1.0000e+00,  5.1087e-01, -4.9978e-01,\n",
      "          6.7652e-01,  5.1374e-02,  6.7809e-01, -1.8451e-01,  8.6169e-01,\n",
      "          7.0624e-01, -9.0138e-01,  7.8450e-01, -6.7374e-01,  6.0716e-01],\n",
      "        [-2.9606e-01,  1.0000e+00, -8.7040e-02,  1.2809e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  4.8698e-01, -4.5486e-01,\n",
      "          6.8331e-01,  7.2306e-02,  6.7520e-01, -1.7345e-01,  8.5784e-01,\n",
      "          7.0088e-01, -9.0219e-01,  7.6329e-01, -6.3902e-01,  5.9577e-01],\n",
      "        [-4.4712e-01,  1.0000e+00, -1.1246e-01,  1.2019e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  6.0078e-01, -4.8815e-01,\n",
      "          6.4848e-01,  2.2428e-03,  6.8116e-01, -1.9600e-01,  8.5029e-01,\n",
      "          7.0572e-01, -9.0013e-01,  7.7411e-01, -6.6896e-01,  6.0602e-01],\n",
      "        [-5.2847e-01,  1.0000e+00, -8.0144e-02, -2.0762e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.5270e-01,  1.0000e+00,  5.5962e-01, -5.2323e-01,\n",
      "          6.8406e-01,  5.5843e-02,  6.8117e-01, -1.9760e-01,  8.5694e-01,\n",
      "          7.0352e-01, -9.0436e-01,  7.7430e-01, -6.6449e-01,  5.9954e-01],\n",
      "        [-2.6348e-01,  1.0000e+00,  8.1390e-04,  6.0000e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.4145e-01,  1.0000e+00,  6.0004e-01, -6.2866e-01,\n",
      "          5.7918e-01,  6.1046e-02,  6.7698e-01, -2.3972e-01,  8.4279e-01,\n",
      "          6.8307e-01, -8.9095e-01,  8.2811e-01, -7.1784e-01,  6.1567e-01],\n",
      "        [-6.7680e-02,  1.0000e+00, -5.0437e-02,  3.6782e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.4083e-01,  1.0000e+00,  5.3670e-01, -4.6674e-01,\n",
      "          6.2202e-01,  5.6494e-02,  6.7147e-01, -1.9982e-01,  8.5170e-01,\n",
      "          6.8838e-01, -8.9936e-01,  7.8231e-01, -6.5704e-01,  5.9941e-01],\n",
      "        [-4.3367e-01,  1.0000e+00, -8.9936e-02,  2.7977e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.5403e-01,  1.0000e+00,  5.7070e-01, -4.7158e-01,\n",
      "          6.5662e-01,  2.8846e-02,  6.7704e-01, -1.8991e-01,  8.4506e-01,\n",
      "          6.9813e-01, -8.9968e-01,  7.7186e-01, -6.5605e-01,  5.9731e-01],\n",
      "        [-6.0301e-01,  1.0000e+00, -7.2631e-02,  3.6000e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.5549e-01,  1.0000e+00,  5.6927e-01, -5.7504e-01,\n",
      "          6.4534e-01,  1.0992e-02,  6.8178e-01, -2.2210e-01,  8.4829e-01,\n",
      "          7.0010e-01, -8.9739e-01,  7.9001e-01, -6.8685e-01,  6.0153e-01],\n",
      "        [-4.3930e-01,  1.0000e+00, -8.5803e-02,  7.1208e-02, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8491e-01,  1.0000e+00,  5.5791e-01, -5.4432e-01,\n",
      "          6.3929e-01,  3.9419e-02,  6.7974e-01, -2.3477e-01,  8.5123e-01,\n",
      "          6.9970e-01, -9.0100e-01,  7.8538e-01, -6.9074e-01,  6.0372e-01],\n",
      "        [-5.9979e-01,  1.0000e+00, -6.1506e-02,  3.7745e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9203e-01,  1.0000e+00,  6.6425e-01, -5.9383e-01,\n",
      "          5.8181e-01, -8.0496e-03,  6.8162e-01, -2.5719e-01,  8.4089e-01,\n",
      "          6.9056e-01, -8.9271e-01,  7.9174e-01, -7.2459e-01,  6.1102e-01],\n",
      "        [-4.4423e-01,  1.0000e+00, -4.7259e-02,  2.8673e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8531e-01,  1.0000e+00,  5.8550e-01, -5.8249e-01,\n",
      "          6.1849e-01,  4.4572e-02,  6.8070e-01, -2.3022e-01,  8.4594e-01,\n",
      "          6.9139e-01, -8.9603e-01,  7.9950e-01, -6.9791e-01,  6.0351e-01],\n",
      "        [-7.5322e-01,  1.0000e+00, -7.3768e-02,  2.1194e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8778e-01,  1.0000e+00,  6.3902e-01, -5.5622e-01,\n",
      "          6.3523e-01,  8.4427e-03,  6.8582e-01, -2.1038e-01,  8.3593e-01,\n",
      "          6.9710e-01, -8.9619e-01,  7.9240e-01, -6.8889e-01,  6.0078e-01],\n",
      "        [-4.9345e-01,  1.0000e+00,  6.5766e-03,  5.1921e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8768e-01,  1.0000e+00,  5.8698e-01, -5.2698e-01,\n",
      "          6.0503e-01,  2.9506e-03,  6.8361e-01, -2.1062e-01,  8.4060e-01,\n",
      "          6.8893e-01, -8.9588e-01,  7.8154e-01, -6.7393e-01,  5.9950e-01],\n",
      "        [-6.6881e-01,  1.0000e+00, -3.1412e-02,  4.4024e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9966e-01,  1.0000e+00,  6.1310e-01, -5.4831e-01,\n",
      "          6.2645e-01, -4.7085e-02,  6.8572e-01, -2.1408e-01,  8.4949e-01,\n",
      "          6.9958e-01, -8.9808e-01,  7.8380e-01, -7.1372e-01,  6.0635e-01],\n",
      "        [-4.1909e-01,  1.0000e+00, -5.1049e-02,  2.0179e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9965e-01,  1.0000e+00,  5.8603e-01, -6.2594e-01,\n",
      "          6.0999e-01,  1.7881e-02,  6.8255e-01, -2.6375e-01,  8.5572e-01,\n",
      "          7.0567e-01, -8.9712e-01,  8.1128e-01, -7.2798e-01,  6.2107e-01],\n",
      "        [-5.9088e-01,  1.0000e+00, -5.5411e-02,  4.0000e-02, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9903e-01,  1.0000e+00,  6.5655e-01, -4.9866e-01,\n",
      "          6.3798e-01, -5.6846e-02,  6.8560e-01, -1.9666e-01,  8.4262e-01,\n",
      "          7.1566e-01, -8.9689e-01,  7.6546e-01, -6.8881e-01,  6.1189e-01],\n",
      "        [-5.4756e-01,  1.0000e+00, -6.1967e-02,  2.1020e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9875e-01,  1.0000e+00,  6.2215e-01, -5.8058e-01,\n",
      "          6.2502e-01,  1.6103e-02,  6.8376e-01, -2.2923e-01,  8.5519e-01,\n",
      "          7.0094e-01, -9.0102e-01,  8.0436e-01, -7.0306e-01,  6.1677e-01],\n",
      "        [-5.6992e-01,  1.0000e+00, -2.3950e-02,  1.4307e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.6405e-01,  1.0000e+00,  5.6233e-01, -5.8091e-01,\n",
      "          6.3099e-01,  2.6197e-03,  6.8453e-01, -2.2936e-01,  8.5836e-01,\n",
      "          7.0488e-01, -9.0117e-01,  7.9474e-01, -6.9062e-01,  6.1103e-01],\n",
      "        [-5.3009e-01,  1.0000e+00, -3.0723e-02,  2.7771e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.5569e-01,  1.0000e+00,  5.7490e-01, -5.5057e-01,\n",
      "          6.0230e-01,  4.9114e-02,  6.7852e-01, -2.1473e-01,  8.5003e-01,\n",
      "          6.9782e-01, -8.9235e-01,  8.0483e-01, -6.7455e-01,  6.0922e-01],\n",
      "        [-6.1798e-01,  1.0000e+00, -5.1503e-02,  3.5995e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9021e-01,  1.0000e+00,  6.6402e-01, -5.6831e-01,\n",
      "          6.1688e-01, -4.9039e-02,  6.7791e-01, -2.4120e-01,  8.3587e-01,\n",
      "          7.0723e-01, -8.9237e-01,  7.8437e-01, -7.1962e-01,  6.0575e-01],\n",
      "        [-3.7844e-01,  1.0000e+00, -2.9048e-02,  2.9428e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9372e-01,  1.0000e+00,  6.1822e-01, -5.0393e-01,\n",
      "          6.4621e-01, -4.1931e-03,  6.7718e-01, -2.0337e-01,  8.5033e-01,\n",
      "          7.0935e-01, -8.9779e-01,  7.8667e-01, -6.9938e-01,  6.1248e-01],\n",
      "        [-4.1601e-01,  1.0000e+00,  4.9452e-02,  1.2000e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9891e-01,  1.0000e+00,  5.9406e-01, -5.7535e-01,\n",
      "          5.8266e-01,  4.3930e-03,  6.7587e-01, -2.5639e-01,  8.5471e-01,\n",
      "          6.9942e-01, -8.9558e-01,  8.0197e-01, -7.1057e-01,  6.1511e-01],\n",
      "        [-6.7404e-01,  1.0000e+00,  4.7630e-02,  3.9309e-02, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8595e-01,  1.0000e+00,  5.8779e-01, -6.3760e-01,\n",
      "          5.9105e-01,  3.1082e-02,  6.8193e-01, -2.6287e-01,  8.5132e-01,\n",
      "          7.0196e-01, -8.9649e-01,  8.0761e-01, -7.0490e-01,  6.0651e-01],\n",
      "        [-4.4523e-01,  1.0000e+00, -1.1603e-02,  2.8132e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9993e-01,  1.0000e+00,  6.2176e-01, -5.7226e-01,\n",
      "          6.1429e-01,  2.8279e-02,  6.8193e-01, -2.1611e-01,  8.4482e-01,\n",
      "          6.9787e-01, -8.9749e-01,  8.0521e-01, -6.9726e-01,  6.1018e-01],\n",
      "        [-6.5224e-01,  1.0000e+00,  4.0281e-02,  4.3995e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9975e-01,  1.0000e+00,  6.6267e-01, -5.1847e-01,\n",
      "          6.0498e-01, -3.2852e-02,  6.7972e-01, -2.0797e-01,  8.3537e-01,\n",
      "          6.9748e-01, -8.9450e-01,  7.9390e-01, -7.0511e-01,  6.0661e-01],\n",
      "        [-5.1558e-01,  1.0000e+00, -5.0434e-02,  2.1661e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8835e-01,  1.0000e+00,  5.7560e-01, -5.6287e-01,\n",
      "          6.7171e-01,  2.1279e-02,  6.8625e-01, -2.0386e-01,  8.5600e-01,\n",
      "          7.0326e-01, -9.0228e-01,  7.8934e-01, -6.8833e-01,  6.1152e-01],\n",
      "        [-6.4174e-01,  1.0000e+00, -7.9828e-02,  2.8032e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9974e-01,  1.0000e+00,  6.6740e-01, -6.2698e-01,\n",
      "          5.9974e-01,  2.2514e-02,  6.8551e-01, -2.3667e-01,  8.3939e-01,\n",
      "          6.9754e-01, -8.9532e-01,  8.1423e-01, -7.1877e-01,  6.1125e-01],\n",
      "        [-5.6957e-01,  1.0000e+00, -6.9399e-02,  2.8000e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9969e-01,  1.0000e+00,  6.4837e-01, -5.3300e-01,\n",
      "          6.1199e-01,  8.0501e-03,  6.8219e-01, -2.2560e-01,  8.4175e-01,\n",
      "          6.9821e-01, -9.0058e-01,  7.8713e-01, -6.8998e-01,  6.0448e-01],\n",
      "        [-5.1998e-01,  1.0000e+00, -6.5907e-02,  3.9899e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  6.4840e-01, -4.8928e-01,\n",
      "          6.2930e-01, -1.5987e-02,  6.7582e-01, -2.0421e-01,  8.3871e-01,\n",
      "          7.0149e-01, -8.9789e-01,  7.7371e-01, -6.8137e-01,  6.0885e-01]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "2\n",
      "tensor([[ 0.9998, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8165,  1.0000,\n",
      "         -0.5224, -0.6635,  0.5631,  0.0698, -0.3002, -0.2192, -0.3005, -0.0874,\n",
      "          0.0350, -0.1713,  0.1992,  0.2042],\n",
      "        [ 0.9823, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8013,  1.0000,\n",
      "         -0.5255, -0.6612,  0.5666,  0.0706, -0.2999, -0.2192, -0.3017, -0.0870,\n",
      "          0.0349, -0.1721,  0.1986,  0.2045],\n",
      "        [ 0.9947, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8228,  1.0000,\n",
      "         -0.5247, -0.6648,  0.5629,  0.0686, -0.3008, -0.2205, -0.3013, -0.0870,\n",
      "          0.0359, -0.1716,  0.1993,  0.2034],\n",
      "        [ 0.9999, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8413,  1.0000,\n",
      "         -0.5223, -0.6638,  0.5615,  0.0685, -0.3002, -0.2196, -0.2999, -0.0876,\n",
      "          0.0354, -0.1711,  0.1991,  0.2038],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8388,  1.0000,\n",
      "         -0.5222, -0.6638,  0.5615,  0.0682, -0.3004, -0.2199, -0.3001, -0.0879,\n",
      "          0.0358, -0.1711,  0.1994,  0.2036],\n",
      "        [ 0.9986, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8826,  1.0000,\n",
      "         -0.5202, -0.6621,  0.5586,  0.0667, -0.3004, -0.2186, -0.2992, -0.0877,\n",
      "          0.0353, -0.1698,  0.1985,  0.2038],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8442,  1.0000,\n",
      "         -0.5227, -0.6636,  0.5620,  0.0696, -0.2999, -0.2195, -0.2999, -0.0870,\n",
      "          0.0349, -0.1710,  0.1985,  0.2041],\n",
      "        [ 0.9982, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8279,  1.0000,\n",
      "         -0.5229, -0.6624,  0.5636,  0.0701, -0.2995, -0.2190, -0.3005, -0.0869,\n",
      "          0.0345, -0.1711,  0.1983,  0.2046],\n",
      "        [ 0.9954, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7897,  1.0000,\n",
      "         -0.5254, -0.6652,  0.5643,  0.0697, -0.3011, -0.2207, -0.3017, -0.0871,\n",
      "          0.0361, -0.1722,  0.2001,  0.2034],\n",
      "        [ 0.9592, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8335,  1.0000,\n",
      "         -0.5249, -0.6588,  0.5669,  0.0686, -0.3015, -0.2188, -0.3028, -0.0872,\n",
      "          0.0358, -0.1717,  0.1984,  0.2034],\n",
      "        [ 0.9994, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7848,  1.0000,\n",
      "         -0.5239, -0.6642,  0.5661,  0.0729, -0.2993, -0.2192, -0.3013, -0.0863,\n",
      "          0.0335, -0.1718,  0.1989,  0.2051],\n",
      "        [ 0.9992, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7962,  1.0000,\n",
      "         -0.5241, -0.6645,  0.5654,  0.0708, -0.2999, -0.2199, -0.3011, -0.0871,\n",
      "          0.0351, -0.1720,  0.1994,  0.2043],\n",
      "        [ 0.9993, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8254,  1.0000,\n",
      "         -0.5234, -0.6645,  0.5636,  0.0697, -0.3002, -0.2201, -0.3006, -0.0873,\n",
      "          0.0355, -0.1717,  0.1992,  0.2039],\n",
      "        [ 0.9998, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8273,  1.0000,\n",
      "         -0.5230, -0.6643,  0.5633,  0.0696, -0.3001, -0.2198, -0.3006, -0.0871,\n",
      "          0.0354, -0.1713,  0.1991,  0.2039],\n",
      "        [ 0.9998, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7936,  1.0000,\n",
      "         -0.5238, -0.6648,  0.5657,  0.0707, -0.3004, -0.2201, -0.3014, -0.0872,\n",
      "          0.0352, -0.1721,  0.1997,  0.2041],\n",
      "        [ 0.9741, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8422,  1.0000,\n",
      "         -0.5240, -0.6589,  0.5653,  0.0707, -0.2998, -0.2179, -0.3010, -0.0864,\n",
      "          0.0340, -0.1712,  0.1971,  0.2046],\n",
      "        [ 0.9622, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8890,  1.0000,\n",
      "         -0.5237, -0.6551,  0.5635,  0.0674, -0.3000, -0.2176, -0.3005, -0.0874,\n",
      "          0.0361, -0.1709,  0.1961,  0.2035],\n",
      "        [ 0.9991, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8744,  1.0000,\n",
      "         -0.5209, -0.6635,  0.5605,  0.0662, -0.3007, -0.2197, -0.2996, -0.0884,\n",
      "          0.0367, -0.1705,  0.1996,  0.2031],\n",
      "        [ 0.9886, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8473,  1.0000,\n",
      "         -0.5232, -0.6615,  0.5641,  0.0693, -0.2999, -0.2190, -0.3007, -0.0870,\n",
      "          0.0350, -0.1711,  0.1981,  0.2041],\n",
      "        [ 0.9999, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8584,  1.0000,\n",
      "         -0.5218, -0.6637,  0.5614,  0.0675, -0.3005, -0.2198, -0.3000, -0.0878,\n",
      "          0.0361, -0.1708,  0.1991,  0.2034],\n",
      "        [ 0.9982, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8004,  1.0000,\n",
      "         -0.5235, -0.6647,  0.5679,  0.0693, -0.3007, -0.2206, -0.3029, -0.0875,\n",
      "          0.0348, -0.1718,  0.1999,  0.2042],\n",
      "        [ 0.9998, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7989,  1.0000,\n",
      "         -0.5240, -0.6634,  0.5664,  0.0714, -0.2995, -0.2197, -0.3014, -0.0867,\n",
      "          0.0349, -0.1718,  0.1991,  0.2045],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7632,  1.0000,\n",
      "         -0.5254, -0.6653,  0.5675,  0.0716, -0.3001, -0.2206, -0.3019, -0.0872,\n",
      "          0.0353, -0.1728,  0.2001,  0.2042],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8166,  1.0000,\n",
      "         -0.5223, -0.6652,  0.5639,  0.0675, -0.3012, -0.2205, -0.3012, -0.0884,\n",
      "          0.0365, -0.1717,  0.2005,  0.2032],\n",
      "        [ 0.9957, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7950,  1.0000,\n",
      "         -0.5245, -0.6647,  0.5660,  0.0701, -0.3008, -0.2204, -0.3018, -0.0875,\n",
      "          0.0355, -0.1723,  0.2000,  0.2038],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7598,  1.0000,\n",
      "         -0.5252, -0.6649,  0.5674,  0.0721, -0.2999, -0.2204, -0.3021, -0.0869,\n",
      "          0.0348, -0.1727,  0.1998,  0.2046],\n",
      "        [ 0.9602, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8474,  1.0000,\n",
      "         -0.5245, -0.6544,  0.5667,  0.0696, -0.2996, -0.2172, -0.3017, -0.0869,\n",
      "          0.0351, -0.1715,  0.1961,  0.2043],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8243,  1.0000,\n",
      "         -0.5233, -0.6632,  0.5636,  0.0694, -0.2998, -0.2198, -0.3004, -0.0876,\n",
      "          0.0359, -0.1716,  0.1994,  0.2040],\n",
      "        [ 0.9998, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8223,  1.0000,\n",
      "         -0.5237, -0.6648,  0.5636,  0.0690, -0.3005, -0.2206, -0.3007, -0.0876,\n",
      "          0.0360, -0.1719,  0.1996,  0.2036],\n",
      "        [ 0.9990, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8292,  1.0000,\n",
      "         -0.5235, -0.6634,  0.5638,  0.0702, -0.2998, -0.2197, -0.3005, -0.0870,\n",
      "          0.0350, -0.1714,  0.1986,  0.2042],\n",
      "        [ 0.9891, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8094,  1.0000,\n",
      "         -0.5255, -0.6629,  0.5663,  0.0715, -0.2997, -0.2197, -0.3015, -0.0863,\n",
      "          0.0344, -0.1719,  0.1983,  0.2044],\n",
      "        [ 0.9996, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.9016,  1.0000,\n",
      "         -0.5196, -0.6629,  0.5582,  0.0644, -0.3012, -0.2196, -0.2993, -0.0887,\n",
      "          0.0373, -0.1700,  0.1993,  0.2026]])\n",
      "tensor([[ 0.9998, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8165,  1.0000,\n",
      "         -0.5224, -0.6635,  0.5631,  0.0698, -0.3002, -0.2192, -0.3005, -0.0874,\n",
      "          0.0350, -0.1713,  0.1992,  0.2042],\n",
      "        [ 0.9823, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8013,  1.0000,\n",
      "         -0.5255, -0.6612,  0.5666,  0.0706, -0.2999, -0.2192, -0.3017, -0.0870,\n",
      "          0.0349, -0.1721,  0.1986,  0.2045],\n",
      "        [ 0.9947, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8228,  1.0000,\n",
      "         -0.5247, -0.6648,  0.5629,  0.0686, -0.3008, -0.2205, -0.3013, -0.0870,\n",
      "          0.0359, -0.1716,  0.1993,  0.2034],\n",
      "        [ 0.9999, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8413,  1.0000,\n",
      "         -0.5223, -0.6638,  0.5615,  0.0685, -0.3002, -0.2196, -0.2999, -0.0876,\n",
      "          0.0354, -0.1711,  0.1991,  0.2038],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8388,  1.0000,\n",
      "         -0.5222, -0.6638,  0.5615,  0.0682, -0.3004, -0.2199, -0.3001, -0.0879,\n",
      "          0.0358, -0.1711,  0.1994,  0.2036],\n",
      "        [ 0.9986, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8826,  1.0000,\n",
      "         -0.5202, -0.6621,  0.5586,  0.0667, -0.3004, -0.2186, -0.2992, -0.0877,\n",
      "          0.0353, -0.1698,  0.1985,  0.2038],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8442,  1.0000,\n",
      "         -0.5227, -0.6636,  0.5620,  0.0696, -0.2999, -0.2195, -0.2999, -0.0870,\n",
      "          0.0349, -0.1710,  0.1985,  0.2041],\n",
      "        [ 0.9982, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8279,  1.0000,\n",
      "         -0.5229, -0.6624,  0.5636,  0.0701, -0.2995, -0.2190, -0.3005, -0.0869,\n",
      "          0.0345, -0.1711,  0.1983,  0.2046],\n",
      "        [ 0.9954, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7897,  1.0000,\n",
      "         -0.5254, -0.6652,  0.5643,  0.0697, -0.3011, -0.2207, -0.3017, -0.0871,\n",
      "          0.0361, -0.1722,  0.2001,  0.2034],\n",
      "        [ 0.9592, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8335,  1.0000,\n",
      "         -0.5249, -0.6588,  0.5669,  0.0686, -0.3015, -0.2188, -0.3028, -0.0872,\n",
      "          0.0358, -0.1717,  0.1984,  0.2034],\n",
      "        [ 0.9994, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7848,  1.0000,\n",
      "         -0.5239, -0.6642,  0.5661,  0.0729, -0.2993, -0.2192, -0.3013, -0.0863,\n",
      "          0.0335, -0.1718,  0.1989,  0.2051],\n",
      "        [ 0.9992, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7962,  1.0000,\n",
      "         -0.5241, -0.6645,  0.5654,  0.0708, -0.2999, -0.2199, -0.3011, -0.0871,\n",
      "          0.0351, -0.1720,  0.1994,  0.2043],\n",
      "        [ 0.9993, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8254,  1.0000,\n",
      "         -0.5234, -0.6645,  0.5636,  0.0697, -0.3002, -0.2201, -0.3006, -0.0873,\n",
      "          0.0355, -0.1717,  0.1992,  0.2039],\n",
      "        [ 0.9998, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8273,  1.0000,\n",
      "         -0.5230, -0.6643,  0.5633,  0.0696, -0.3001, -0.2198, -0.3006, -0.0871,\n",
      "          0.0354, -0.1713,  0.1991,  0.2039],\n",
      "        [ 0.9998, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7936,  1.0000,\n",
      "         -0.5238, -0.6648,  0.5657,  0.0707, -0.3004, -0.2201, -0.3014, -0.0872,\n",
      "          0.0352, -0.1721,  0.1997,  0.2041],\n",
      "        [ 0.9741, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8422,  1.0000,\n",
      "         -0.5240, -0.6589,  0.5653,  0.0707, -0.2998, -0.2179, -0.3010, -0.0864,\n",
      "          0.0340, -0.1712,  0.1971,  0.2046],\n",
      "        [ 0.9622, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8890,  1.0000,\n",
      "         -0.5237, -0.6551,  0.5635,  0.0674, -0.3000, -0.2176, -0.3005, -0.0874,\n",
      "          0.0361, -0.1709,  0.1961,  0.2035],\n",
      "        [ 0.9991, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8744,  1.0000,\n",
      "         -0.5209, -0.6635,  0.5605,  0.0662, -0.3007, -0.2197, -0.2996, -0.0884,\n",
      "          0.0367, -0.1705,  0.1996,  0.2031],\n",
      "        [ 0.9886, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8473,  1.0000,\n",
      "         -0.5232, -0.6615,  0.5641,  0.0693, -0.2999, -0.2190, -0.3007, -0.0870,\n",
      "          0.0350, -0.1711,  0.1981,  0.2041],\n",
      "        [ 0.9999, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8584,  1.0000,\n",
      "         -0.5218, -0.6637,  0.5614,  0.0675, -0.3005, -0.2198, -0.3000, -0.0878,\n",
      "          0.0361, -0.1708,  0.1991,  0.2034],\n",
      "        [ 0.9982, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8004,  1.0000,\n",
      "         -0.5235, -0.6647,  0.5679,  0.0693, -0.3007, -0.2206, -0.3029, -0.0875,\n",
      "          0.0348, -0.1718,  0.1999,  0.2042],\n",
      "        [ 0.9998, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7989,  1.0000,\n",
      "         -0.5240, -0.6634,  0.5664,  0.0714, -0.2995, -0.2197, -0.3014, -0.0867,\n",
      "          0.0349, -0.1718,  0.1991,  0.2045],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7632,  1.0000,\n",
      "         -0.5254, -0.6653,  0.5675,  0.0716, -0.3001, -0.2206, -0.3019, -0.0872,\n",
      "          0.0353, -0.1728,  0.2001,  0.2042],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8166,  1.0000,\n",
      "         -0.5223, -0.6652,  0.5639,  0.0675, -0.3012, -0.2205, -0.3012, -0.0884,\n",
      "          0.0365, -0.1717,  0.2005,  0.2032],\n",
      "        [ 0.9957, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7950,  1.0000,\n",
      "         -0.5245, -0.6647,  0.5660,  0.0701, -0.3008, -0.2204, -0.3018, -0.0875,\n",
      "          0.0355, -0.1723,  0.2000,  0.2038],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7598,  1.0000,\n",
      "         -0.5252, -0.6649,  0.5674,  0.0721, -0.2999, -0.2204, -0.3021, -0.0869,\n",
      "          0.0348, -0.1727,  0.1998,  0.2046],\n",
      "        [ 0.9602, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8474,  1.0000,\n",
      "         -0.5245, -0.6544,  0.5667,  0.0696, -0.2996, -0.2172, -0.3017, -0.0869,\n",
      "          0.0351, -0.1715,  0.1961,  0.2043],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8243,  1.0000,\n",
      "         -0.5233, -0.6632,  0.5636,  0.0694, -0.2998, -0.2198, -0.3004, -0.0876,\n",
      "          0.0359, -0.1716,  0.1994,  0.2040],\n",
      "        [ 0.9998, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8223,  1.0000,\n",
      "         -0.5237, -0.6648,  0.5636,  0.0690, -0.3005, -0.2206, -0.3007, -0.0876,\n",
      "          0.0360, -0.1719,  0.1996,  0.2036],\n",
      "        [ 0.9990, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8292,  1.0000,\n",
      "         -0.5235, -0.6634,  0.5638,  0.0702, -0.2998, -0.2197, -0.3005, -0.0870,\n",
      "          0.0350, -0.1714,  0.1986,  0.2042],\n",
      "        [ 0.9891, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8094,  1.0000,\n",
      "         -0.5255, -0.6629,  0.5663,  0.0715, -0.2997, -0.2197, -0.3015, -0.0863,\n",
      "          0.0344, -0.1719,  0.1983,  0.2044],\n",
      "        [ 0.9996, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.9016,  1.0000,\n",
      "         -0.5196, -0.6629,  0.5582,  0.0644, -0.3012, -0.2196, -0.2993, -0.0887,\n",
      "          0.0373, -0.1700,  0.1993,  0.2026]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "cumModel = hiddens[0][2]\n",
    "iter = 1\n",
    "for model in hiddens[1:]:\n",
    "    if model[1] != -1:\n",
    "        if iter == 0:\n",
    "            cumModel = model[2]\n",
    "        else:\n",
    "            cumModel = cumModel + model[2]\n",
    "        iter += 1\n",
    "    else:\n",
    "        print(model[0])\n",
    "        print(cumModel/iter)\n",
    "        print(model[2])\n",
    "        print(cumModel/iter - model[2])\n",
    "        iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c81689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "list = [0,1,2]\n",
    "print(list[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3503aa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# INDIVIDUAL OBU TEST SETUP\n",
    "testOBU = OBU(\n",
    "    inputSize = 7,  # Number of features per BSM\n",
    "    units = 20, # Number of hidden cells\n",
    "    motors = 8, # Number of motor neurons\n",
    "    outputs = 20, # Number of possible labels\n",
    "    epochs = 50,\n",
    "    lr = 0.01,\n",
    "    gpu = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5f3d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 78/78 [00:04<00:00, 19.00it/s, v_num=634, trainLoss=2.520]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 78/78 [00:04<00:00, 18.91it/s, v_num=634, trainLoss=2.520]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.5195, device='mps:0', grad_fn=<NllLoss2DBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TRAIN INDIVIDUAL OBU\n",
    "testOBU.fit(testingDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053d8e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 10 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:   9%|▉         | 7/78 [00:00<00:03, 18.12it/s, v_num=595, trainLoss=1.800] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "testOBU.fit(testingDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1c4dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([124774, 10, 20])\n",
      "0.2970971516501835\n",
      "1.0\n",
      "Model got 370700/1247740 right.\n",
      "Accuracy: 0.2970971516501835, Precision: 0.2970971516501835, Recall: 1.0, F1 Score: 0.4580954499394479\n",
      "877040, 70.29028483498165% Zeroes, 370700 Non Zero entries.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Model got 370700/1247740 right. Accuracy: 0.2970971516501835, Precision: 0.2970971516501835, Recall: 1.0, F1 Score: 0.4580954499394479'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testOBU.test(testDataIn, testDataOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382a51c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "save = OBU(testOBU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b2a6e7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12480, 10, 20])\n",
      "Model got 6232/124800 right. Accuracy of 4.993589743589744%\n",
      "69.88782051282051% Zeroes.\n"
     ]
    }
   ],
   "source": [
    "# RUN TEST ON SMALL DATASET INDIVIDUAL MODEL\n",
    "_, _, perc, _ = testOBU.test(inTest, outTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c51f439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([196990, 10, 20])\n",
      "Model got 1159988/1969900 right. Accuracy of 58.88562871211737%\n",
      "40.353165135286055% Zeroes.\n"
     ]
    }
   ],
   "source": [
    "# RUN TEST ON LARGE DATASET INDIVIDUAL MODEL\n",
    "_, _, perc, _ = testOBU.test(testDataIn, testDataOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5f9608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19700, 10, 20])\n",
      "Model got 116065/197000 right. Accuracy of 58.91624365482233%\n",
      "41.08375634517766% Zeroes.\n"
     ]
    }
   ],
   "source": [
    "# TESTING COPY\n",
    "_, _, perc, _ = save.test(inTest, outTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a959600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "print(testOBU.getHidden() - save.getHidden())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f79ef7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        # Loop through messages from reciever\n",
    "        newData.append(dataSet[lastRecieverCount+index:lastRecieverCount +index+10])\n",
    "        index += 5\n",
    "print(testOBU.model.fF.weight - save.model.fF.weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kettering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
