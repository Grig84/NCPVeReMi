{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a997a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from ncps.wirings import AutoNCP\n",
    "from ncps.torch import CfC\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from random import sample\n",
    "import os\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "batchSize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed3cc2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\will\\AppData\\Local\\Temp\\ipykernel_20268\\2495743071.py:22: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  subData = torch.Tensor(subData)\n"
     ]
    }
   ],
   "source": [
    "# FORMATTING DATASET FOR FED. LEARNING\n",
    "dataFile = 'Data/CfCMultiExtension/RandomPos_0709.csv'\n",
    "dataSet = genfromtxt(dataFile, delimiter=',')\n",
    "dataSet = np.delete(dataSet, 0, axis=0) # Remove the labels at the beginning of the dataset\n",
    "\n",
    "# Devide dataset into reciever groups\n",
    "fedDataSet = dataSet[np.argsort(dataSet[:, 1])] # Sort dataset by reciver ID\n",
    "_, counts = np.unique(fedDataSet[:,1], return_counts=True) # Get the indexes of the change in datasets.\n",
    "sum = 0\n",
    "for i in range(len(counts)): # Accumulating counts so that we can use them as indexes\n",
    "    sum += counts[i]\n",
    "    counts[i] = sum\n",
    "fedDataSet = np.split(fedDataSet, counts) # Split larger dataset into per vehicle datasets.\n",
    "\n",
    "newData = [] \n",
    "for reciever in fedDataSet: # Go through all vehicle datasets\n",
    "    subData = []\n",
    "    index = 0\n",
    "    while index < len(reciever) - 10: # organize the new dataset as a list of chuncks of 10 messages \n",
    "        subData.append(reciever[index:index+10])\n",
    "        index += 5\n",
    "    subData = torch.Tensor(subData)\n",
    "    if subData.shape[0] != 0:\n",
    "        newData.append(subData) # Create tensor from per vehicle dataset and add to list of datas.\n",
    "fedDataSet = newData\n",
    "# Final output of this cell is fedDataSet, a list of the datasets of each vehicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1794295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([56, 10, 12])\n"
     ]
    }
   ],
   "source": [
    "print(fedDataSet[25].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2491f35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# #Current Simulation File\\ndataFile = 'Data/CfCMultiExtension/RandomPos_0709.csv'\\n\\ndataSet = genfromtxt(dataFile, delimiter=',')\\n\\nbatchSize = 64\\n# Ceate dataloader and fill with (BSM, attk#). Expanding to add 0th dimension for batches.\\n# Batch size should be 64 for the low density simulations and 128 for high density simulations.\\n# No shuffle to keep batches on same vehicle.\\n# Num_workers is set to = num CPU cores\\ndataSet[0:-1,:] = dataSet[1:,:] # Get rid of the first null value of the dataset\\n# Sort Dataset by reciever id to pass on to every car.\\ndataSet = dataSet[np.argsort(dataSet[:, 1])]\\nprint(dataSet.shape)\\n# count subsets per vehicle\\nprint(dataSet[0])\\nunq, counts = np.unique(dataSet[:, 1], return_counts = True)\\nrecvr = 0\\nlastRecieverCount = 0\\nnewData = []\\nprint(counts)\\n# Organize dataset into sets of 10 messages by reciever\\nwhile recvr < counts.shape[0]:\\n    # Loop through reciever\\n    index = 0\\n    while index < counts[recvr] - 10:\\n        # Loop through messages from reciever\\n        newData.append(dataSet[lastRecieverCount+index:lastRecieverCount +index+10])\\n        index += 5\\n    recvr += 1\\n    lastRecieverCount = counts[recvr-1]\\ndataSet = torch.tensor(newData)\\nprint(dataSet.shape)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ***** DEPRECATED *****\n",
    "'''\n",
    "# #Current Simulation File\n",
    "dataFile = 'Data/CfCMultiExtension/RandomPos_0709.csv'\n",
    "\n",
    "dataSet = genfromtxt(dataFile, delimiter=',')\n",
    "\n",
    "batchSize = 64\n",
    "# Ceate dataloader and fill with (BSM, attk#). Expanding to add 0th dimension for batches.\n",
    "# Batch size should be 64 for the low density simulations and 128 for high density simulations.\n",
    "# No shuffle to keep batches on same vehicle.\n",
    "# Num_workers is set to = num CPU cores\n",
    "dataSet[0:-1,:] = dataSet[1:,:] # Get rid of the first null value of the dataset\n",
    "# Sort Dataset by reciever id to pass on to every car.\n",
    "dataSet = dataSet[np.argsort(dataSet[:, 1])]\n",
    "print(dataSet.shape)\n",
    "# count subsets per vehicle\n",
    "print(dataSet[0])\n",
    "unq, counts = np.unique(dataSet[:, 1], return_counts = True)\n",
    "recvr = 0\n",
    "lastRecieverCount = 0\n",
    "newData = []\n",
    "print(counts)\n",
    "# Organize dataset into sets of 10 messages by reciever\n",
    "while recvr < counts.shape[0]:\n",
    "    # Loop through reciever\n",
    "    index = 0\n",
    "    while index < counts[recvr] - 10:\n",
    "        # Loop through messages from reciever\n",
    "        newData.append(dataSet[lastRecieverCount+index:lastRecieverCount +index+10])\n",
    "        index += 5\n",
    "    recvr += 1\n",
    "    lastRecieverCount = counts[recvr-1]\n",
    "dataSet = torch.tensor(newData)\n",
    "print(dataSet.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65c814c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROPER FORMATTING FOR TESTING DATASETS\n",
    "#Time sequences are 10 timepoints (Messages) with 7 features per message.\n",
    "#Organized by car.\n",
    "unq, counts = np.unique(dataSet[:, 2], return_counts = True)\n",
    "sender = 0\n",
    "lastSenderCount = 0\n",
    "newData = []\n",
    "# Organize dataset into sets of 10 messages by sender\n",
    "while sender < counts.shape[0]:\n",
    "    # Loop through sender\n",
    "    index = 0\n",
    "    while index < counts[sender] - 10:\n",
    "        # Loop through messages from sender\n",
    "        newData.append(dataSet[lastSenderCount+index:lastSenderCount +index+10])\n",
    "        index += 5\n",
    "    sender += 1\n",
    "    lastSenderCount += counts[sender-1]\n",
    "dataSet = torch.tensor(newData)\n",
    "leng = dataSet.shape[0]\n",
    "trainPerc = 80\n",
    "# Create seperate datasets for testing and training, using Train Percentage as metric for split\n",
    "trainDataIn = torch.Tensor(dataSet[:int(leng*(trainPerc/100)),:,3:10]).float()\n",
    "trainDataOut = torch.Tensor(np.int_(dataSet[:int(leng*(trainPerc/100)),:,11])).long()\n",
    "testDataIn = torch.Tensor(dataSet[int(leng*(trainPerc/100)):,:,3:10]).float()\n",
    "testDataOut = torch.Tensor(np.int_(dataSet[int(leng*(trainPerc/100)):,:,11])).long()\n",
    "newsetIn = []\n",
    "newsetOut = []\n",
    "testsetIn = []\n",
    "testsetOut = []\n",
    "# Create dataset of 1/100th of the entries for quicker testing during development\n",
    "for index in range(0,int((leng) * (trainPerc/100))):\n",
    "    if not (int(index/10) % 100):\n",
    "        newsetIn.append(dataSet[index,:,3:10])\n",
    "        newsetOut.append((dataSet[index,:,11]))\n",
    "for idx in range(int((leng) * (trainPerc/100)), leng):\n",
    "    if not (int(idx/10) % 10):\n",
    "        testsetIn.append(dataSet[idx,:,3:10])\n",
    "        testsetOut.append((dataSet[idx,:,11]))\n",
    "testingIn = torch.Tensor(np.array(newsetIn)).float()\n",
    "testingOut = torch.Tensor(np.array(newsetOut)).long()\n",
    "inTest = torch.Tensor(np.array(testsetIn)).float()\n",
    "outTest = torch.Tensor(np.array(testsetOut)).long()\n",
    "# Create Dataloaders for all the datasets\n",
    "dataLoaderTrain = data.DataLoader(data.TensorDataset(trainDataIn, trainDataOut), batch_size=batchSize, shuffle=False, num_workers=10, persistent_workers = True, drop_last= True)\n",
    "dataLoaderTest = data.DataLoader(data.TensorDataset(testDataIn, testDataOut), batch_size=batchSize, shuffle=False, num_workers=10, persistent_workers = True, drop_last= True)\n",
    "testingDataLoader = data.DataLoader(data.TensorDataset(testingIn, testingOut), batch_size=batchSize, shuffle = False, num_workers=10, persistent_workers = True, drop_last= True)\n",
    "testingTestData = data.DataLoader(data.TensorDataset(testingIn, testingOut), batch_size=batchSize, shuffle = False, num_workers=10, persistent_workers = True, drop_last= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b158270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12480, 10, 7])\n",
      "torch.Size([12480, 10])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TESTS\n",
    "print(inTest.shape)\n",
    "print(outTest.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1da521c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4]\n",
      " [9 8 7 6]\n",
      " [5 7 8 3]\n",
      " [9 8 7 3]]\n",
      "[[1 2 3 4]\n",
      " [5 7 8 3]\n",
      " [9 8 7 6]\n",
      " [9 8 7 3]]\n"
     ]
    }
   ],
   "source": [
    "#TESTING\n",
    "tom = np.array([[1,2,3,4],[9,8,7,6],[5,7,8,3],[9,8,7,3]])\n",
    "print(tom)\n",
    "tom = tom[np.argsort(tom[:, 1])]\n",
    "print(tom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01abeb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Learner\n",
    "class CfCLearner(pl.LightningModule):\n",
    "    def __init__(self, model, lr):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.lossFunc = nn.CrossEntropyLoss()\n",
    "        self.loss = None\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Get in and out from batch\n",
    "        inputs, target = batch\n",
    "        # Put input through model\n",
    "        output, _ = self.model.forward(inputs)\n",
    "        # Reorganize inputs for use with loss function\n",
    "        output = output.permute(0, 2, 1)\n",
    "        # Calculate Loss using Cross Entropy Loss \n",
    "        loss = self.lossFunc(output, target)\n",
    "        self.log(\"trainLoss\", loss, prog_bar=True)\n",
    "        self.loss = loss\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Get in and out from batch\n",
    "        inputs, target = batch\n",
    "        # Put input through model\n",
    "        output, _ = self.model.forward(inputs)\n",
    "        # Reorganize inputs for use with loss function\n",
    "        output = output.permute(0, 2, 1)\n",
    "        print(f\"output: {output.shape}\")\n",
    "        print(f\"target: {target.shape}\")\n",
    "        # Calculate Loss using Cross Entropy Loss \n",
    "        loss = self.lossFunc(output, target)\n",
    "        self.log(\"valLoss\", loss, prog_bar=True)\n",
    "        self.loss = loss\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.validation_step(batch, batch_idx)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Using AdamW optomizer based on info from paper\n",
    "        # optimizer = torch.optim.AdamW(self.model.parameters(), lr = 0.001)\n",
    "        # return ([optimizer], [torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.6)])\n",
    "        return torch.optim.AdamW(self.model.parameters(), lr = 0.01) # TESTING REMOVING THE SCHEDULER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfb6cf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Model/Module\n",
    "class Modena(nn.Module): \n",
    "    # CfC with feed-forward layer to classify at end.\n",
    "    def __init__(self, inputSize, unitNum = None, motorNum = 2, outputDim = 2, batchFirst = True):\n",
    "        super().__init__()\n",
    "        if isinstance(inputSize, Modena):\n",
    "            self.inputSize = inputSize.inputSize\n",
    "            self.unitNum = inputSize.unitNum\n",
    "            self.motorNum = inputSize.motorNum\n",
    "            self.outputDim = inputSize.outputDim\n",
    "            self.batchFirst = inputSize.batchFirst\n",
    "            # Create NCP wiring for CfC\n",
    "            wiring = AutoNCP(self.unitNum, self.motorNum)\n",
    "            # Create CfC model with inputs and wiring\n",
    "            self.cfc = CfC(self.inputSize, wiring, batch_first=self.batchFirst)\n",
    "            # Create feed-forward layer\n",
    "            self.fF = nn.Linear(self.motorNum, self.outputDim)\n",
    "            self.fF.weight = nn.Parameter(inputSize.fF.weight)\n",
    "        else:\n",
    "            self.inputSize = inputSize\n",
    "            self.unitNum = unitNum\n",
    "            self.motorNum = motorNum\n",
    "            self.outputDim = outputDim\n",
    "            self.batchFirst = batchFirst\n",
    "            # Create NCP wiring for CfC\n",
    "            wiring = AutoNCP(unitNum, motorNum)\n",
    "            # Create CfC model with inputs and wiring\n",
    "            self.cfc = CfC(inputSize, wiring, batch_first=batchFirst)\n",
    "            # Create feed-forward layer\n",
    "            self.fF = nn.Linear(motorNum, outputDim)\n",
    "        \n",
    "\n",
    "    def forward(self, batch, hidden = None):\n",
    "        batch, hidden = self.cfc(batch, hidden) # Pass inputs through CfC\n",
    "        out = nn.functional.relu(self.fF(batch)) # pass through FeedForward Layer, then make 0 minimum\n",
    "        return out, hidden # Return the guess and the hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5406ad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating overall model Class\n",
    "class OBU():\n",
    "    def __init__(self, inputSize, units = 20, motors = 8, outputs = 20, epochs = 10, lr = 0.01, randInt = 0, gpu = False, dataset = None, evil = False):\n",
    "        if isinstance(inputSize, OBU):\n",
    "            self.lr = inputSize.lr\n",
    "            self.epochs = inputSize.epochs\n",
    "            self.gpu = inputSize.gpu\n",
    "            self.model = Modena(inputSize.model)\n",
    "            self.model.load_state_dict(inputSize.model.state_dict())\n",
    "            self.learner = CfCLearner(self.model, self.lr)\n",
    "            self.learner.load_state_dict(inputSize.learner.state_dict())\n",
    "            self.trainer = pl.Trainer(\n",
    "                logger = CSVLogger('log/Fed'), # Set ouput destination of logs, logging accuracy every 50 steps\n",
    "                max_epochs = self.epochs, # Number of epochs to train for\n",
    "                gradient_clip_val = 1, # This is said to stabilize training, but we should test if that is true\n",
    "                accelerator = \"gpu\" if self.gpu else \"cpu\" # Using the GPU to run training or not\n",
    "                )\n",
    "\n",
    "        else:\n",
    "            self.lr = lr\n",
    "            self.epochs = epochs\n",
    "            self.gpu = gpu\n",
    "            self.model = Modena(inputSize, units, motors, outputs)\n",
    "            self.learner = CfCLearner(self.model, lr) # tune units, lr\n",
    "            self.trainer = pl.Trainer(\n",
    "                logger = CSVLogger('log/Fed'), # Set ouput destination of logs, logging accuracy every 50 steps\n",
    "                max_epochs = epochs, # Number of epochs to train for\n",
    "                gradient_clip_val = 1, # This is said to stabilize training, but we should test if that is true\n",
    "                accelerator = \"gpu\" if gpu else \"cpu\" # Using the GPU to run training or not\n",
    "                )\n",
    "        self.prevAccuracy = 0\n",
    "        self.evil = evil\n",
    "        self.nearbyOBUs = []\n",
    "        self.id = None\n",
    "        self.dataset = dataset\n",
    "        self.outnum = 0\n",
    "        self.confidences = []\n",
    "        self.samplingWeights = []\n",
    "        self.priority = 0\n",
    "        self.datalen = 0\n",
    "        self.otherPriorities = []\n",
    "        self.sampling = []\n",
    "        self.curr_loss = 0\n",
    "        self.prev_loss = None\n",
    "        self.trust_loss = 0\n",
    "        self.backupWeights = {'model':self.model.state_dict(), 'learner':self.learner.state_dict()}\n",
    "        self.prevWeights = dict(self.model.state_dict())\n",
    "    \n",
    "\n",
    "        # Overloading add function to create fed.avg. model\n",
    "    def __add__(self, other):\n",
    "        # if self.learner.getHidden() != None and other.learner.getHidden() != None:\n",
    "        self.model.load_state_dict(dict( (n, self.model.state_dict().get(n, 0)+other.model.state_dict().get(n, 0)) for n in set(self.model.state_dict())|set(other.model.state_dict()) ))\n",
    "        # elif other.learner.getHidden() != None:\n",
    "        #     self.model.load_state_dict(other.model.state_dict())\n",
    "        # elif self.learner.getHidden() != None:\n",
    "        #     self.model.load_state_dict(self.model.state_dict())\n",
    "        return self\n",
    "    \n",
    "    def __mul__(self, i):\n",
    "        self.model.load_state_dict(dict((n, self.model.state_dict().get(n, 0)*i) for n in self.model.state_dict()))\n",
    "        return self\n",
    "\n",
    "    # Overloading div. function to average model\n",
    "    def __truediv__(self, i):\n",
    "        \n",
    "        self.model.load_state_dict(dict((n, self.model.state_dict().get(n, 0)/i) for n in self.model.state_dict()))\n",
    "        # self.model.load_state_dict(self.model.state_dict()/i)\n",
    "        # self.learner.setHidden(self.learner.getHidden() / i)\n",
    "        # self.model.fF.weight = nn.Parameter(self.model.fF.weight/i)\n",
    "        return self\n",
    "    \n",
    "    def fit(self, dataLoader):\n",
    "        # calling built in fit function\n",
    "        self.trainer.fit(self.learner, dataLoader) \n",
    "        return self.learner.loss\n",
    "    \n",
    "    # Function to run model through a testing dataset and calculate accuracy. Can be expanded to give more metrics and more useful metrics.\n",
    "    def test(self, dataIn, dataOut):\n",
    "        # Put input data through model and determine classification\n",
    "        with torch.no_grad():\n",
    "            outs = np.asarray(self.model(dataIn)[0])\n",
    "        outs = torch.from_numpy(outs)\n",
    "        # Get the label with the maximum confidence for determining classification\n",
    "        print(outs.shape)\n",
    "        _, res = torch.max(outs, 2)\n",
    "        Pt = Pf = Nt = Nf = 0\n",
    "        countR = 0\n",
    "        numZero = 0\n",
    "        tot = outs.shape[0]\n",
    "        total = 0\n",
    "        for i in range(0, tot):\n",
    "            # Loop through sequences of 10 each\n",
    "            for t in range(0, res[i].shape[0]):\n",
    "                # Loop through the sub-sequences\n",
    "                if res[i,t] == dataOut[i,t]:\n",
    "                    if res[i,t] == 0:\n",
    "                        Nt += 1\n",
    "                        numZero += 1\n",
    "                    else:\n",
    "                        Pt += 1\n",
    "                    # Check if label is correct, and add to count right accordingly\n",
    "                    countR += 1\n",
    "                else:\n",
    "                    if dataOut[i,t] == 0:\n",
    "                        Pf += 1\n",
    "                        numZero += 1\n",
    "                    else:\n",
    "                        Nf += 1\n",
    "                total += 1\n",
    "        # Calculate percent correct and percent zero\n",
    "        if Pt != 0:\n",
    "            accuracy = (Pt+Nt)/(Pt+Pf+Nf+Nt)\n",
    "            precision = (Pt)/(Pt+Pf)\n",
    "            recall = (Pt)/(Pt+Nf)\n",
    "            f1 = (2*precision*recall)/(precision+recall)\n",
    "            print(precision)\n",
    "            print(recall)\n",
    "            print(\"Model got \" + str(countR) + \"/\" + str(total) + \" right.\")\n",
    "            print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")\n",
    "            print(f\"{numZero}, {numZero/total * 100}% Zeroes, {total-numZero} Non Zero entries.\")\n",
    "            return f\"Model got {countR}/{total} right. Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}\"\n",
    "        else:\n",
    "            print(\"Model could not complete tests.\")\n",
    "            return f\"Model could not complete tests, found 0 of misbehaviour.\"\n",
    "    \n",
    "    def testStep(self, dataLoader):\n",
    "        self.learner.validation_step(next(iter(dataLoader)), 0)\n",
    "    \n",
    "    def setModel(self, model):\n",
    "        if not model == None:\n",
    "            self.model = model\n",
    "\n",
    "    def getModel(self):\n",
    "        return self.model\n",
    "    \n",
    "    def getSavedState(self):\n",
    "        return self.prevWeights\n",
    "    \n",
    "    def updateSavedStates(self):\n",
    "        if self.evil:\n",
    "            self.prevWeights = dict((n, torch.zeros(self.model.state_dict()[n].shape)) for n in self.model.state_dict())\n",
    "            return # Never update weights, so always passing on Zero weights. Can also try with infite/random weights\n",
    "        self.prevWeights = self.model.state_dict()\n",
    "    \n",
    "    def getState(self):\n",
    "        return self.model.state_dict()\n",
    "    \n",
    "    def restoreFromBackup(self):\n",
    "        self.model.load_state_dict(self.backupWeights['model'])\n",
    "        self.learner.load_state_dict(self.backupWeights['learner'])\n",
    "\n",
    "    def saveBackup(self):\n",
    "        self.backupWeights['model'] = self.model.state_dict()\n",
    "        self.backupWeights['learner'] = self.learner.state_dict()\n",
    "    \n",
    "    def isEvil(self):\n",
    "        return True if self.evil else False\n",
    "    \n",
    "    def setState(self, one, two = None):\n",
    "        if two:\n",
    "            tom = dict((n, one.get(n, 0)+two.get(n, 0)) for n in set(one)|set(two))\n",
    "        else:\n",
    "            tom = one\n",
    "        self.model.load_state_dict(tom)\n",
    "        return tom\n",
    "    \n",
    "    def step(self, epochs):\n",
    "        self.trainer.fit_loop.max_epochs = self.trainer.current_epoch + epochs\n",
    "        self.curr_loss = self.fit(self.dataset)\n",
    "        return self.curr_loss\n",
    "\n",
    "    def updateSelected(self):\n",
    "        # self.sampling = [self.nearbyOBUs[i] for i in torch.utils.data.WeightedRandomSampler([self.samplingWeights[i] for i in self.nearbyOBUs], self.outnum)] # Randomly generates list of outnum vehicles to sample based on the sampling weights.\n",
    "        # print(self.sampling)\n",
    "        # return self.sampling\n",
    "        self.sampling = []\n",
    "        count = 0\n",
    "        for idx in self.nearbyOBUs:\n",
    "            rand = np.random.randint(0, 100)\n",
    "            if rand <= int(100*self.samplingWeights[idx]): # Less than or equal, as we want 1 to be selected every time.\n",
    "                self.sampling.append(int(idx))\n",
    "                count += 1\n",
    "        return self.sampling # Returning how many vehicles were selected for training\n",
    "        \n",
    "        \n",
    "    def resetTrainer(self):\n",
    "        self.trainer = pl.Trainer(\n",
    "            logger = CSVLogger('log'), # Set ouput destination of logs, logging accuracy every 50 steps\n",
    "            max_epochs = self.epochs, # Number of epochs to train for\n",
    "            gradient_clip_val = 1, # This is said to stabilize training, but we should test if that is true\n",
    "            accelerator = \"gpu\" if self.gpu else \"cpu\" # Using the GPU to run training or not\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd58282c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1000\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 10 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 108.48it/s, v_num=2562, trainLoss=2.780]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 90.44it/s, v_num=2562, trainLoss=2.780] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 94.81it/s, v_num=2563, trainLoss=2.850] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 71.57it/s, v_num=2563, trainLoss=2.850]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 3/3 [00:00<00:00, 106.65it/s, v_num=2564, trainLoss=2.230]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 3/3 [00:00<00:00, 92.39it/s, v_num=2564, trainLoss=2.230] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 122.08it/s, v_num=2565, trainLoss=2.610]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 102.69it/s, v_num=2565, trainLoss=2.610]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 115.09it/s, v_num=2566, trainLoss=2.870]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 95.94it/s, v_num=2566, trainLoss=2.870] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 105.31it/s, v_num=2567, trainLoss=2.540]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 86.39it/s, v_num=2567, trainLoss=2.540] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 106.75it/s, v_num=2568, trainLoss=2.710]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 90.73it/s, v_num=2568, trainLoss=2.710] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 99.37it/s, v_num=2569, trainLoss=2.990] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 75.36it/s, v_num=2569, trainLoss=2.990]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 93.77it/s, v_num=2570, trainLoss=2.890] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 68.35it/s, v_num=2570, trainLoss=2.890]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 76.00it/s, v_num=2571, trainLoss=2.870] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 56.57it/s, v_num=2571, trainLoss=2.870]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 3/3 [00:00<00:00, 121.29it/s, v_num=2572, trainLoss=2.840]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 3/3 [00:00<00:00, 104.71it/s, v_num=2572, trainLoss=2.840]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 4/4 [00:00<00:00, 106.18it/s, v_num=2573, trainLoss=2.670]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 4/4 [00:00<00:00, 96.60it/s, v_num=2573, trainLoss=2.670] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 105.90it/s, v_num=2574, trainLoss=2.740]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 88.21it/s, v_num=2574, trainLoss=2.740] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 3/3 [00:00<00:00, 113.85it/s, v_num=2575, trainLoss=2.790]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 3/3 [00:00<00:00, 99.55it/s, v_num=2575, trainLoss=2.790] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 98.12it/s, v_num=2576, trainLoss=2.960] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 83.38it/s, v_num=2576, trainLoss=2.960]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 102.73it/s, v_num=2577, trainLoss=2.850]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 87.04it/s, v_num=2577, trainLoss=2.850] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2572/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 3/3 [00:00<00:00, 105.99it/s, v_num=2572, trainLoss=2.840]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 3/3 [00:00<00:00, 95.04it/s, v_num=2572, trainLoss=2.840] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2576/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 102.45it/s, v_num=2576, trainLoss=2.960]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 86.54it/s, v_num=2576, trainLoss=2.960] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 91.58it/s, v_num=2578, trainLoss=2.860] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 78.37it/s, v_num=2578, trainLoss=2.860]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2567/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 92.91it/s, v_num=2567, trainLoss=2.540] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 77.97it/s, v_num=2567, trainLoss=2.540]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 94.38it/s, v_num=2579, trainLoss=2.940] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 68.69it/s, v_num=2579, trainLoss=2.940]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 105.62it/s, v_num=2567, trainLoss=2.540]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 89.76it/s, v_num=2567, trainLoss=2.540] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 4/4 [00:00<00:00, 105.96it/s, v_num=2580, trainLoss=3.100]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 4/4 [00:00<00:00, 95.77it/s, v_num=2580, trainLoss=3.100] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 109.73it/s, v_num=2581, trainLoss=2.870]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 89.53it/s, v_num=2581, trainLoss=2.870] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 3/3 [00:00<00:00, 106.64it/s, v_num=2582, trainLoss=2.560]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 3/3 [00:00<00:00, 95.03it/s, v_num=2582, trainLoss=2.560] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 4/4 [00:00<00:00, 109.41it/s, v_num=2583, trainLoss=2.230]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 4/4 [00:00<00:00, 100.26it/s, v_num=2583, trainLoss=2.230]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 3/3 [00:00<00:00, 120.66it/s, v_num=2584, trainLoss=2.060]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 3/3 [00:00<00:00, 106.25it/s, v_num=2584, trainLoss=2.060]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 94.76it/s, v_num=2585, trainLoss=2.910] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 70.90it/s, v_num=2585, trainLoss=2.910]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 104.14it/s, v_num=2586, trainLoss=2.950]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 87.79it/s, v_num=2586, trainLoss=2.950] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 3/3 [00:00<00:00, 105.34it/s, v_num=2587, trainLoss=2.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 3/3 [00:00<00:00, 93.30it/s, v_num=2587, trainLoss=2.390] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 3/3 [00:00<00:00, 116.21it/s, v_num=2588, trainLoss=2.150]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 3/3 [00:00<00:00, 103.14it/s, v_num=2588, trainLoss=2.150]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 112.54it/s, v_num=2589, trainLoss=2.570]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 94.39it/s, v_num=2589, trainLoss=2.570] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 105.24it/s, v_num=2590, trainLoss=2.790]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 89.85it/s, v_num=2590, trainLoss=2.790] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 112.32it/s, v_num=2591, trainLoss=2.690]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 96.17it/s, v_num=2591, trainLoss=2.690] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 112.78it/s, v_num=2592, trainLoss=2.980]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 92.54it/s, v_num=2592, trainLoss=2.980] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 108.85it/s, v_num=2593, trainLoss=3.010]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 78.76it/s, v_num=2593, trainLoss=3.010] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 55.31it/s, v_num=2594, trainLoss=3.020] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 39.23it/s, v_num=2594, trainLoss=3.020]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 110.63it/s, v_num=2595, trainLoss=2.410]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 93.45it/s, v_num=2595, trainLoss=2.410] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 99.93it/s, v_num=2596, trainLoss=2.900] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 84.99it/s, v_num=2596, trainLoss=2.900]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2566/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 101.94it/s, v_num=2566, trainLoss=2.870]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 86.37it/s, v_num=2566, trainLoss=2.870] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 105.40it/s, v_num=2597, trainLoss=2.990]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 78.13it/s, v_num=2597, trainLoss=2.990] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 111.42it/s, v_num=2598, trainLoss=2.640]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 92.39it/s, v_num=2598, trainLoss=2.640] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 3/3 [00:00<00:00, 115.05it/s, v_num=2599, trainLoss=2.790]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 3/3 [00:00<00:00, 101.61it/s, v_num=2599, trainLoss=2.790]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2562/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 111.12it/s, v_num=2562, trainLoss=2.780]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 93.76it/s, v_num=2562, trainLoss=2.780] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 4/4 [00:00<00:00, 112.42it/s, v_num=2600, trainLoss=2.910]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 4/4 [00:00<00:00, 101.18it/s, v_num=2600, trainLoss=2.910]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2571/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 85.04it/s, v_num=2571, trainLoss=2.870] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 63.31it/s, v_num=2571, trainLoss=2.870]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 110.09it/s, v_num=2601, trainLoss=2.780]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 92.25it/s, v_num=2601, trainLoss=2.780] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 110.94it/s, v_num=2602, trainLoss=2.530]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 94.03it/s, v_num=2602, trainLoss=2.530] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 106.71it/s, v_num=2603, trainLoss=2.920]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2/2 [00:00<00:00, 90.13it/s, v_num=2603, trainLoss=2.920] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 97.40it/s, v_num=2604, trainLoss=2.950] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 72.21it/s, v_num=2604, trainLoss=2.950]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 115.90it/s, v_num=2562, trainLoss=2.710]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 97.61it/s, v_num=2562, trainLoss=2.710] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2563/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 96.25it/s, v_num=2563, trainLoss=2.490] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 73.06it/s, v_num=2563, trainLoss=2.490]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2564/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 3/3 [00:00<00:00, 102.13it/s, v_num=2564, trainLoss=2.070]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 3/3 [00:00<00:00, 91.09it/s, v_num=2564, trainLoss=2.070] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2565/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 122.60it/s, v_num=2565, trainLoss=2.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 101.75it/s, v_num=2565, trainLoss=2.390]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 106.64it/s, v_num=2566, trainLoss=2.820]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 90.26it/s, v_num=2566, trainLoss=2.820] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 111.11it/s, v_num=2567, trainLoss=2.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 92.16it/s, v_num=2567, trainLoss=2.390] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2568/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 108.15it/s, v_num=2568, trainLoss=2.480]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 91.06it/s, v_num=2568, trainLoss=2.480] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2569/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 85.62it/s, v_num=2569, trainLoss=2.840] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 65.52it/s, v_num=2569, trainLoss=2.840]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2570/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 104.25it/s, v_num=2570, trainLoss=2.600]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 77.77it/s, v_num=2570, trainLoss=2.600] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 96.30it/s, v_num=2571, trainLoss=2.520] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 71.23it/s, v_num=2571, trainLoss=2.520]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 3/3 [00:00<00:00, 108.11it/s, v_num=2572, trainLoss=2.780]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 3/3 [00:00<00:00, 96.60it/s, v_num=2572, trainLoss=2.780] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2573/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 4/4 [00:00<00:00, 117.68it/s, v_num=2573, trainLoss=2.560]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 4/4 [00:00<00:00, 107.32it/s, v_num=2573, trainLoss=2.560]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2574/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 106.65it/s, v_num=2574, trainLoss=2.670]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 89.77it/s, v_num=2574, trainLoss=2.670] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2575/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 3/3 [00:00<00:00, 114.00it/s, v_num=2575, trainLoss=2.780]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 3/3 [00:00<00:00, 100.64it/s, v_num=2575, trainLoss=2.780]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 109.80it/s, v_num=2576, trainLoss=2.900]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 92.48it/s, v_num=2576, trainLoss=2.900] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2577/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 115.83it/s, v_num=2577, trainLoss=2.780]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 97.14it/s, v_num=2577, trainLoss=2.780] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 3/3 [00:00<00:00, 111.39it/s, v_num=2572, trainLoss=2.780]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 3/3 [00:00<00:00, 98.03it/s, v_num=2572, trainLoss=2.780] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 87.95it/s, v_num=2576, trainLoss=2.900] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 75.12it/s, v_num=2576, trainLoss=2.900]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2578/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 109.31it/s, v_num=2578, trainLoss=2.840]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 92.15it/s, v_num=2578, trainLoss=2.840] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 104.28it/s, v_num=2567, trainLoss=2.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 88.55it/s, v_num=2567, trainLoss=2.390] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2579/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 79.51it/s, v_num=2579, trainLoss=3.020] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 61.15it/s, v_num=2579, trainLoss=3.020]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 2/2 [00:00<00:00, 111.16it/s, v_num=2567, trainLoss=2.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 2/2 [00:00<00:00, 92.26it/s, v_num=2567, trainLoss=2.390] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2580/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 4/4 [00:00<00:00, 118.43it/s, v_num=2580, trainLoss=3.040]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 4/4 [00:00<00:00, 107.13it/s, v_num=2580, trainLoss=3.040]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2581/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 105.82it/s, v_num=2581, trainLoss=2.840]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 89.00it/s, v_num=2581, trainLoss=2.840] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2582/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 3/3 [00:00<00:00, 113.77it/s, v_num=2582, trainLoss=2.440]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 3/3 [00:00<00:00, 101.28it/s, v_num=2582, trainLoss=2.440]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2583/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 4/4 [00:00<00:00, 109.23it/s, v_num=2583, trainLoss=2.180]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 4/4 [00:00<00:00, 99.21it/s, v_num=2583, trainLoss=2.180] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2584/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 3/3 [00:00<00:00, 113.57it/s, v_num=2584, trainLoss=1.860]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 3/3 [00:00<00:00, 90.02it/s, v_num=2584, trainLoss=1.860] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2585/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 101.66it/s, v_num=2585, trainLoss=2.660]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 73.46it/s, v_num=2585, trainLoss=2.660] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2586/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 107.10it/s, v_num=2586, trainLoss=2.910]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 89.72it/s, v_num=2586, trainLoss=2.910] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2587/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 3/3 [00:00<00:00, 110.18it/s, v_num=2587, trainLoss=2.320]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 3/3 [00:00<00:00, 98.34it/s, v_num=2587, trainLoss=2.320] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2588/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 3/3 [00:00<00:00, 108.99it/s, v_num=2588, trainLoss=2.030]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 3/3 [00:00<00:00, 96.99it/s, v_num=2588, trainLoss=2.030] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2589/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 111.33it/s, v_num=2589, trainLoss=2.330]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 93.99it/s, v_num=2589, trainLoss=2.330] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2590/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 112.11it/s, v_num=2590, trainLoss=2.700]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 93.93it/s, v_num=2590, trainLoss=2.700] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2591/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 92.46it/s, v_num=2591, trainLoss=2.590] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 78.29it/s, v_num=2591, trainLoss=2.590]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2592/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 107.38it/s, v_num=2592, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 90.03it/s, v_num=2592, trainLoss=3.000] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2593/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 96.02it/s, v_num=2593, trainLoss=2.890] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 71.90it/s, v_num=2593, trainLoss=2.890]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2594/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 104.70it/s, v_num=2594, trainLoss=3.010]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 77.94it/s, v_num=2594, trainLoss=3.010] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2595/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 108.75it/s, v_num=2595, trainLoss=2.220]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 91.40it/s, v_num=2595, trainLoss=2.220] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2596/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 113.80it/s, v_num=2596, trainLoss=2.740]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 94.42it/s, v_num=2596, trainLoss=2.740] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 106.86it/s, v_num=2566, trainLoss=2.820]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 88.26it/s, v_num=2566, trainLoss=2.820] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2597/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 91.83it/s, v_num=2597, trainLoss=2.860] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 69.88it/s, v_num=2597, trainLoss=2.860]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2598/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 108.83it/s, v_num=2598, trainLoss=2.490]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 91.88it/s, v_num=2598, trainLoss=2.490] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2599/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 3/3 [00:00<00:00, 110.36it/s, v_num=2599, trainLoss=2.700]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 3/3 [00:00<00:00, 98.51it/s, v_num=2599, trainLoss=2.700] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 100.09it/s, v_num=2562, trainLoss=2.710]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 83.95it/s, v_num=2562, trainLoss=2.710] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2600/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 4/4 [00:00<00:00, 111.39it/s, v_num=2600, trainLoss=2.800]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 4/4 [00:00<00:00, 100.77it/s, v_num=2600, trainLoss=2.800]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 98.85it/s, v_num=2571, trainLoss=2.520] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 72.15it/s, v_num=2571, trainLoss=2.520]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2601/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 105.89it/s, v_num=2601, trainLoss=2.690]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 88.63it/s, v_num=2601, trainLoss=2.690] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2602/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 106.36it/s, v_num=2602, trainLoss=2.370]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 90.03it/s, v_num=2602, trainLoss=2.370] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2603/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 100.79it/s, v_num=2603, trainLoss=2.890]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 2/2 [00:00<00:00, 85.35it/s, v_num=2603, trainLoss=2.890] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory log/Fed/lightning_logs/version_2604/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 99.36it/s, v_num=2604, trainLoss=2.750] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 75.59it/s, v_num=2604, trainLoss=2.750]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 107.19it/s, v_num=2562, trainLoss=2.560]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 89.99it/s, v_num=2562, trainLoss=2.560] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 102.47it/s, v_num=2563, trainLoss=2.330]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 73.94it/s, v_num=2563, trainLoss=2.330] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 3/3 [00:00<00:00, 114.09it/s, v_num=2564, trainLoss=1.840]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 3/3 [00:00<00:00, 100.91it/s, v_num=2564, trainLoss=1.840]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 104.65it/s, v_num=2565, trainLoss=2.220]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 88.66it/s, v_num=2565, trainLoss=2.220] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 106.00it/s, v_num=2566, trainLoss=2.700]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 89.30it/s, v_num=2566, trainLoss=2.700] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349: 100%|██████████| 2/2 [00:00<00:00, 100.58it/s, v_num=2567, trainLoss=2.130]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=350` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349: 100%|██████████| 2/2 [00:00<00:00, 86.08it/s, v_num=2567, trainLoss=2.130] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 98.97it/s, v_num=2568, trainLoss=2.310] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 84.93it/s, v_num=2568, trainLoss=2.310]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 99.21it/s, v_num=2569, trainLoss=2.810] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 72.50it/s, v_num=2569, trainLoss=2.810]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 104.69it/s, v_num=2570, trainLoss=2.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 79.30it/s, v_num=2570, trainLoss=2.460] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 90.89it/s, v_num=2571, trainLoss=2.370] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 68.34it/s, v_num=2571, trainLoss=2.370]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 3/3 [00:00<00:00, 110.62it/s, v_num=2572, trainLoss=2.650]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 3/3 [00:00<00:00, 97.79it/s, v_num=2572, trainLoss=2.650] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 4/4 [00:00<00:00, 105.33it/s, v_num=2573, trainLoss=1.790]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 4/4 [00:00<00:00, 96.76it/s, v_num=2573, trainLoss=1.790] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 101.21it/s, v_num=2574, trainLoss=2.490]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 83.96it/s, v_num=2574, trainLoss=2.490] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 3/3 [00:00<00:00, 102.34it/s, v_num=2575, trainLoss=2.610]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 3/3 [00:00<00:00, 89.91it/s, v_num=2575, trainLoss=2.610] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 97.37it/s, v_num=2576, trainLoss=2.850] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 82.90it/s, v_num=2576, trainLoss=2.850]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 101.97it/s, v_num=2577, trainLoss=2.660]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 84.97it/s, v_num=2577, trainLoss=2.660] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 3/3 [00:00<00:00, 100.71it/s, v_num=2572, trainLoss=2.650]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 3/3 [00:00<00:00, 89.48it/s, v_num=2572, trainLoss=2.650] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 2/2 [00:00<00:00, 104.39it/s, v_num=2576, trainLoss=2.850]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 2/2 [00:00<00:00, 86.56it/s, v_num=2576, trainLoss=2.850] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 102.65it/s, v_num=2578, trainLoss=2.680]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 86.84it/s, v_num=2578, trainLoss=2.680] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399: 100%|██████████| 2/2 [00:00<00:00, 101.28it/s, v_num=2567, trainLoss=2.130]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399: 100%|██████████| 2/2 [00:00<00:00, 85.78it/s, v_num=2567, trainLoss=2.130] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 93.82it/s, v_num=2579, trainLoss=3.050] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 71.42it/s, v_num=2579, trainLoss=3.050]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449: 100%|██████████| 2/2 [00:00<00:00, 105.39it/s, v_num=2567, trainLoss=2.130]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=450` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449: 100%|██████████| 2/2 [00:00<00:00, 88.33it/s, v_num=2567, trainLoss=2.130] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 4/4 [00:00<00:00, 108.57it/s, v_num=2580, trainLoss=3.020]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 4/4 [00:00<00:00, 98.71it/s, v_num=2580, trainLoss=3.020] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 101.28it/s, v_num=2581, trainLoss=2.720]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 84.92it/s, v_num=2581, trainLoss=2.720] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 3/3 [00:00<00:00, 105.94it/s, v_num=2582, trainLoss=2.190]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 3/3 [00:00<00:00, 91.85it/s, v_num=2582, trainLoss=2.190] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 4/4 [00:00<00:00, 112.98it/s, v_num=2583, trainLoss=1.880]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 4/4 [00:00<00:00, 103.28it/s, v_num=2583, trainLoss=1.880]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 3/3 [00:00<00:00, 107.96it/s, v_num=2584, trainLoss=1.750]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 3/3 [00:00<00:00, 95.66it/s, v_num=2584, trainLoss=1.750] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 96.91it/s, v_num=2585, trainLoss=2.510] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 72.54it/s, v_num=2585, trainLoss=2.510]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 114.90it/s, v_num=2586, trainLoss=2.850]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 93.73it/s, v_num=2586, trainLoss=2.850] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 3/3 [00:00<00:00, 110.47it/s, v_num=2587, trainLoss=2.100]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 3/3 [00:00<00:00, 96.98it/s, v_num=2587, trainLoss=2.100] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 3/3 [00:00<00:00, 109.77it/s, v_num=2588, trainLoss=1.820]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 3/3 [00:00<00:00, 98.22it/s, v_num=2588, trainLoss=1.820] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 104.95it/s, v_num=2589, trainLoss=2.190]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 87.91it/s, v_num=2589, trainLoss=2.190] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 102.22it/s, v_num=2590, trainLoss=2.530]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 85.35it/s, v_num=2590, trainLoss=2.530] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 112.01it/s, v_num=2591, trainLoss=2.410]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 93.76it/s, v_num=2591, trainLoss=2.410] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 110.67it/s, v_num=2592, trainLoss=2.950]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 92.42it/s, v_num=2592, trainLoss=2.950] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 93.98it/s, v_num=2593, trainLoss=2.850] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 71.86it/s, v_num=2593, trainLoss=2.850]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 102.59it/s, v_num=2594, trainLoss=3.040]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 76.94it/s, v_num=2594, trainLoss=3.040] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 107.48it/s, v_num=2595, trainLoss=1.960]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 90.55it/s, v_num=2595, trainLoss=1.960] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 106.36it/s, v_num=2596, trainLoss=2.680]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 88.06it/s, v_num=2596, trainLoss=2.680] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 2/2 [00:00<00:00, 104.70it/s, v_num=2566, trainLoss=2.700]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 2/2 [00:00<00:00, 88.91it/s, v_num=2566, trainLoss=2.700] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 106.81it/s, v_num=2597, trainLoss=2.840]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 78.97it/s, v_num=2597, trainLoss=2.840] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 102.43it/s, v_num=2598, trainLoss=2.340]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 87.97it/s, v_num=2598, trainLoss=2.340] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 3/3 [00:00<00:00, 104.36it/s, v_num=2599, trainLoss=2.510]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 3/3 [00:00<00:00, 93.12it/s, v_num=2599, trainLoss=2.510] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 2/2 [00:00<00:00, 106.49it/s, v_num=2562, trainLoss=2.560]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 2/2 [00:00<00:00, 89.62it/s, v_num=2562, trainLoss=2.560] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 4/4 [00:00<00:00, 111.09it/s, v_num=2600, trainLoss=2.720]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 4/4 [00:00<00:00, 100.68it/s, v_num=2600, trainLoss=2.720]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 103.91it/s, v_num=2571, trainLoss=2.370]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 76.89it/s, v_num=2571, trainLoss=2.370] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 108.72it/s, v_num=2601, trainLoss=2.540]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 92.04it/s, v_num=2601, trainLoss=2.540] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 109.96it/s, v_num=2602, trainLoss=2.130]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 92.76it/s, v_num=2602, trainLoss=2.130] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 99.80it/s, v_num=2603, trainLoss=2.780] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 2/2 [00:00<00:00, 84.27it/s, v_num=2603, trainLoss=2.780]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 106.21it/s, v_num=2604, trainLoss=2.670]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 79.27it/s, v_num=2604, trainLoss=2.670] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349: 100%|██████████| 2/2 [00:00<00:00, 110.39it/s, v_num=2562, trainLoss=2.450]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=350` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349: 100%|██████████| 2/2 [00:00<00:00, 92.58it/s, v_num=2562, trainLoss=2.450] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 93.42it/s, v_num=2563, trainLoss=2.140] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 69.88it/s, v_num=2563, trainLoss=2.140]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 3/3 [00:00<00:00, 111.46it/s, v_num=2564, trainLoss=1.170]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 3/3 [00:00<00:00, 97.97it/s, v_num=2564, trainLoss=1.170] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 111.96it/s, v_num=2565, trainLoss=1.900]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 91.66it/s, v_num=2565, trainLoss=1.900] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349: 100%|██████████| 2/2 [00:00<00:00, 103.42it/s, v_num=2566, trainLoss=2.480]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=350` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349: 100%|██████████| 2/2 [00:00<00:00, 87.53it/s, v_num=2566, trainLoss=2.480] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 2/2 [00:00<00:00, 110.99it/s, v_num=2567, trainLoss=1.910]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 2/2 [00:00<00:00, 92.02it/s, v_num=2567, trainLoss=1.910] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 105.43it/s, v_num=2568, trainLoss=2.060]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 88.37it/s, v_num=2568, trainLoss=2.060] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 104.57it/s, v_num=2569, trainLoss=2.660]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 77.99it/s, v_num=2569, trainLoss=2.660] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 101.34it/s, v_num=2570, trainLoss=2.280]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 72.18it/s, v_num=2570, trainLoss=2.280] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 92.59it/s, v_num=2571, trainLoss=2.130] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=350` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 68.64it/s, v_num=2571, trainLoss=2.130]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349: 100%|██████████| 3/3 [00:00<00:00, 114.20it/s, v_num=2572, trainLoss=1.810]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=350` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349: 100%|██████████| 3/3 [00:00<00:00, 99.42it/s, v_num=2572, trainLoss=1.810] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 4/4 [00:00<00:00, 112.55it/s, v_num=2573, trainLoss=1.130]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 4/4 [00:00<00:00, 102.28it/s, v_num=2573, trainLoss=1.130]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 103.26it/s, v_num=2574, trainLoss=2.220]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 87.48it/s, v_num=2574, trainLoss=2.220] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 3/3 [00:00<00:00, 105.28it/s, v_num=2575, trainLoss=2.230]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 3/3 [00:00<00:00, 93.75it/s, v_num=2575, trainLoss=2.230] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349: 100%|██████████| 2/2 [00:00<00:00, 123.98it/s, v_num=2576, trainLoss=2.590]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=350` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349: 100%|██████████| 2/2 [00:00<00:00, 103.63it/s, v_num=2576, trainLoss=2.590]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 110.06it/s, v_num=2577, trainLoss=2.410]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 92.72it/s, v_num=2577, trainLoss=2.410] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399: 100%|██████████| 3/3 [00:00<00:00, 105.36it/s, v_num=2572, trainLoss=1.810]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399: 100%|██████████| 3/3 [00:00<00:00, 93.93it/s, v_num=2572, trainLoss=1.810] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399: 100%|██████████| 2/2 [00:00<00:00, 109.24it/s, v_num=2576, trainLoss=2.590]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399: 100%|██████████| 2/2 [00:00<00:00, 92.60it/s, v_num=2576, trainLoss=2.590] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 107.66it/s, v_num=2578, trainLoss=2.230]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 90.87it/s, v_num=2578, trainLoss=2.230] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 549: 100%|██████████| 2/2 [00:00<00:00, 107.90it/s, v_num=2567, trainLoss=1.910]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=550` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 549: 100%|██████████| 2/2 [00:00<00:00, 90.67it/s, v_num=2567, trainLoss=1.910] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 94.72it/s, v_num=2579, trainLoss=3.020] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 73.41it/s, v_num=2579, trainLoss=3.020]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 599: 100%|██████████| 2/2 [00:00<00:00, 98.75it/s, v_num=2567, trainLoss=1.910] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=600` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 599: 100%|██████████| 2/2 [00:00<00:00, 83.64it/s, v_num=2567, trainLoss=1.910]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 4/4 [00:00<00:00, 119.69it/s, v_num=2580, trainLoss=1.280]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 4/4 [00:00<00:00, 107.96it/s, v_num=2580, trainLoss=1.280]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 106.93it/s, v_num=2581, trainLoss=2.570]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 89.64it/s, v_num=2581, trainLoss=2.570] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 3/3 [00:00<00:00, 114.29it/s, v_num=2582, trainLoss=1.540]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 3/3 [00:00<00:00, 100.71it/s, v_num=2582, trainLoss=1.540]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 4/4 [00:00<00:00, 112.46it/s, v_num=2583, trainLoss=1.280]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 4/4 [00:00<00:00, 102.59it/s, v_num=2583, trainLoss=1.280]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 3/3 [00:00<00:00, 109.78it/s, v_num=2584, trainLoss=2.020]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 3/3 [00:00<00:00, 97.65it/s, v_num=2584, trainLoss=2.020] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 98.18it/s, v_num=2585, trainLoss=2.330] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 73.75it/s, v_num=2585, trainLoss=2.330]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 108.01it/s, v_num=2586, trainLoss=2.790]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 91.13it/s, v_num=2586, trainLoss=2.790] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 3/3 [00:00<00:00, 112.99it/s, v_num=2587, trainLoss=1.730]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 3/3 [00:00<00:00, 99.94it/s, v_num=2587, trainLoss=1.730] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 3/3 [00:00<00:00, 102.18it/s, v_num=2588, trainLoss=1.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 3/3 [00:00<00:00, 90.89it/s, v_num=2588, trainLoss=1.390] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 105.18it/s, v_num=2589, trainLoss=1.790]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 87.95it/s, v_num=2589, trainLoss=1.790] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 102.65it/s, v_num=2590, trainLoss=2.420]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 85.57it/s, v_num=2590, trainLoss=2.420] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 113.67it/s, v_num=2591, trainLoss=2.250]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 96.07it/s, v_num=2591, trainLoss=2.250] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 111.09it/s, v_num=2592, trainLoss=2.890]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 93.10it/s, v_num=2592, trainLoss=2.890] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 94.64it/s, v_num=2593, trainLoss=2.720] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 71.32it/s, v_num=2593, trainLoss=2.720]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 103.23it/s, v_num=2594, trainLoss=3.020]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 77.11it/s, v_num=2594, trainLoss=3.020] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 107.14it/s, v_num=2595, trainLoss=1.760]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 89.18it/s, v_num=2595, trainLoss=1.760] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 111.76it/s, v_num=2596, trainLoss=2.530]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 92.95it/s, v_num=2596, trainLoss=2.530] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399: 100%|██████████| 2/2 [00:00<00:00, 111.56it/s, v_num=2566, trainLoss=2.480]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399: 100%|██████████| 2/2 [00:00<00:00, 93.20it/s, v_num=2566, trainLoss=2.480] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 83.06it/s, v_num=2597, trainLoss=2.690] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 63.46it/s, v_num=2597, trainLoss=2.690]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 106.55it/s, v_num=2598, trainLoss=2.160]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 90.33it/s, v_num=2598, trainLoss=2.160] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 3/3 [00:00<00:00, 106.62it/s, v_num=2599, trainLoss=1.790]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 3/3 [00:00<00:00, 94.29it/s, v_num=2599, trainLoss=1.790] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399: 100%|██████████| 2/2 [00:00<00:00, 109.06it/s, v_num=2562, trainLoss=2.450]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399: 100%|██████████| 2/2 [00:00<00:00, 93.17it/s, v_num=2562, trainLoss=2.450] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 4/4 [00:00<00:00, 120.00it/s, v_num=2600, trainLoss=1.370]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 4/4 [00:00<00:00, 107.40it/s, v_num=2600, trainLoss=1.370]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 105.46it/s, v_num=2571, trainLoss=2.130]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 78.98it/s, v_num=2571, trainLoss=2.130] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 114.33it/s, v_num=2601, trainLoss=2.310]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 95.69it/s, v_num=2601, trainLoss=2.310] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 102.72it/s, v_num=2602, trainLoss=1.890]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 86.29it/s, v_num=2602, trainLoss=1.890] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 108.17it/s, v_num=2603, trainLoss=2.570]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 2/2 [00:00<00:00, 90.69it/s, v_num=2603, trainLoss=2.570] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 95.57it/s, v_num=2604, trainLoss=2.500] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 72.65it/s, v_num=2604, trainLoss=2.500]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449: 100%|██████████| 2/2 [00:00<00:00, 90.77it/s, v_num=2562, trainLoss=1.580] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=450` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449: 100%|██████████| 2/2 [00:00<00:00, 76.30it/s, v_num=2562, trainLoss=1.580]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 88.57it/s, v_num=2563, trainLoss=1.680] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 68.01it/s, v_num=2563, trainLoss=1.680]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 3/3 [00:00<00:00, 110.48it/s, v_num=2564, trainLoss=0.753]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 3/3 [00:00<00:00, 96.91it/s, v_num=2564, trainLoss=0.753] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 111.22it/s, v_num=2565, trainLoss=1.340]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 90.34it/s, v_num=2565, trainLoss=1.340] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449: 100%|██████████| 2/2 [00:00<00:00, 111.18it/s, v_num=2566, trainLoss=1.720]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=450` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449: 100%|██████████| 2/2 [00:00<00:00, 93.24it/s, v_num=2566, trainLoss=1.720] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 649: 100%|██████████| 2/2 [00:00<00:00, 108.97it/s, v_num=2567, trainLoss=1.190]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=650` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 649: 100%|██████████| 2/2 [00:00<00:00, 91.36it/s, v_num=2567, trainLoss=1.190] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 109.12it/s, v_num=2568, trainLoss=1.290]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 92.18it/s, v_num=2568, trainLoss=1.290] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 93.55it/s, v_num=2569, trainLoss=2.130] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 72.16it/s, v_num=2569, trainLoss=2.130]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 113.34it/s, v_num=2570, trainLoss=1.830]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 85.47it/s, v_num=2570, trainLoss=1.830] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 90.13it/s, v_num=2571, trainLoss=1.670] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=450` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 67.15it/s, v_num=2571, trainLoss=1.670]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449: 100%|██████████| 3/3 [00:00<00:00, 96.17it/s, v_num=2572, trainLoss=1.270] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=450` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449: 100%|██████████| 3/3 [00:00<00:00, 83.17it/s, v_num=2572, trainLoss=1.270]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 4/4 [00:00<00:00, 105.33it/s, v_num=2573, trainLoss=0.837]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 4/4 [00:00<00:00, 96.43it/s, v_num=2573, trainLoss=0.837] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 106.40it/s, v_num=2574, trainLoss=1.510]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 88.11it/s, v_num=2574, trainLoss=1.510] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 3/3 [00:00<00:00, 108.54it/s, v_num=2575, trainLoss=1.240]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 3/3 [00:00<00:00, 96.42it/s, v_num=2575, trainLoss=1.240] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449: 100%|██████████| 2/2 [00:00<00:00, 98.88it/s, v_num=2576, trainLoss=1.740] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=450` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449: 100%|██████████| 2/2 [00:00<00:00, 83.89it/s, v_num=2576, trainLoss=1.740]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 97.75it/s, v_num=2577, trainLoss=1.560] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 82.43it/s, v_num=2577, trainLoss=1.560]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 3/3 [00:00<00:00, 101.71it/s, v_num=2572, trainLoss=1.270]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 3/3 [00:00<00:00, 90.47it/s, v_num=2572, trainLoss=1.270] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 2/2 [00:00<00:00, 106.66it/s, v_num=2576, trainLoss=1.740]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 2/2 [00:00<00:00, 90.04it/s, v_num=2576, trainLoss=1.740] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 114.62it/s, v_num=2578, trainLoss=1.650]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 95.73it/s, v_num=2578, trainLoss=1.650] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 699: 100%|██████████| 2/2 [00:00<00:00, 100.41it/s, v_num=2567, trainLoss=1.190]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=700` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 699: 100%|██████████| 2/2 [00:00<00:00, 85.47it/s, v_num=2567, trainLoss=1.190] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 89.11it/s, v_num=2579, trainLoss=2.290] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 68.68it/s, v_num=2579, trainLoss=2.290]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 749: 100%|██████████| 2/2 [00:00<00:00, 105.90it/s, v_num=2567, trainLoss=1.190]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=750` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 749: 100%|██████████| 2/2 [00:00<00:00, 88.10it/s, v_num=2567, trainLoss=1.190] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 4/4 [00:00<00:00, 117.69it/s, v_num=2580, trainLoss=1.130]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 4/4 [00:00<00:00, 105.78it/s, v_num=2580, trainLoss=1.130]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 106.36it/s, v_num=2581, trainLoss=1.670]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 88.55it/s, v_num=2581, trainLoss=1.670] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 3/3 [00:00<00:00, 107.20it/s, v_num=2582, trainLoss=0.990]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 3/3 [00:00<00:00, 94.99it/s, v_num=2582, trainLoss=0.990] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 4/4 [00:00<00:00, 104.79it/s, v_num=2583, trainLoss=0.728]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 4/4 [00:00<00:00, 94.69it/s, v_num=2583, trainLoss=0.728] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 3/3 [00:00<00:00, 112.79it/s, v_num=2584, trainLoss=1.560]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 3/3 [00:00<00:00, 99.76it/s, v_num=2584, trainLoss=1.560] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 95.95it/s, v_num=2585, trainLoss=1.810] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 74.08it/s, v_num=2585, trainLoss=1.810]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 116.48it/s, v_num=2586, trainLoss=1.790]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 95.67it/s, v_num=2586, trainLoss=1.790] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 3/3 [00:00<00:00, 110.09it/s, v_num=2587, trainLoss=0.947]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 3/3 [00:00<00:00, 97.94it/s, v_num=2587, trainLoss=0.947] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 3/3 [00:00<00:00, 106.72it/s, v_num=2588, trainLoss=0.818]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 3/3 [00:00<00:00, 93.83it/s, v_num=2588, trainLoss=0.818] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 104.02it/s, v_num=2589, trainLoss=1.130]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 87.94it/s, v_num=2589, trainLoss=1.130] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 109.63it/s, v_num=2590, trainLoss=1.520]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 92.55it/s, v_num=2590, trainLoss=1.520] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 102.40it/s, v_num=2591, trainLoss=1.440]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 85.68it/s, v_num=2591, trainLoss=1.440] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 105.80it/s, v_num=2592, trainLoss=1.870]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 89.45it/s, v_num=2592, trainLoss=1.870] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 98.03it/s, v_num=2593, trainLoss=2.130] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 74.61it/s, v_num=2593, trainLoss=2.130]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 90.62it/s, v_num=2594, trainLoss=2.280] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 67.63it/s, v_num=2594, trainLoss=2.280]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 108.43it/s, v_num=2595, trainLoss=1.200]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 88.03it/s, v_num=2595, trainLoss=1.200] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 98.41it/s, v_num=2596, trainLoss=1.750] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 82.68it/s, v_num=2596, trainLoss=1.750]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 2/2 [00:00<00:00, 104.65it/s, v_num=2566, trainLoss=1.720]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 2/2 [00:00<00:00, 88.11it/s, v_num=2566, trainLoss=1.720] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 80.26it/s, v_num=2597, trainLoss=2.100] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 61.36it/s, v_num=2597, trainLoss=2.100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 100.61it/s, v_num=2598, trainLoss=1.550]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 83.79it/s, v_num=2598, trainLoss=1.550] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 3/3 [00:00<00:00, 96.72it/s, v_num=2599, trainLoss=1.200] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 3/3 [00:00<00:00, 86.04it/s, v_num=2599, trainLoss=1.200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 2/2 [00:00<00:00, 87.96it/s, v_num=2562, trainLoss=1.580] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 2/2 [00:00<00:00, 74.03it/s, v_num=2562, trainLoss=1.580]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 4/4 [00:00<00:00, 109.49it/s, v_num=2600, trainLoss=0.967]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 4/4 [00:00<00:00, 99.78it/s, v_num=2600, trainLoss=0.967] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 87.60it/s, v_num=2571, trainLoss=1.670] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 64.31it/s, v_num=2571, trainLoss=1.670]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 102.50it/s, v_num=2601, trainLoss=1.550]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 85.32it/s, v_num=2601, trainLoss=1.550] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 102.09it/s, v_num=2602, trainLoss=1.180]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 85.88it/s, v_num=2602, trainLoss=1.180] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 94.92it/s, v_num=2603, trainLoss=1.820] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 2/2 [00:00<00:00, 80.19it/s, v_num=2603, trainLoss=1.820]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 85.44it/s, v_num=2604, trainLoss=2.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=250` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 64.89it/s, v_num=2604, trainLoss=2.000]\n",
      "torch.Size([124774, 10, 20])\n",
      "0.8443495151097161\n",
      "0.9709495548961424\n",
      "Model got 1170620/1247740 right.\n",
      "Accuracy: 0.9381922515908763, Precision: 0.8443495151097161, Recall: 0.9709495548961424, F1 Score: 0.90323495386345\n",
      "877040, 70.29028483498165% Zeroes, 370700 Non Zero entries.\n"
     ]
    }
   ],
   "source": [
    "# Standard Federated Learning\n",
    "\n",
    "# With 2 epochs, 10 sub, and 0:3 models ending acc. of 0.1377%\n",
    "# With 2 epochs, 10 sub, and 0:10 models ending acc. of\n",
    "\n",
    "# Tested with weights, but weighing off of the loss leads to choosing the models trained by vehicles without attacks.\n",
    "\n",
    "pl.seed_everything(1000)\n",
    "results = {}\n",
    "dataSets = {}\n",
    "models = {}\n",
    "histWeights = []\n",
    "percentages = []\n",
    "cars = []\n",
    "rcvrs = []\n",
    "percs = {}\n",
    "states = {}\n",
    "subEpochs = 50 # 50\n",
    "epochs = 5 # 5\n",
    "vehicles = 50 # 50\n",
    "lr = 0.01\n",
    "motors = 8\n",
    "units = 20\n",
    "batchSize = 64\n",
    "gpu = False\n",
    "deepTest = False\n",
    "weighing = False\n",
    "randomVehicles = False\n",
    "doValidation = False\n",
    "# Create starting models\n",
    "mainModel = OBU(7, epochs= subEpochs, gpu = gpu, lr = lr, motors = motors, units = units)\n",
    "nextModel = OBU(7, epochs= subEpochs, gpu = gpu, lr = lr, motors = motors, units = units)\n",
    "\n",
    "if not randomVehicles:\n",
    "    # Divide dataset of recieving vehicles among OBUs\n",
    "    rcvrs = []\n",
    "    for vehicle in fedDataSet[500:vehicles+500]: # 10\n",
    "        rcvrID = int(vehicle[0,0,2].item())\n",
    "        # Add new OBU for each model\n",
    "        models[rcvrID] = OBU(7, epochs = subEpochs, gpu=gpu, lr = lr, motors = motors, units = units)\n",
    "        # Create Slice of dataset\n",
    "        vehicle = data.DataLoader(data.TensorDataset(vehicle[:,:,3:10].float(), vehicle[:,:,11].long()), batch_size=batchSize, shuffle=False, num_workers=16, persistent_workers = True) # type: ignore\n",
    "        # Add sub - dataset to dataset\n",
    "        rcvrs.append(rcvrID)\n",
    "        dataSets[rcvrID]=vehicle\n",
    "        models[rcvrID].dataset = vehicle\n",
    "\n",
    "# Train individual models and combine\n",
    "for epoch in range(epochs):\n",
    "    i = 0\n",
    "    if randomVehicles:\n",
    "        # choose random assortment of vehicles to train on\n",
    "        cars = []\n",
    "        rcvrs = []\n",
    "        for ted in np.random.choice(len(fedDataSet), vehicles, replace = False):\n",
    "            cars.append(fedDataSet[ted])\n",
    "        # Divide dataset of recieving vehicles among OBUs\n",
    "        for vehicle in cars: # 10\n",
    "            rcvrID = int(vehicle[0,0,2].item())\n",
    "            # Add new OBU for each model\n",
    "            if rcvrID not in models:\n",
    "                models[rcvrID] = OBU(7, epochs = subEpochs, gpu=gpu, lr = lr, motors = motors, units = units)\n",
    "            # Create Slice of dataset\n",
    "            vehicle = data.DataLoader(data.TensorDataset(vehicle[:,:,3:10].float(), vehicle[:,:,11].long()), batch_size=batchSize, shuffle=False, num_workers=16, persistent_workers = True)\n",
    "            # Add sub - dataset to dataset\n",
    "            rcvrs.append(rcvrID)\n",
    "            dataSets[rcvrID]=vehicle\n",
    "            models[rcvrID].dataset = vehicle\n",
    "\n",
    "    print(rcvrs, file = open('rcvrs.txt', 'w'))\n",
    "    # Baseline model to add everything to. !!Do I want this or should it be a completely new model?!! Got 0% on combination before, testing with new model for next model.\n",
    "    nextModel = OBU(7, epochs= subEpochs, gpu = gpu, lr = lr, motors = motors, units = units)\n",
    "    # Train models\n",
    "    weights = []\n",
    "    for rcvr in rcvrs:\n",
    "        # Make multithreaded?\n",
    "        if doValidation and models[rcvr].prevAccuracy != 0:\n",
    "            _, _, p, _ = mainModel.test(inTest, outTest)\n",
    "            print(f\"Current Epoch: {epoch}, Reciever: {rcvr}\")\n",
    "            print(f\"Tested. main perc: {p}, my perc: {models[rcvr].prevAccuracy}\")\n",
    "            if p > models[rcvr].prevAccuracy:\n",
    "                print(\"Updating Model\")\n",
    "                # set model to main model, and train that \n",
    "                models[rcvr].setState(mainModel.getState())\n",
    "        else:\n",
    "            models[rcvr].setState(mainModel.getState())\n",
    "        # Reset the trainer (should be unneeded now) to allow for further training\n",
    "        # mod.resetTrainer()\n",
    "        # Actually train\n",
    "        modLoss = models[rcvr].step(subEpochs)\n",
    "        weights.append(1/modLoss.item())\n",
    "        if deepTest or doValidation:\n",
    "            _, _ , perc, _ = models[rcvr].test(inTest, outTest)\n",
    "            percs[rcvr] = perc\n",
    "            models[rcvr].prevAccuracy = perc\n",
    "            # Test individual model\n",
    "            print(rcvr)\n",
    "            if rcvr not in results:\n",
    "                results[rcvr] = ([epoch, i+1, perc, modLoss.item()])\n",
    "            else:\n",
    "                results[rcvr].append([epoch, i+1, perc, modLoss.item()])\n",
    "        states[rcvr] = (models[rcvr].getState())\n",
    "        i+=1\n",
    "        \n",
    "    # Create combined model\n",
    "    # combine models\n",
    "    weights = np.abs(weights)/np.sum(weights)\n",
    "\n",
    "    y=0\n",
    "    for w in weights:\n",
    "        y+= w\n",
    "    teds = [[float(weights[n]), percs[n]] for n in range(len(percs))]\n",
    "    percentages.append(teds)\n",
    "    histWeights.append([weights,y])\n",
    "    tom = 1/i\n",
    "    for rcvr in rcvrs:\n",
    "        if weighing:\n",
    "            nextState = nextModel.setState(nextModel.getState(), dict((n, states[rcvr].get(n, 0)*weights[rcvr]) for n in states[rcvr])) # Done with weights\n",
    "        else:\n",
    "            nextState = nextModel.setState(nextModel.getState(), states[rcvr]) # No Weights\n",
    "    if weighing:\n",
    "        mainModel.setState(nextState) #Weights\n",
    "    else:\n",
    "        mainModel.setState(dict((n, nextState.get(n, 0)/i) for n in nextState)) # No weights\n",
    "# Test combined model at end\n",
    "perc = mainModel.test(testDataIn, testDataOut)\n",
    "results['FINAL'] = [-1, -1, perc]\n",
    "print(results, file = open('out/SF/results.txt', 'w'))\n",
    "print(histWeights, file = open('out/SF/Weights.txt', 'w'))\n",
    "print(percentages, file = open('out/SF/Percs.txt', 'w'))\n",
    "\n",
    "\n",
    "# 'Model got 340703/1247740 right. Accuracy: 0.27305608540240756, Precision: 0.27978235144854047, Recall: 0.919080118694362, F1 Score: 0.42897730670851897'\n",
    "# This was with scheduler, 50, 10, 100. Before accuracy with this was 96.388%, now 27.306%. \n",
    "# Running test with 50, 5, 50, w/out scheduler: 'Model got 1170620/1247740 right. Accuracy: 0.9381922515908763, Precision: 0.8443495151097161, Recall: 0.9709495548961424, F1 Score: 0.90323495386345'\n",
    "# Accuracy of 93.820% after half the vehicles and half the epochs. I think we need to rething the scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629437ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1000\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\will\\miniconda3\\envs\\Kettering\\Lib\\site-packages\\pytorch_lightning\\trainer\\setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\will\\miniconda3\\envs\\Kettering\\Lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 0 now\n",
      "vehicle 0 priority: 0.03438873059472361, total priority of subgroup: 1.0\n",
      "vehicle 1 priority: 0.006025756647581977, total priority of subgroup: 1.0\n",
      "vehicle 2 priority: 0.07655838502226625, total priority of subgroup: 1.0\n",
      "vehicle 3 priority: 0.08670775907921609, total priority of subgroup: 1.0\n",
      "vehicle 4 priority: 0.14614503699659676, total priority of subgroup: 1.0\n",
      "vehicle 5 priority: 0.006256201402629975, total priority of subgroup: 1.0\n",
      "vehicle 6 priority: 0.006639673510628343, total priority of subgroup: 1.0\n",
      "vehicle 7 priority: 0.014646070369417822, total priority of subgroup: 1.0\n",
      "vehicle 8 priority: 0.022561258361760643, total priority of subgroup: 1.0\n",
      "vehicle 9 priority: 0.3690602520788838, total priority of subgroup: 1.0\n",
      "vehicle 10 priority: 0.04343240057082584, total priority of subgroup: 1.0\n",
      "vehicle 11 priority: 0.1195304202830868, total priority of subgroup: 1.0\n",
      "vehicle 12 priority: 0.2500862921968843, total priority of subgroup: 1.0\n",
      "vehicle 13 priority: 0.07853545646825455, total priority of subgroup: 1.0\n",
      "vehicle 14 priority: 0.053301532191557824, total priority of subgroup: 1.0\n",
      "vehicle 15 priority: 0.1547116604637084, total priority of subgroup: 1.0\n",
      "vehicle 16 priority: 0.03523633547545616, total priority of subgroup: 1.0\n",
      "vehicle 17 priority: 0.06089796666945365, total priority of subgroup: 1.0\n",
      "vehicle 18 priority: 0.021434058092500416, total priority of subgroup: 1.0\n",
      "vehicle 19 priority: 0.1201763270896044, total priority of subgroup: 1.0\n",
      "vehicle 20 priority: 0.0577716643741403, total priority of subgroup: 1.0\n",
      "vehicle 21 priority: 0.09643383032971647, total priority of subgroup: 1.0\n",
      "vehicle 22 priority: 0.003694626202981774, total priority of subgroup: 1.0\n",
      "vehicle 23 priority: 0.04035363808319163, total priority of subgroup: 1.0\n",
      "vehicle 24 priority: 0.03601446515056322, total priority of subgroup: 1.0\n",
      "vehicle 25 priority: 0.03891889940385128, total priority of subgroup: 1.0\n",
      "vehicle 26 priority: 0.10890018536201765, total priority of subgroup: 1.0\n",
      "vehicle 27 priority: 0.0045840956438812554, total priority of subgroup: 1.0\n",
      "vehicle 28 priority: 0.04052127913263347, total priority of subgroup: 1.0\n",
      "vehicle 29 priority: 0.025276090022462082, total priority of subgroup: 1.0\n",
      "vehicle 30 priority: 0.012098639245784039, total priority of subgroup: 1.0\n",
      "vehicle 31 priority: 0.12342313612311596, total priority of subgroup: 1.0\n",
      "vehicle 32 priority: 0.10027078004914099, total priority of subgroup: 1.0\n",
      "vehicle 33 priority: 0.09058477197178479, total priority of subgroup: 1.0\n",
      "vehicle 34 priority: 0.08934178632318232, total priority of subgroup: 1.0\n",
      "vehicle 35 priority: 0.16499890974267814, total priority of subgroup: 1.0\n",
      "vehicle 36 priority: 0.002533272587333471, total priority of subgroup: 1.0\n",
      "vehicle 37 priority: 0.25765287685708826, total priority of subgroup: 1.0\n",
      "vehicle 38 priority: 0.015349576398580736, total priority of subgroup: 1.0\n",
      "vehicle 39 priority: 0.29438572343909436, total priority of subgroup: 1.0\n",
      "vehicle 40 priority: 0.027787782764003913, total priority of subgroup: 1.0\n",
      "vehicle 41 priority: 0.2734190000740496, total priority of subgroup: 1.0\n",
      "vehicle 42 priority: 0.12793152721705298, total priority of subgroup: 1.0\n",
      "vehicle 43 priority: 0.24898242827360273, total priority of subgroup: 1.0\n",
      "vehicle 44 priority: 0.04092590971783243, total priority of subgroup: 1.0\n",
      "vehicle 45 priority: 0.010490500826404797, total priority of subgroup: 1.0\n",
      "vehicle 46 priority: 0.163518423976696, total priority of subgroup: 1.0\n",
      "vehicle 47 priority: 0.13371537726838587, total priority of subgroup: 1.0\n",
      "vehicle 48 priority: 0.02040049048224097, total priority of subgroup: 1.0\n",
      "vehicle 49 priority: 0.05966231400840952, total priority of subgroup: 1.0\n",
      "vehicle 50 priority: 0.04822900875239921, total priority of subgroup: 1.0\n",
      "vehicle 51 priority: 0.14081009512698142, total priority of subgroup: 1.0\n",
      "vehicle 52 priority: 0.042351896288799, total priority of subgroup: 1.0\n",
      "vehicle 53 priority: 0.06290077109125977, total priority of subgroup: 1.0\n",
      "vehicle 54 priority: 0.11118453948611469, total priority of subgroup: 1.0\n",
      "vehicle 55 priority: 0.014267267571676623, total priority of subgroup: 1.0\n",
      "vehicle 56 priority: 0.11927325684651727, total priority of subgroup: 1.0\n",
      "vehicle 57 priority: 0.05507579691078612, total priority of subgroup: 1.0\n",
      "vehicle 58 priority: 0.10329520960212454, total priority of subgroup: 1.0\n",
      "vehicle 59 priority: 0.03046783138368492, total priority of subgroup: 1.0\n",
      "vehicle 60 priority: 0.04851077021703711, total priority of subgroup: 1.0\n",
      "vehicle 61 priority: 0.20414345680523774, total priority of subgroup: 1.0\n",
      "vehicle 62 priority: 0.40123659140538714, total priority of subgroup: 1.0\n",
      "vehicle 63 priority: 0.17359074336850772, total priority of subgroup: 1.0\n",
      "vehicle 64 priority: 0.011770816922148198, total priority of subgroup: 1.0\n",
      "vehicle 65 priority: 0.017444469322141786, total priority of subgroup: 1.0\n",
      "vehicle 66 priority: 0.1292453788918761, total priority of subgroup: 1.0\n",
      "vehicle 67 priority: 0.04269655867181205, total priority of subgroup: 1.0\n",
      "vehicle 68 priority: 0.038515479112032895, total priority of subgroup: 1.0\n",
      "vehicle 69 priority: 0.049527851339974734, total priority of subgroup: 1.0\n",
      "vehicle 70 priority: 0.17247092891360546, total priority of subgroup: 1.0\n",
      "vehicle 71 priority: 0.02586818049129441, total priority of subgroup: 1.0\n",
      "vehicle 72 priority: 0.006634948296842135, total priority of subgroup: 1.0\n",
      "vehicle 73 priority: 0.13459706058595483, total priority of subgroup: 1.0\n",
      "vehicle 74 priority: 0.08682421595585371, total priority of subgroup: 1.0\n",
      "vehicle 75 priority: 0.040339170253013125, total priority of subgroup: 1.0\n",
      "vehicle 76 priority: 0.12218487216756174, total priority of subgroup: 1.0\n",
      "vehicle 77 priority: 0.030615293947572775, total priority of subgroup: 1.0\n",
      "vehicle 78 priority: 0.09039856320832827, total priority of subgroup: 1.0\n",
      "vehicle 79 priority: 0.027109219127109063, total priority of subgroup: 1.0\n",
      "vehicle 80 priority: 0.07396636742951068, total priority of subgroup: 1.0\n",
      "vehicle 81 priority: 0.10034151690099848, total priority of subgroup: 1.0\n",
      "vehicle 82 priority: 0.056753747515431024, total priority of subgroup: 1.0\n",
      "vehicle 83 priority: 0.02117458752713772, total priority of subgroup: 1.0\n",
      "vehicle 84 priority: 0.058445925104162626, total priority of subgroup: 1.0\n",
      "vehicle 85 priority: 0.08529385692093619, total priority of subgroup: 1.0\n",
      "vehicle 86 priority: 0.07002755103428865, total priority of subgroup: 1.0\n",
      "vehicle 87 priority: 0.1909606720935872, total priority of subgroup: 1.0\n",
      "vehicle 88 priority: 0.12498693403801611, total priority of subgroup: 1.0\n",
      "vehicle 89 priority: 0.09004857726631708, total priority of subgroup: 1.0\n",
      "vehicle 90 priority: 0.08106704967921748, total priority of subgroup: 1.0\n",
      "vehicle 91 priority: 0.2665160199962096, total priority of subgroup: 1.0\n",
      "vehicle 92 priority: 0.19062132345428168, total priority of subgroup: 1.0\n",
      "vehicle 93 priority: 0.04760682420993667, total priority of subgroup: 1.0\n",
      "vehicle 94 priority: 0.11009250854750763, total priority of subgroup: 1.0\n",
      "vehicle 95 priority: 0.44908373927163076, total priority of subgroup: 1.0\n",
      "vehicle 96 priority: 0.2051091081477707, total priority of subgroup: 1.0\n",
      "vehicle 97 priority: 0.41952836510999264, total priority of subgroup: 1.0\n",
      "vehicle 98 priority: 0.1018857169999525, total priority of subgroup: 1.0\n",
      "vehicle 99 priority: 0.023018679138162662, total priority of subgroup: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\will\\miniconda3\\envs\\Kettering\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 2/2 [00:00<00:00, 32.04it/s, v_num=1876, trainLoss=0.852]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 2/2 [00:00<00:00, 25.78it/s, v_num=1876, trainLoss=0.852]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\will\\miniconda3\\envs\\Kettering\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:310: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 32.70it/s, v_num=1877, trainLoss=2.400]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 21.47it/s, v_num=1877, trainLoss=2.400]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 2/2 [00:00<00:00, 31.99it/s, v_num=1878, trainLoss=1.220]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 2/2 [00:00<00:00, 26.46it/s, v_num=1878, trainLoss=1.220]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 27.28it/s, v_num=1879, trainLoss=2.170]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 19.68it/s, v_num=1879, trainLoss=2.170]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 28.56it/s, v_num=1880, trainLoss=3.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 20.37it/s, v_num=1880, trainLoss=3.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 32.77it/s, v_num=1881, trainLoss=2.320]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 22.77it/s, v_num=1881, trainLoss=2.320]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 27.70it/s, v_num=1882, trainLoss=2.100]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 18.94it/s, v_num=1882, trainLoss=2.100]\n"
     ]
    }
   ],
   "source": [
    "# DeFTA: Decentralized Federalized Training\n",
    "\n",
    "pl.seed_everything(1000)\n",
    "\n",
    "vehicleNumTot = 100 # 50 # 50\n",
    "subNetworkNum = 30 # 15 # 15\n",
    "totEpochs = 15 # 30 # 5\n",
    "stepsPerEpoch = 15 # 5 # 30\n",
    "minConnnectedVehicles = 15 # 10\n",
    "backupThreshold = 3\n",
    "vehicles = []\n",
    "selectionWeights = {}\n",
    "gpu = False\n",
    "doEvil = True\n",
    "percEvil = 10\n",
    "lr = 0.01\n",
    "phiGain = 100\n",
    "\n",
    "path = f\"DeFTA/{doEvil}-{percEvil}-{vehicleNumTot}-{subNetworkNum}-{totEpochs}-{stepsPerEpoch}-{minConnnectedVehicles}-{backupThreshold}-{phiGain}/\"\n",
    "if not os.path.exists(f\"out/{path}\"):\n",
    "    os.makedirs(f\"out/{path}\")\n",
    "# Function to update sampling weights and confidence values\n",
    "def phi(vehicle):\n",
    "    m = [0 for n in range(vehicleNumTot)]\n",
    "    for t in vehicle.sampling:\n",
    "        m[t] += 1  # define matrix m that contains weather the vehicle is in the sampled set, and how many times it is in the set.\n",
    "    if vehicle.prev_loss != None: # If it isn't the first iteration:\n",
    "        if vehicle.curr_loss > vehicle.prev_loss * backupThreshold: # If this training round broke the model \n",
    "            print(f\"Previous Loss: {vehicle.prev_loss}, Current loss: {vehicle.curr_loss}\")\n",
    "            print(\"Loading From Backup\")\n",
    "            vehicle.restoreFromBackup() # Restore backup weights\n",
    "            vehicle.step(stepsPerEpoch) # Training Step\n",
    "            vehicle.trust_loss = 10000 # set loss to infinity, as this model is destroyed\n",
    "        else:\n",
    "            if vehicle.curr_loss < vehicle.prev_loss: # If this is new best model\n",
    "                vehicle.saveBackup() # Save model as new backup\n",
    "            vehicle.trust_loss = vehicle.curr_loss - vehicle.prev_loss # Set change in trust\n",
    "            vehicle.prev_loss = vehicle.curr_loss # Update previous loss to stay current\n",
    "        print(vehicle.confidences)\n",
    "        for i in range(len(vehicle.confidences)):\n",
    "            if m[i]*vehicle.otherPriorities[i]*vehicle.trust_loss < 0:\n",
    "                add = m[i]*vehicle.otherPriorities[i]*vehicle.trust_loss\n",
    "            else:\n",
    "                add = phiGain*m[i]*vehicle.otherPriorities[i]*vehicle.trust_loss\n",
    "            vehicle.confidences[i] = vehicle.confidences[i] - (add) # Update confidences based on what vehicles are contributing to the training and the size of their contribution\n",
    "            print(f'{i}: {add}')\n",
    "        for i in range(len(vehicle.confidences)):\n",
    "            if vehicle.confidences[i] > 5:\n",
    "                vehicle.confidences[i] = 5 # Add max to the sampling weights\n",
    "        for i in range(len(vehicle.samplingWeights)):\n",
    "            vehicle.samplingWeights[i] = (0.2 * vehicle.confidences[i]) if (vehicle.confidences[i] > 0) else (vehicle.confidences[i]) # Perform cRELU on C, with weighting a as 0.2 as per the findings of the DeFTA paper\n",
    "        # vehicle.samplingWeights = np.exp(vehicle.samplingWeights)/np.sum(np.exp(vehicle.samplingWeights)) # Implementation of the softMax function to align the theta values properly. Trying without this to have everything sampled unless issue.\n",
    "        for i in range(len(vehicle.samplingWeights)):\n",
    "            if vehicle.samplingWeights[i] > 1:\n",
    "                vehicle.samplingWeights[i] = 1 # Add max to the sampling weights\n",
    "    else:\n",
    "        vehicle.prev_loss = vehicle.curr_loss # Update previous loss while allowing for one epoch of randomness.\n",
    "    if vehicle.id in selectionWeights:\n",
    "        selectionWeights[vehicle.id].append(vehicle.samplingWeights[:])\n",
    "    else:\n",
    "        selectionWeights[vehicle.id] = [vehicle.samplingWeights[:]]\n",
    "    # Returns nothing, since all operations are done inside the vehicle\n",
    "\n",
    "def updatePriorities(vehicles):\n",
    "    for i in range(vehicleNumTot):\n",
    "        vehicles[i].outnum = len(vehicles[i].sampling) + 1# Update useful outnumber of each vehicle in the simulation by having outnum = num sampled vehicles\n",
    "\n",
    "    for i in range(vehicleNumTot): # Loop through vehicles and add priority of vehicle, done in separete loop as it requires info from other vehicles\n",
    "        sum = vehicles[i].datalen/vehicles[i].outnum # Start out by including this vehicle's priority\n",
    "        dum = vehicles[i].datalen/vehicles[i].outnum\n",
    "        for j in vehicles[i].sampling:\n",
    "            sum += vehicles[j].datalen/vehicles[j].outnum\n",
    "        vehicles[i].priority = (vehicles[i].datalen/vehicles[i].outnum)/(sum)\n",
    "        for j in vehicles[i].sampling:\n",
    "            vehicles[i].otherPriorities[j] = (vehicles[j].datalen/vehicles[j].outnum)/sum # fill out standard list of other priorities\n",
    "            dum += vehicles[j].datalen/vehicles[j].outnum\n",
    "        print(f\"vehicle {i} priority: {vehicles[i].priority}, total priority of subgroup: {dum/sum}\")\n",
    "\n",
    "for i in range(vehicleNumTot):\n",
    "    set = data.DataLoader(data.TensorDataset(fedDataSet[i][:,:,3:10].float(), fedDataSet[i][:,:,11].long()), batch_size=batchSize, shuffle=False, num_workers=10, persistent_workers = True) # Create datasets\n",
    "    if doEvil:\n",
    "        if np.random.randint(0,100) < percEvil:\n",
    "            vehicles.append(OBU(inputSize=7, units=20, motors=8, outputs=20, lr=lr, randInt=i, gpu=gpu, dataset=set, evil=True)) # Create evil vehicles\n",
    "        else:\n",
    "            vehicles.append(OBU(inputSize=7, units=20, motors=8, outputs=20, lr=lr, randInt=i, gpu=gpu, dataset=set)) # Create vehicles\n",
    "    else:\n",
    "        vehicles.append(OBU(inputSize=7, units=20, motors=8, outputs=20, lr=lr, randInt=i, gpu=gpu, dataset=set)) # Create vehicles\n",
    "    vehicles[i].prevWeights = vehicles[i].getState() # Save previous state, so that we can do it in iterations\n",
    "    vehicles[i].datalen = fedDataSet[i].shape[0]\n",
    "    vehicles[i].outnum = np.random.randint(minConnnectedVehicles, subNetworkNum) # Get number of vehicles in sub network, at least #x so that vehicle has some use.\n",
    "    range1 = np.arange(0, i).tolist()\n",
    "    range2 = np.arange(i+1, vehicleNumTot).tolist()\n",
    "    vehicles[i].nearbyOBUs = np.random.choice(range1 + range2, vehicles[i].outnum, replace=False) # Create subnetworks and add them to the vehicle\n",
    "    vehicles[i].confidences = np.full((vehicleNumTot), 3.) # Initialize confidence values for all vehicles - can be shifted to a dict later to allow for varying number/discovery of vehicles\n",
    "    vehicles[i].samplingWeights = np.full((vehicleNumTot), .5) # Initialize the sampling weights to 0.5 - similarly, can be switched to a dict\n",
    "    vehicles[i].otherPriorities = np.zeros((vehicleNumTot)) # Initialize list of priorities\n",
    "    vehicles[i].sampling = vehicles[i].nearbyOBUs.tolist() # Initialize list of OBUs we are sampling\n",
    "    vehicles[i].id = i # Save vehicles id\n",
    "\n",
    "historicLoss = {}\n",
    "selections = {}\n",
    "results = {}\n",
    "\n",
    "for vehicle in vehicles:\n",
    "    if vehicle.id in selections:\n",
    "        selections[vehicle.id].append([int(i) for i in (vehicle.updateSelected())]) # Update selected vehicles for next training\n",
    "    else:\n",
    "        selections[vehicle.id] = [[int(i) for i in (vehicle.updateSelected())]]\n",
    "\n",
    "for epoch in range(totEpochs):\n",
    "    print(f\"Starting Epoch {epoch} now\")\n",
    "    updatePriorities(vehicles)\n",
    "    for vehicle in vehicles:\n",
    "        vehicle.updateSavedStates() # Save current model as model to send to others, so that they are getting the latest after each loop\n",
    "    for vehicle in vehicles:\n",
    "         # Model aggregation - Sum weights of all participating models weighted by their priority\n",
    "        sum = None\n",
    "        for i in vehicle.sampling:\n",
    "            if not sum:\n",
    "                state = vehicles[i].getSavedState()\n",
    "                sum = dict((n, state.get(n, 0)*vehicle.otherPriorities[i]) for n in state) # Multiplying weights and priority\n",
    "            else:\n",
    "                state = vehicles[i].getSavedState()\n",
    "                add = dict((n, state.get(n, 0)*vehicle.otherPriorities[i]) for n in state) # Multiply weights and priority\n",
    "                sum = dict( (n, add.get(n, 0)+sum.get(n, 0)) for n in sum) # Add this models weights to the sum\n",
    "        state = vehicle.getSavedState()\n",
    "        add = dict((n, state.get(n, 0)*vehicle.priority) for n in state)\n",
    "        if sum:\n",
    "            sum = dict((n, add.get(n, 0)+sum.get(n, 0)) for n in sum) # Add this vehicles model to the aggregation\n",
    "        else:\n",
    "            sum = add\n",
    "        vehicle.setState(sum)\n",
    "        loss = vehicle.step(stepsPerEpoch) # Run training step to progress model\n",
    "        if vehicle.id in historicLoss:\n",
    "            historicLoss[vehicle.id].append(loss.item())\n",
    "        else:\n",
    "            historicLoss[vehicle.id] = [loss.item()]\n",
    "        phi(vehicle) # Update theta and confidence matrix\n",
    "        if vehicle.id in selections:\n",
    "            selections[vehicle.id].append([int(i) for i in (vehicle.updateSelected())]) # Update selected vehicles for next training\n",
    "        else:\n",
    "            selections[vehicle.id] = [[int(i) for i in (vehicle.updateSelected())]]\n",
    "\n",
    "sampleSizes = {}\n",
    "for id in selections:\n",
    "    for epoch in selections[id]:\n",
    "        if id in sampleSizes:\n",
    "            sampleSizes[id].append(len(epoch))\n",
    "        else:\n",
    "            sampleSizes[id] = [len(epoch)] # Printing number of vehicles sampled by each vehicle each iteration\n",
    "print(sampleSizes, file=open(f'out/{path}SampleSizes.txt', 'w'))\n",
    "print(historicLoss, file=open(f'out/{path}HistoricLoss.txt', 'w'))\n",
    "for vehicle in vehicles:\n",
    "    results[vehicle.id] = vehicle.test(testDataIn, testDataOut)\n",
    "print(selections, file=open(f'out/{path}SelectedVehicles.txt', 'w'))\n",
    "avgF1 = 0\n",
    "cnt = 0\n",
    "for result in results: # Loop through results\n",
    "    print(results[result].split())\n",
    "    if not vehicles[result].isEvil(): # If the vehicle is evil/misbehaving, we don't include that in our average F1 score.\n",
    "        if results[result] != 'Model could not complete tests, found 0 of misbehaviour.':\n",
    "            avgF1 += float(results[result].split()[-1])\n",
    "            cnt += 1\n",
    "        else:\n",
    "            avgF1 += 0\n",
    "            cnt += 1\n",
    "avgF1 = avgF1/cnt\n",
    "results['Final'] = f\"Average F1 over dataset: {avgF1}\"\n",
    "print(results, file=open(f'out/{path}DeFedResults.txt', 'w'))\n",
    "evils = {}\n",
    "for vehicle in vehicles: # Create list of evil/bad vehicles\n",
    "    evils[vehicle.id] = f\"This vehicle did not contribute a malitious model.\" if not vehicle.isEvil() else f\"This vehicle contributed a false model.\"\n",
    "print(evils, file=open(f'out/{path}VehicleStatus.txt','w'))\n",
    "print(selectionWeights, file = open(f'out/{path}SelectionWeights.txt', 'w')) # Print out the chances of selecting each vehicle\n",
    "\n",
    "'''\n",
    "Results:\n",
    "- 0 Starting weight: Accuracy: 0.2970971516501835, Precision: 0.2970971516501835, Recall: 1.0, F1 Score: 0.4580954499394479\n",
    "-.5 Starting weight: Accuracy: 0.2970971516501835, Precision: 0.2970971516501835, Recall: 1.0, F1 Score: 0.4580954499394479\n",
    "'''\n",
    "\n",
    "'''\n",
    "Pseudocode:\n",
    "nodes = list of nodes in simulation\n",
    "    every node has: N = list of nodes in network; C = list of confidence values; theta = list of weights for each vehicles contribution; D = local dataset; d = outdegree; w = local weights for model\n",
    "N = list of networks (each node i has a list of attached nodes) * At some point make this vary per iteration?\n",
    "for each node in simulation in parrallel:\n",
    "    Initialize list of nodes to be sampled - S\n",
    "        *** How do we do this ***\n",
    "    for each epoch:\n",
    "        collect weights from each node in N\n",
    "        new w = sum(sample weight * model weight) for model in sampled models - aggregate w\n",
    "        w = w - (learning rate) * (Loss function (model)) - Local optimizing (training step)\n",
    "        C_i, theta_i = phi(c, model) - update c and theta\n",
    "        Update S? - WeightedSample(W, theta)\n",
    "        Send local data to other models - maybe not necessary depending on how I do this\n",
    "        wait for the rest of peers to finish this loop\n",
    "\n",
    "        c is based on the training loss, ie. c_i_j increases if the training loss of w_i decreases (from their paper, they suggest coming up with your own)\n",
    "        theta = softmax(cRELU(c))\n",
    "        cRELU = {x; x<= 0, ax; x >0} They suggest a = 0.2 from their findings\n",
    "\n",
    "        phi(c, w_i):\n",
    "            m is binary matrix where its j-th entry is 1 iff j is in the set of used models (S) - m has all values on different columns\n",
    "            p is the set of aggregation weights for all nodes in the network - P has all values on different rows\n",
    "            if w_i is bad:\n",
    "                w = w_backup - don't allow bad training to mess up model\n",
    "                do training step on w\n",
    "                loss_trust = inf.\n",
    "            else:\n",
    "                if loss_curr is lowest:\n",
    "                    w_backup = w - create backup\n",
    "                loss_trust = loss_curr - loss_last\n",
    "                loss_last = loss_curr\n",
    "            c = c_prev - (m composite multipied by p) * loss_trust - update c\n",
    "            theta = softmax(cRELU(c)) - Update sample weights\n",
    "            Update S with subset of N, random sampling using weights to randomize selection size as well as selected values\n",
    "\n",
    "            \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fff3c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94284057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "d = {'a': 1, 'b': 2, 'c': 3}\n",
    "e = ['a','b']\n",
    "print([d[x] for x in e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae882c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10002457 0.09977863 0.10002469 0.10002465 0.10002414 0.10002459\n",
      " 0.10002469 0.10002469 0.10002468 0.10002469]\n",
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "print(weights)\n",
    "i=0\n",
    "for w in weights:\n",
    "    i+= w\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2739aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([[-0.9981, -1.0000,  1.0000, -0.8293, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6075,  0.0442,  0.7163,  0.6767,  0.7933,  0.7151,  0.5629,  0.9533,\n",
      "         -0.8753,  0.7856, -0.5999, -0.2247],\n",
      "        [-0.9155, -1.0000,  1.0000, -0.7490, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5863,  0.0659,  0.7266,  0.6708,  0.7904,  0.7140,  0.5576,  0.9531,\n",
      "         -0.8754,  0.7839, -0.6045, -0.2218],\n",
      "        [-0.9489, -1.0000,  1.0000, -0.8079, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6044,  0.0083,  0.7259,  0.6747,  0.8049,  0.7217,  0.5656,  0.9527,\n",
      "         -0.8770,  0.7812, -0.5921, -0.2208],\n",
      "        [-0.9244, -1.0000,  1.0000, -0.8202, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5903,  0.0450,  0.7244,  0.6746,  0.7943,  0.7130,  0.5605,  0.9540,\n",
      "         -0.8758,  0.7817, -0.6040, -0.2236],\n",
      "        [-0.8204, -1.0000,  1.0000, -0.8306, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5760,  0.0688,  0.7257,  0.6738,  0.7918,  0.7142,  0.5560,  0.9537,\n",
      "         -0.8759,  0.7806, -0.6065, -0.2197],\n",
      "        [-0.9052, -1.0000,  1.0000, -0.8287, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6007,  0.0619,  0.7186,  0.6713,  0.7910,  0.7146,  0.5613,  0.9531,\n",
      "         -0.8752,  0.7856, -0.6016, -0.2228],\n",
      "        [-0.9171, -1.0000,  1.0000, -0.7736, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5861,  0.0592,  0.7295,  0.6732,  0.7919,  0.7156,  0.5582,  0.9522,\n",
      "         -0.8768,  0.7824, -0.6066, -0.2217],\n",
      "        [-0.9011, -1.0000,  1.0000, -0.8475, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5786,  0.0812,  0.7179,  0.6703,  0.7889,  0.7076,  0.5549,  0.9542,\n",
      "         -0.8750,  0.7827, -0.6045, -0.2219],\n",
      "        [-0.8631, -1.0000,  1.0000, -0.7902, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5965,  0.0589,  0.7250,  0.6712,  0.7918,  0.7152,  0.5585,  0.9532,\n",
      "         -0.8754,  0.7846, -0.6021, -0.2216],\n",
      "        [-0.9376, -1.0000,  1.0000, -0.8336, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6009,  0.0534,  0.7154,  0.6759,  0.7930,  0.7149,  0.5618,  0.9533,\n",
      "         -0.8752,  0.7852, -0.6004, -0.2241],\n",
      "        [-0.9918, -1.0000,  1.0000, -0.7738, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6079,  0.0590,  0.7221,  0.6598,  0.7916,  0.7140,  0.5577,  0.9529,\n",
      "         -0.8750,  0.7859, -0.6021, -0.2236],\n",
      "        [-0.9324, -1.0000,  1.0000, -0.8054, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6019,  0.0490,  0.7242,  0.6739,  0.7940,  0.7152,  0.5615,  0.9533,\n",
      "         -0.8758,  0.7848, -0.6005, -0.2245],\n",
      "        [-0.9729, -1.0000,  1.0000, -0.8740, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6004,  0.0527,  0.7156,  0.6718,  0.7918,  0.7144,  0.5609,  0.9533,\n",
      "         -0.8754,  0.7845, -0.6022, -0.2225],\n",
      "        [-0.9392, -1.0000,  1.0000, -0.7578, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6012,  0.0588,  0.7272,  0.6672,  0.7925,  0.7125,  0.5599,  0.9530,\n",
      "         -0.8754,  0.7839, -0.6021, -0.2222],\n",
      "        [-0.9753, -1.0000,  1.0000, -0.8987, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6006,  0.0513,  0.7112,  0.6751,  0.7920,  0.7149,  0.5619,  0.9533,\n",
      "         -0.8752,  0.7849, -0.6016, -0.2230],\n",
      "        [-0.9694, -1.0000,  1.0000, -0.8849, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6046,  0.0526,  0.7158,  0.6742,  0.7929,  0.7148,  0.5624,  0.9533,\n",
      "         -0.8754,  0.7853, -0.6007, -0.2234],\n",
      "        [-0.9733, -1.0000,  1.0000, -0.8345, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6086,  0.0414,  0.7199,  0.6723,  0.7945,  0.7157,  0.5638,  0.9532,\n",
      "         -0.8756,  0.7850, -0.5993, -0.2237],\n",
      "        [-0.9559, -1.0000,  1.0000, -0.8139, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6064,  0.0446,  0.7236,  0.6764,  0.7946,  0.7156,  0.5635,  0.9533,\n",
      "         -0.8757,  0.7853, -0.5992, -0.2243],\n",
      "        [-0.9895, -1.0000,  1.0000, -0.8400, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6053,  0.0515,  0.7152,  0.6766,  0.7923,  0.7138,  0.5629,  0.9533,\n",
      "         -0.8753,  0.7853, -0.6006, -0.2246],\n",
      "        [-0.9850, -1.0000,  1.0000, -0.8246, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6057,  0.0509,  0.7189,  0.6756,  0.7923,  0.7139,  0.5636,  0.9530,\n",
      "         -0.8761,  0.7846, -0.6011, -0.2232],\n",
      "        [-0.9141, -1.0000,  1.0000, -0.8038, -1.0000, -1.0000,  0.9986, -1.0000,\n",
      "          0.5877,  0.0757,  0.7221,  0.6766,  0.7851,  0.7114,  0.5568,  0.9535,\n",
      "         -0.8753,  0.7852, -0.6084, -0.2252],\n",
      "        [-1.0000, -1.0000,  1.0000, -0.7906, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6010,  0.0500,  0.7189,  0.6741,  0.7931,  0.7138,  0.5617,  0.9541,\n",
      "         -0.8750,  0.7851, -0.6002, -0.2256],\n",
      "        [-0.9512, -1.0000,  1.0000, -0.7711, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5806,  0.0660,  0.7224,  0.6653,  0.7907,  0.7124,  0.5555,  0.9528,\n",
      "         -0.8753,  0.7823, -0.6020, -0.2221],\n",
      "        [-0.9773, -1.0000,  1.0000, -0.6992, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5976,  0.0353,  0.7326,  0.6754,  0.7977,  0.7173,  0.5616,  0.9533,\n",
      "         -0.8767,  0.7812, -0.5994, -0.2206],\n",
      "        [-0.8841, -1.0000,  1.0000, -0.7073, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5803,  0.0804,  0.7310,  0.6690,  0.7865,  0.7111,  0.5568,  0.9522,\n",
      "         -0.8763,  0.7848, -0.6070, -0.2240],\n",
      "        [-0.9066, -1.0000,  1.0000, -0.8235, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5815,  0.0613,  0.7235,  0.6754,  0.7908,  0.7140,  0.5575,  0.9535,\n",
      "         -0.8758,  0.7806, -0.6078, -0.2208],\n",
      "        [-0.9674, -1.0000,  1.0000, -0.7686, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6023,  0.0395,  0.7230,  0.6756,  0.7967,  0.7166,  0.5635,  0.9533,\n",
      "         -0.8754,  0.7849, -0.5974, -0.2249],\n",
      "        [-1.0000, -1.0000,  1.0000, -0.8173, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6059,  0.0477,  0.7172,  0.6753,  0.7931,  0.7147,  0.5630,  0.9534,\n",
      "         -0.8753,  0.7853, -0.6001, -0.2245],\n",
      "        [-0.9537, -1.0000,  1.0000, -0.8257, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5943,  0.0285,  0.7231,  0.6745,  0.7992,  0.7157,  0.5622,  0.9538,\n",
      "         -0.8760,  0.7806, -0.5997, -0.2230],\n",
      "        [-0.9737, -1.0000,  1.0000, -0.7748, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6039,  0.0499,  0.7228,  0.6780,  0.7933,  0.7130,  0.5619,  0.9543,\n",
      "         -0.8753,  0.7851, -0.6001, -0.2259],\n",
      "        [-0.9677, -1.0000,  1.0000, -0.7541, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5983,  0.0546,  0.7248,  0.6760,  0.7928,  0.7140,  0.5608,  0.9534,\n",
      "         -0.8756,  0.7852, -0.6007, -0.2250],\n",
      "        [-0.9449, -1.0000,  1.0000, -0.8400, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5912,  0.0640,  0.7158,  0.6795,  0.7895,  0.7091,  0.5596,  0.9541,\n",
      "         -0.8751,  0.7837, -0.6026, -0.2254]])\n",
      "tensor([[-0.9981, -1.0000,  1.0000, -0.8293, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6075,  0.0442,  0.7163,  0.6767,  0.7933,  0.7151,  0.5629,  0.9533,\n",
      "         -0.8753,  0.7856, -0.5999, -0.2247],\n",
      "        [-0.9155, -1.0000,  1.0000, -0.7490, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5863,  0.0659,  0.7266,  0.6708,  0.7904,  0.7140,  0.5576,  0.9531,\n",
      "         -0.8754,  0.7839, -0.6045, -0.2218],\n",
      "        [-0.9489, -1.0000,  1.0000, -0.8079, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6044,  0.0083,  0.7259,  0.6747,  0.8049,  0.7217,  0.5656,  0.9527,\n",
      "         -0.8770,  0.7812, -0.5921, -0.2208],\n",
      "        [-0.9244, -1.0000,  1.0000, -0.8202, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5903,  0.0450,  0.7244,  0.6746,  0.7943,  0.7130,  0.5605,  0.9540,\n",
      "         -0.8758,  0.7817, -0.6040, -0.2236],\n",
      "        [-0.8204, -1.0000,  1.0000, -0.8306, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5760,  0.0688,  0.7257,  0.6738,  0.7918,  0.7142,  0.5560,  0.9537,\n",
      "         -0.8759,  0.7806, -0.6065, -0.2197],\n",
      "        [-0.9052, -1.0000,  1.0000, -0.8287, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6007,  0.0619,  0.7186,  0.6713,  0.7910,  0.7146,  0.5613,  0.9531,\n",
      "         -0.8752,  0.7856, -0.6016, -0.2228],\n",
      "        [-0.9171, -1.0000,  1.0000, -0.7736, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5861,  0.0592,  0.7295,  0.6732,  0.7919,  0.7156,  0.5582,  0.9522,\n",
      "         -0.8768,  0.7824, -0.6066, -0.2217],\n",
      "        [-0.9011, -1.0000,  1.0000, -0.8475, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5786,  0.0812,  0.7179,  0.6703,  0.7889,  0.7076,  0.5549,  0.9542,\n",
      "         -0.8750,  0.7827, -0.6045, -0.2219],\n",
      "        [-0.8631, -1.0000,  1.0000, -0.7902, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5965,  0.0589,  0.7250,  0.6712,  0.7918,  0.7152,  0.5585,  0.9532,\n",
      "         -0.8754,  0.7846, -0.6021, -0.2216],\n",
      "        [-0.9376, -1.0000,  1.0000, -0.8336, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6009,  0.0534,  0.7154,  0.6759,  0.7930,  0.7149,  0.5618,  0.9533,\n",
      "         -0.8752,  0.7852, -0.6004, -0.2241],\n",
      "        [-0.9918, -1.0000,  1.0000, -0.7738, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6079,  0.0590,  0.7221,  0.6598,  0.7916,  0.7140,  0.5577,  0.9529,\n",
      "         -0.8750,  0.7859, -0.6021, -0.2236],\n",
      "        [-0.9324, -1.0000,  1.0000, -0.8054, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6019,  0.0490,  0.7242,  0.6739,  0.7940,  0.7152,  0.5615,  0.9533,\n",
      "         -0.8758,  0.7848, -0.6005, -0.2245],\n",
      "        [-0.9729, -1.0000,  1.0000, -0.8740, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6004,  0.0527,  0.7156,  0.6718,  0.7918,  0.7144,  0.5609,  0.9533,\n",
      "         -0.8754,  0.7845, -0.6022, -0.2225],\n",
      "        [-0.9392, -1.0000,  1.0000, -0.7578, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6012,  0.0588,  0.7272,  0.6672,  0.7925,  0.7125,  0.5599,  0.9530,\n",
      "         -0.8754,  0.7839, -0.6021, -0.2222],\n",
      "        [-0.9753, -1.0000,  1.0000, -0.8987, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6006,  0.0513,  0.7112,  0.6751,  0.7920,  0.7149,  0.5619,  0.9533,\n",
      "         -0.8752,  0.7849, -0.6016, -0.2230],\n",
      "        [-0.9694, -1.0000,  1.0000, -0.8849, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6046,  0.0526,  0.7158,  0.6742,  0.7929,  0.7148,  0.5624,  0.9533,\n",
      "         -0.8754,  0.7853, -0.6007, -0.2234],\n",
      "        [-0.9733, -1.0000,  1.0000, -0.8345, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6086,  0.0414,  0.7199,  0.6723,  0.7945,  0.7157,  0.5638,  0.9532,\n",
      "         -0.8756,  0.7850, -0.5993, -0.2237],\n",
      "        [-0.9559, -1.0000,  1.0000, -0.8139, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6064,  0.0446,  0.7236,  0.6764,  0.7946,  0.7156,  0.5635,  0.9533,\n",
      "         -0.8757,  0.7853, -0.5992, -0.2243],\n",
      "        [-0.9895, -1.0000,  1.0000, -0.8400, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6053,  0.0515,  0.7152,  0.6766,  0.7923,  0.7138,  0.5629,  0.9533,\n",
      "         -0.8753,  0.7853, -0.6006, -0.2246],\n",
      "        [-0.9850, -1.0000,  1.0000, -0.8246, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6057,  0.0509,  0.7189,  0.6756,  0.7923,  0.7139,  0.5636,  0.9530,\n",
      "         -0.8761,  0.7846, -0.6011, -0.2232],\n",
      "        [-0.9141, -1.0000,  1.0000, -0.8038, -1.0000, -1.0000,  0.9986, -1.0000,\n",
      "          0.5877,  0.0757,  0.7221,  0.6766,  0.7851,  0.7114,  0.5568,  0.9535,\n",
      "         -0.8753,  0.7852, -0.6084, -0.2252],\n",
      "        [-1.0000, -1.0000,  1.0000, -0.7906, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6010,  0.0500,  0.7189,  0.6741,  0.7931,  0.7138,  0.5617,  0.9541,\n",
      "         -0.8750,  0.7851, -0.6002, -0.2256],\n",
      "        [-0.9512, -1.0000,  1.0000, -0.7711, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5806,  0.0660,  0.7224,  0.6653,  0.7907,  0.7124,  0.5555,  0.9528,\n",
      "         -0.8753,  0.7823, -0.6020, -0.2221],\n",
      "        [-0.9773, -1.0000,  1.0000, -0.6992, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5976,  0.0353,  0.7326,  0.6754,  0.7977,  0.7173,  0.5616,  0.9533,\n",
      "         -0.8767,  0.7812, -0.5994, -0.2206],\n",
      "        [-0.8841, -1.0000,  1.0000, -0.7073, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5803,  0.0804,  0.7310,  0.6690,  0.7865,  0.7111,  0.5568,  0.9522,\n",
      "         -0.8763,  0.7848, -0.6070, -0.2240],\n",
      "        [-0.9066, -1.0000,  1.0000, -0.8235, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5815,  0.0613,  0.7235,  0.6754,  0.7908,  0.7140,  0.5575,  0.9535,\n",
      "         -0.8758,  0.7806, -0.6078, -0.2208],\n",
      "        [-0.9674, -1.0000,  1.0000, -0.7686, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6023,  0.0395,  0.7230,  0.6756,  0.7967,  0.7166,  0.5635,  0.9533,\n",
      "         -0.8754,  0.7849, -0.5974, -0.2249],\n",
      "        [-1.0000, -1.0000,  1.0000, -0.8173, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6059,  0.0477,  0.7172,  0.6753,  0.7931,  0.7147,  0.5630,  0.9534,\n",
      "         -0.8753,  0.7853, -0.6001, -0.2245],\n",
      "        [-0.9537, -1.0000,  1.0000, -0.8257, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5943,  0.0285,  0.7231,  0.6745,  0.7992,  0.7157,  0.5622,  0.9538,\n",
      "         -0.8760,  0.7806, -0.5997, -0.2230],\n",
      "        [-0.9737, -1.0000,  1.0000, -0.7748, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.6039,  0.0499,  0.7228,  0.6780,  0.7933,  0.7130,  0.5619,  0.9543,\n",
      "         -0.8753,  0.7851, -0.6001, -0.2259],\n",
      "        [-0.9677, -1.0000,  1.0000, -0.7541, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5983,  0.0546,  0.7248,  0.6760,  0.7928,  0.7140,  0.5608,  0.9534,\n",
      "         -0.8756,  0.7852, -0.6007, -0.2250],\n",
      "        [-0.9449, -1.0000,  1.0000, -0.8400, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "          0.5912,  0.0640,  0.7158,  0.6795,  0.7895,  0.7091,  0.5596,  0.9541,\n",
      "         -0.8751,  0.7837, -0.6026, -0.2254]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "1\n",
      "tensor([[-7.6004e-01,  1.0000e+00, -5.3941e-02,  1.2167e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9998e-01,  1.0000e+00,  6.8931e-01, -6.0010e-01,\n",
      "          6.2882e-01, -3.5610e-03,  6.8400e-01, -2.3380e-01,  8.4522e-01,\n",
      "          7.1126e-01, -8.9890e-01,  8.0388e-01, -7.1784e-01,  6.1549e-01],\n",
      "        [-5.2351e-01,  1.0000e+00, -6.7182e-02,  2.8477e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9999e-01,  1.0000e+00,  6.2850e-01, -5.5974e-01,\n",
      "          6.1508e-01, -2.2991e-02,  6.8370e-01, -2.2596e-01,  8.4608e-01,\n",
      "          7.0229e-01, -8.9671e-01,  7.8804e-01, -6.9764e-01,  6.0886e-01],\n",
      "        [-2.9397e-01,  1.0000e+00, -2.8543e-02,  1.2000e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9998e-01,  1.0000e+00,  5.0971e-01, -4.8665e-01,\n",
      "          6.5966e-01,  3.7812e-02,  6.7772e-01, -1.9162e-01,  8.5490e-01,\n",
      "          6.9819e-01, -8.9955e-01,  7.6936e-01, -6.5779e-01,  6.0142e-01],\n",
      "        [-3.9620e-01,  1.0000e+00, -5.8512e-02,  1.2215e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9998e-01,  1.0000e+00,  5.1087e-01, -4.9978e-01,\n",
      "          6.7652e-01,  5.1374e-02,  6.7809e-01, -1.8451e-01,  8.6169e-01,\n",
      "          7.0624e-01, -9.0138e-01,  7.8450e-01, -6.7374e-01,  6.0716e-01],\n",
      "        [-2.9606e-01,  1.0000e+00, -8.7040e-02,  1.2809e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  4.8698e-01, -4.5486e-01,\n",
      "          6.8331e-01,  7.2306e-02,  6.7520e-01, -1.7345e-01,  8.5784e-01,\n",
      "          7.0088e-01, -9.0219e-01,  7.6329e-01, -6.3902e-01,  5.9577e-01],\n",
      "        [-4.4712e-01,  1.0000e+00, -1.1246e-01,  1.2019e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  6.0078e-01, -4.8815e-01,\n",
      "          6.4848e-01,  2.2428e-03,  6.8116e-01, -1.9600e-01,  8.5029e-01,\n",
      "          7.0572e-01, -9.0013e-01,  7.7411e-01, -6.6896e-01,  6.0602e-01],\n",
      "        [-5.2847e-01,  1.0000e+00, -8.0144e-02, -2.0762e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.5270e-01,  1.0000e+00,  5.5962e-01, -5.2323e-01,\n",
      "          6.8406e-01,  5.5843e-02,  6.8117e-01, -1.9760e-01,  8.5694e-01,\n",
      "          7.0352e-01, -9.0436e-01,  7.7430e-01, -6.6449e-01,  5.9954e-01],\n",
      "        [-2.6348e-01,  1.0000e+00,  8.1390e-04,  6.0000e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.4145e-01,  1.0000e+00,  6.0004e-01, -6.2866e-01,\n",
      "          5.7918e-01,  6.1046e-02,  6.7698e-01, -2.3972e-01,  8.4279e-01,\n",
      "          6.8307e-01, -8.9095e-01,  8.2811e-01, -7.1784e-01,  6.1567e-01],\n",
      "        [-6.7680e-02,  1.0000e+00, -5.0437e-02,  3.6782e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.4083e-01,  1.0000e+00,  5.3670e-01, -4.6674e-01,\n",
      "          6.2202e-01,  5.6494e-02,  6.7147e-01, -1.9982e-01,  8.5170e-01,\n",
      "          6.8838e-01, -8.9936e-01,  7.8231e-01, -6.5704e-01,  5.9941e-01],\n",
      "        [-4.3367e-01,  1.0000e+00, -8.9936e-02,  2.7977e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.5403e-01,  1.0000e+00,  5.7070e-01, -4.7158e-01,\n",
      "          6.5662e-01,  2.8846e-02,  6.7704e-01, -1.8991e-01,  8.4506e-01,\n",
      "          6.9813e-01, -8.9968e-01,  7.7186e-01, -6.5605e-01,  5.9731e-01],\n",
      "        [-6.0301e-01,  1.0000e+00, -7.2631e-02,  3.6000e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.5549e-01,  1.0000e+00,  5.6927e-01, -5.7504e-01,\n",
      "          6.4534e-01,  1.0992e-02,  6.8178e-01, -2.2210e-01,  8.4829e-01,\n",
      "          7.0010e-01, -8.9739e-01,  7.9001e-01, -6.8685e-01,  6.0153e-01],\n",
      "        [-4.3930e-01,  1.0000e+00, -8.5803e-02,  7.1208e-02, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8491e-01,  1.0000e+00,  5.5791e-01, -5.4432e-01,\n",
      "          6.3929e-01,  3.9419e-02,  6.7974e-01, -2.3477e-01,  8.5123e-01,\n",
      "          6.9970e-01, -9.0100e-01,  7.8538e-01, -6.9074e-01,  6.0372e-01],\n",
      "        [-5.9979e-01,  1.0000e+00, -6.1506e-02,  3.7745e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9203e-01,  1.0000e+00,  6.6425e-01, -5.9383e-01,\n",
      "          5.8181e-01, -8.0496e-03,  6.8162e-01, -2.5719e-01,  8.4089e-01,\n",
      "          6.9056e-01, -8.9271e-01,  7.9174e-01, -7.2459e-01,  6.1102e-01],\n",
      "        [-4.4423e-01,  1.0000e+00, -4.7259e-02,  2.8673e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8531e-01,  1.0000e+00,  5.8550e-01, -5.8249e-01,\n",
      "          6.1849e-01,  4.4572e-02,  6.8070e-01, -2.3022e-01,  8.4594e-01,\n",
      "          6.9139e-01, -8.9603e-01,  7.9950e-01, -6.9791e-01,  6.0351e-01],\n",
      "        [-7.5322e-01,  1.0000e+00, -7.3768e-02,  2.1194e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8778e-01,  1.0000e+00,  6.3902e-01, -5.5622e-01,\n",
      "          6.3523e-01,  8.4427e-03,  6.8582e-01, -2.1038e-01,  8.3593e-01,\n",
      "          6.9710e-01, -8.9619e-01,  7.9240e-01, -6.8889e-01,  6.0078e-01],\n",
      "        [-4.9345e-01,  1.0000e+00,  6.5766e-03,  5.1921e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8768e-01,  1.0000e+00,  5.8698e-01, -5.2698e-01,\n",
      "          6.0503e-01,  2.9506e-03,  6.8361e-01, -2.1062e-01,  8.4060e-01,\n",
      "          6.8893e-01, -8.9588e-01,  7.8154e-01, -6.7393e-01,  5.9950e-01],\n",
      "        [-6.6881e-01,  1.0000e+00, -3.1412e-02,  4.4024e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9966e-01,  1.0000e+00,  6.1310e-01, -5.4831e-01,\n",
      "          6.2645e-01, -4.7085e-02,  6.8572e-01, -2.1408e-01,  8.4949e-01,\n",
      "          6.9958e-01, -8.9808e-01,  7.8380e-01, -7.1372e-01,  6.0635e-01],\n",
      "        [-4.1909e-01,  1.0000e+00, -5.1049e-02,  2.0179e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9965e-01,  1.0000e+00,  5.8603e-01, -6.2594e-01,\n",
      "          6.0999e-01,  1.7881e-02,  6.8255e-01, -2.6375e-01,  8.5572e-01,\n",
      "          7.0567e-01, -8.9712e-01,  8.1128e-01, -7.2798e-01,  6.2107e-01],\n",
      "        [-5.9088e-01,  1.0000e+00, -5.5411e-02,  4.0000e-02, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9903e-01,  1.0000e+00,  6.5655e-01, -4.9866e-01,\n",
      "          6.3798e-01, -5.6846e-02,  6.8560e-01, -1.9666e-01,  8.4262e-01,\n",
      "          7.1566e-01, -8.9689e-01,  7.6546e-01, -6.8881e-01,  6.1189e-01],\n",
      "        [-5.4756e-01,  1.0000e+00, -6.1967e-02,  2.1020e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9875e-01,  1.0000e+00,  6.2215e-01, -5.8058e-01,\n",
      "          6.2502e-01,  1.6103e-02,  6.8376e-01, -2.2923e-01,  8.5519e-01,\n",
      "          7.0094e-01, -9.0102e-01,  8.0436e-01, -7.0306e-01,  6.1677e-01],\n",
      "        [-5.6992e-01,  1.0000e+00, -2.3950e-02,  1.4307e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.6405e-01,  1.0000e+00,  5.6233e-01, -5.8091e-01,\n",
      "          6.3099e-01,  2.6197e-03,  6.8453e-01, -2.2936e-01,  8.5836e-01,\n",
      "          7.0488e-01, -9.0117e-01,  7.9474e-01, -6.9062e-01,  6.1103e-01],\n",
      "        [-5.3009e-01,  1.0000e+00, -3.0723e-02,  2.7771e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.5569e-01,  1.0000e+00,  5.7490e-01, -5.5057e-01,\n",
      "          6.0230e-01,  4.9114e-02,  6.7852e-01, -2.1473e-01,  8.5003e-01,\n",
      "          6.9782e-01, -8.9235e-01,  8.0483e-01, -6.7455e-01,  6.0922e-01],\n",
      "        [-6.1798e-01,  1.0000e+00, -5.1503e-02,  3.5995e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9021e-01,  1.0000e+00,  6.6402e-01, -5.6831e-01,\n",
      "          6.1688e-01, -4.9039e-02,  6.7791e-01, -2.4120e-01,  8.3587e-01,\n",
      "          7.0723e-01, -8.9237e-01,  7.8437e-01, -7.1962e-01,  6.0575e-01],\n",
      "        [-3.7844e-01,  1.0000e+00, -2.9048e-02,  2.9428e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9372e-01,  1.0000e+00,  6.1822e-01, -5.0393e-01,\n",
      "          6.4621e-01, -4.1931e-03,  6.7718e-01, -2.0337e-01,  8.5033e-01,\n",
      "          7.0935e-01, -8.9779e-01,  7.8667e-01, -6.9938e-01,  6.1248e-01],\n",
      "        [-4.1601e-01,  1.0000e+00,  4.9452e-02,  1.2000e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9891e-01,  1.0000e+00,  5.9406e-01, -5.7535e-01,\n",
      "          5.8266e-01,  4.3930e-03,  6.7587e-01, -2.5639e-01,  8.5471e-01,\n",
      "          6.9942e-01, -8.9558e-01,  8.0197e-01, -7.1057e-01,  6.1511e-01],\n",
      "        [-6.7404e-01,  1.0000e+00,  4.7630e-02,  3.9309e-02, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8595e-01,  1.0000e+00,  5.8779e-01, -6.3760e-01,\n",
      "          5.9105e-01,  3.1082e-02,  6.8193e-01, -2.6287e-01,  8.5132e-01,\n",
      "          7.0196e-01, -8.9649e-01,  8.0761e-01, -7.0490e-01,  6.0651e-01],\n",
      "        [-4.4523e-01,  1.0000e+00, -1.1603e-02,  2.8132e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9993e-01,  1.0000e+00,  6.2176e-01, -5.7226e-01,\n",
      "          6.1429e-01,  2.8279e-02,  6.8193e-01, -2.1611e-01,  8.4482e-01,\n",
      "          6.9787e-01, -8.9749e-01,  8.0521e-01, -6.9726e-01,  6.1018e-01],\n",
      "        [-6.5224e-01,  1.0000e+00,  4.0281e-02,  4.3995e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9975e-01,  1.0000e+00,  6.6267e-01, -5.1847e-01,\n",
      "          6.0498e-01, -3.2852e-02,  6.7972e-01, -2.0797e-01,  8.3537e-01,\n",
      "          6.9748e-01, -8.9450e-01,  7.9390e-01, -7.0511e-01,  6.0661e-01],\n",
      "        [-5.1558e-01,  1.0000e+00, -5.0434e-02,  2.1661e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8835e-01,  1.0000e+00,  5.7560e-01, -5.6287e-01,\n",
      "          6.7171e-01,  2.1279e-02,  6.8625e-01, -2.0386e-01,  8.5600e-01,\n",
      "          7.0326e-01, -9.0228e-01,  7.8934e-01, -6.8833e-01,  6.1152e-01],\n",
      "        [-6.4174e-01,  1.0000e+00, -7.9828e-02,  2.8032e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9974e-01,  1.0000e+00,  6.6740e-01, -6.2698e-01,\n",
      "          5.9974e-01,  2.2514e-02,  6.8551e-01, -2.3667e-01,  8.3939e-01,\n",
      "          6.9754e-01, -8.9532e-01,  8.1423e-01, -7.1877e-01,  6.1125e-01],\n",
      "        [-5.6957e-01,  1.0000e+00, -6.9399e-02,  2.8000e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9969e-01,  1.0000e+00,  6.4837e-01, -5.3300e-01,\n",
      "          6.1199e-01,  8.0501e-03,  6.8219e-01, -2.2560e-01,  8.4175e-01,\n",
      "          6.9821e-01, -9.0058e-01,  7.8713e-01, -6.8998e-01,  6.0448e-01],\n",
      "        [-5.1998e-01,  1.0000e+00, -6.5907e-02,  3.9899e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  6.4840e-01, -4.8928e-01,\n",
      "          6.2930e-01, -1.5987e-02,  6.7582e-01, -2.0421e-01,  8.3871e-01,\n",
      "          7.0149e-01, -8.9789e-01,  7.7371e-01, -6.8137e-01,  6.0885e-01]])\n",
      "tensor([[-7.6004e-01,  1.0000e+00, -5.3941e-02,  1.2167e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9998e-01,  1.0000e+00,  6.8931e-01, -6.0010e-01,\n",
      "          6.2882e-01, -3.5610e-03,  6.8400e-01, -2.3380e-01,  8.4522e-01,\n",
      "          7.1126e-01, -8.9890e-01,  8.0388e-01, -7.1784e-01,  6.1549e-01],\n",
      "        [-5.2351e-01,  1.0000e+00, -6.7182e-02,  2.8477e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9999e-01,  1.0000e+00,  6.2850e-01, -5.5974e-01,\n",
      "          6.1508e-01, -2.2991e-02,  6.8370e-01, -2.2596e-01,  8.4608e-01,\n",
      "          7.0229e-01, -8.9671e-01,  7.8804e-01, -6.9764e-01,  6.0886e-01],\n",
      "        [-2.9397e-01,  1.0000e+00, -2.8543e-02,  1.2000e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9998e-01,  1.0000e+00,  5.0971e-01, -4.8665e-01,\n",
      "          6.5966e-01,  3.7812e-02,  6.7772e-01, -1.9162e-01,  8.5490e-01,\n",
      "          6.9819e-01, -8.9955e-01,  7.6936e-01, -6.5779e-01,  6.0142e-01],\n",
      "        [-3.9620e-01,  1.0000e+00, -5.8512e-02,  1.2215e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9998e-01,  1.0000e+00,  5.1087e-01, -4.9978e-01,\n",
      "          6.7652e-01,  5.1374e-02,  6.7809e-01, -1.8451e-01,  8.6169e-01,\n",
      "          7.0624e-01, -9.0138e-01,  7.8450e-01, -6.7374e-01,  6.0716e-01],\n",
      "        [-2.9606e-01,  1.0000e+00, -8.7040e-02,  1.2809e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  4.8698e-01, -4.5486e-01,\n",
      "          6.8331e-01,  7.2306e-02,  6.7520e-01, -1.7345e-01,  8.5784e-01,\n",
      "          7.0088e-01, -9.0219e-01,  7.6329e-01, -6.3902e-01,  5.9577e-01],\n",
      "        [-4.4712e-01,  1.0000e+00, -1.1246e-01,  1.2019e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  6.0078e-01, -4.8815e-01,\n",
      "          6.4848e-01,  2.2428e-03,  6.8116e-01, -1.9600e-01,  8.5029e-01,\n",
      "          7.0572e-01, -9.0013e-01,  7.7411e-01, -6.6896e-01,  6.0602e-01],\n",
      "        [-5.2847e-01,  1.0000e+00, -8.0144e-02, -2.0762e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.5270e-01,  1.0000e+00,  5.5962e-01, -5.2323e-01,\n",
      "          6.8406e-01,  5.5843e-02,  6.8117e-01, -1.9760e-01,  8.5694e-01,\n",
      "          7.0352e-01, -9.0436e-01,  7.7430e-01, -6.6449e-01,  5.9954e-01],\n",
      "        [-2.6348e-01,  1.0000e+00,  8.1390e-04,  6.0000e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.4145e-01,  1.0000e+00,  6.0004e-01, -6.2866e-01,\n",
      "          5.7918e-01,  6.1046e-02,  6.7698e-01, -2.3972e-01,  8.4279e-01,\n",
      "          6.8307e-01, -8.9095e-01,  8.2811e-01, -7.1784e-01,  6.1567e-01],\n",
      "        [-6.7680e-02,  1.0000e+00, -5.0437e-02,  3.6782e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.4083e-01,  1.0000e+00,  5.3670e-01, -4.6674e-01,\n",
      "          6.2202e-01,  5.6494e-02,  6.7147e-01, -1.9982e-01,  8.5170e-01,\n",
      "          6.8838e-01, -8.9936e-01,  7.8231e-01, -6.5704e-01,  5.9941e-01],\n",
      "        [-4.3367e-01,  1.0000e+00, -8.9936e-02,  2.7977e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.5403e-01,  1.0000e+00,  5.7070e-01, -4.7158e-01,\n",
      "          6.5662e-01,  2.8846e-02,  6.7704e-01, -1.8991e-01,  8.4506e-01,\n",
      "          6.9813e-01, -8.9968e-01,  7.7186e-01, -6.5605e-01,  5.9731e-01],\n",
      "        [-6.0301e-01,  1.0000e+00, -7.2631e-02,  3.6000e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.5549e-01,  1.0000e+00,  5.6927e-01, -5.7504e-01,\n",
      "          6.4534e-01,  1.0992e-02,  6.8178e-01, -2.2210e-01,  8.4829e-01,\n",
      "          7.0010e-01, -8.9739e-01,  7.9001e-01, -6.8685e-01,  6.0153e-01],\n",
      "        [-4.3930e-01,  1.0000e+00, -8.5803e-02,  7.1208e-02, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8491e-01,  1.0000e+00,  5.5791e-01, -5.4432e-01,\n",
      "          6.3929e-01,  3.9419e-02,  6.7974e-01, -2.3477e-01,  8.5123e-01,\n",
      "          6.9970e-01, -9.0100e-01,  7.8538e-01, -6.9074e-01,  6.0372e-01],\n",
      "        [-5.9979e-01,  1.0000e+00, -6.1506e-02,  3.7745e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9203e-01,  1.0000e+00,  6.6425e-01, -5.9383e-01,\n",
      "          5.8181e-01, -8.0496e-03,  6.8162e-01, -2.5719e-01,  8.4089e-01,\n",
      "          6.9056e-01, -8.9271e-01,  7.9174e-01, -7.2459e-01,  6.1102e-01],\n",
      "        [-4.4423e-01,  1.0000e+00, -4.7259e-02,  2.8673e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8531e-01,  1.0000e+00,  5.8550e-01, -5.8249e-01,\n",
      "          6.1849e-01,  4.4572e-02,  6.8070e-01, -2.3022e-01,  8.4594e-01,\n",
      "          6.9139e-01, -8.9603e-01,  7.9950e-01, -6.9791e-01,  6.0351e-01],\n",
      "        [-7.5322e-01,  1.0000e+00, -7.3768e-02,  2.1194e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8778e-01,  1.0000e+00,  6.3902e-01, -5.5622e-01,\n",
      "          6.3523e-01,  8.4427e-03,  6.8582e-01, -2.1038e-01,  8.3593e-01,\n",
      "          6.9710e-01, -8.9619e-01,  7.9240e-01, -6.8889e-01,  6.0078e-01],\n",
      "        [-4.9345e-01,  1.0000e+00,  6.5766e-03,  5.1921e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8768e-01,  1.0000e+00,  5.8698e-01, -5.2698e-01,\n",
      "          6.0503e-01,  2.9506e-03,  6.8361e-01, -2.1062e-01,  8.4060e-01,\n",
      "          6.8893e-01, -8.9588e-01,  7.8154e-01, -6.7393e-01,  5.9950e-01],\n",
      "        [-6.6881e-01,  1.0000e+00, -3.1412e-02,  4.4024e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9966e-01,  1.0000e+00,  6.1310e-01, -5.4831e-01,\n",
      "          6.2645e-01, -4.7085e-02,  6.8572e-01, -2.1408e-01,  8.4949e-01,\n",
      "          6.9958e-01, -8.9808e-01,  7.8380e-01, -7.1372e-01,  6.0635e-01],\n",
      "        [-4.1909e-01,  1.0000e+00, -5.1049e-02,  2.0179e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9965e-01,  1.0000e+00,  5.8603e-01, -6.2594e-01,\n",
      "          6.0999e-01,  1.7881e-02,  6.8255e-01, -2.6375e-01,  8.5572e-01,\n",
      "          7.0567e-01, -8.9712e-01,  8.1128e-01, -7.2798e-01,  6.2107e-01],\n",
      "        [-5.9088e-01,  1.0000e+00, -5.5411e-02,  4.0000e-02, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9903e-01,  1.0000e+00,  6.5655e-01, -4.9866e-01,\n",
      "          6.3798e-01, -5.6846e-02,  6.8560e-01, -1.9666e-01,  8.4262e-01,\n",
      "          7.1566e-01, -8.9689e-01,  7.6546e-01, -6.8881e-01,  6.1189e-01],\n",
      "        [-5.4756e-01,  1.0000e+00, -6.1967e-02,  2.1020e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9875e-01,  1.0000e+00,  6.2215e-01, -5.8058e-01,\n",
      "          6.2502e-01,  1.6103e-02,  6.8376e-01, -2.2923e-01,  8.5519e-01,\n",
      "          7.0094e-01, -9.0102e-01,  8.0436e-01, -7.0306e-01,  6.1677e-01],\n",
      "        [-5.6992e-01,  1.0000e+00, -2.3950e-02,  1.4307e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.6405e-01,  1.0000e+00,  5.6233e-01, -5.8091e-01,\n",
      "          6.3099e-01,  2.6197e-03,  6.8453e-01, -2.2936e-01,  8.5836e-01,\n",
      "          7.0488e-01, -9.0117e-01,  7.9474e-01, -6.9062e-01,  6.1103e-01],\n",
      "        [-5.3009e-01,  1.0000e+00, -3.0723e-02,  2.7771e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.5569e-01,  1.0000e+00,  5.7490e-01, -5.5057e-01,\n",
      "          6.0230e-01,  4.9114e-02,  6.7852e-01, -2.1473e-01,  8.5003e-01,\n",
      "          6.9782e-01, -8.9235e-01,  8.0483e-01, -6.7455e-01,  6.0922e-01],\n",
      "        [-6.1798e-01,  1.0000e+00, -5.1503e-02,  3.5995e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9021e-01,  1.0000e+00,  6.6402e-01, -5.6831e-01,\n",
      "          6.1688e-01, -4.9039e-02,  6.7791e-01, -2.4120e-01,  8.3587e-01,\n",
      "          7.0723e-01, -8.9237e-01,  7.8437e-01, -7.1962e-01,  6.0575e-01],\n",
      "        [-3.7844e-01,  1.0000e+00, -2.9048e-02,  2.9428e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9372e-01,  1.0000e+00,  6.1822e-01, -5.0393e-01,\n",
      "          6.4621e-01, -4.1931e-03,  6.7718e-01, -2.0337e-01,  8.5033e-01,\n",
      "          7.0935e-01, -8.9779e-01,  7.8667e-01, -6.9938e-01,  6.1248e-01],\n",
      "        [-4.1601e-01,  1.0000e+00,  4.9452e-02,  1.2000e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9891e-01,  1.0000e+00,  5.9406e-01, -5.7535e-01,\n",
      "          5.8266e-01,  4.3930e-03,  6.7587e-01, -2.5639e-01,  8.5471e-01,\n",
      "          6.9942e-01, -8.9558e-01,  8.0197e-01, -7.1057e-01,  6.1511e-01],\n",
      "        [-6.7404e-01,  1.0000e+00,  4.7630e-02,  3.9309e-02, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8595e-01,  1.0000e+00,  5.8779e-01, -6.3760e-01,\n",
      "          5.9105e-01,  3.1082e-02,  6.8193e-01, -2.6287e-01,  8.5132e-01,\n",
      "          7.0196e-01, -8.9649e-01,  8.0761e-01, -7.0490e-01,  6.0651e-01],\n",
      "        [-4.4523e-01,  1.0000e+00, -1.1603e-02,  2.8132e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9993e-01,  1.0000e+00,  6.2176e-01, -5.7226e-01,\n",
      "          6.1429e-01,  2.8279e-02,  6.8193e-01, -2.1611e-01,  8.4482e-01,\n",
      "          6.9787e-01, -8.9749e-01,  8.0521e-01, -6.9726e-01,  6.1018e-01],\n",
      "        [-6.5224e-01,  1.0000e+00,  4.0281e-02,  4.3995e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9975e-01,  1.0000e+00,  6.6267e-01, -5.1847e-01,\n",
      "          6.0498e-01, -3.2852e-02,  6.7972e-01, -2.0797e-01,  8.3537e-01,\n",
      "          6.9748e-01, -8.9450e-01,  7.9390e-01, -7.0511e-01,  6.0661e-01],\n",
      "        [-5.1558e-01,  1.0000e+00, -5.0434e-02,  2.1661e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.8835e-01,  1.0000e+00,  5.7560e-01, -5.6287e-01,\n",
      "          6.7171e-01,  2.1279e-02,  6.8625e-01, -2.0386e-01,  8.5600e-01,\n",
      "          7.0326e-01, -9.0228e-01,  7.8934e-01, -6.8833e-01,  6.1152e-01],\n",
      "        [-6.4174e-01,  1.0000e+00, -7.9828e-02,  2.8032e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9974e-01,  1.0000e+00,  6.6740e-01, -6.2698e-01,\n",
      "          5.9974e-01,  2.2514e-02,  6.8551e-01, -2.3667e-01,  8.3939e-01,\n",
      "          6.9754e-01, -8.9532e-01,  8.1423e-01, -7.1877e-01,  6.1125e-01],\n",
      "        [-5.6957e-01,  1.0000e+00, -6.9399e-02,  2.8000e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  9.9969e-01,  1.0000e+00,  6.4837e-01, -5.3300e-01,\n",
      "          6.1199e-01,  8.0501e-03,  6.8219e-01, -2.2560e-01,  8.4175e-01,\n",
      "          6.9821e-01, -9.0058e-01,  7.8713e-01, -6.8998e-01,  6.0448e-01],\n",
      "        [-5.1998e-01,  1.0000e+00, -6.5907e-02,  3.9899e-01, -1.0000e+00,\n",
      "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  6.4840e-01, -4.8928e-01,\n",
      "          6.2930e-01, -1.5987e-02,  6.7582e-01, -2.0421e-01,  8.3871e-01,\n",
      "          7.0149e-01, -8.9789e-01,  7.7371e-01, -6.8137e-01,  6.0885e-01]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "2\n",
      "tensor([[ 0.9998, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8165,  1.0000,\n",
      "         -0.5224, -0.6635,  0.5631,  0.0698, -0.3002, -0.2192, -0.3005, -0.0874,\n",
      "          0.0350, -0.1713,  0.1992,  0.2042],\n",
      "        [ 0.9823, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8013,  1.0000,\n",
      "         -0.5255, -0.6612,  0.5666,  0.0706, -0.2999, -0.2192, -0.3017, -0.0870,\n",
      "          0.0349, -0.1721,  0.1986,  0.2045],\n",
      "        [ 0.9947, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8228,  1.0000,\n",
      "         -0.5247, -0.6648,  0.5629,  0.0686, -0.3008, -0.2205, -0.3013, -0.0870,\n",
      "          0.0359, -0.1716,  0.1993,  0.2034],\n",
      "        [ 0.9999, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8413,  1.0000,\n",
      "         -0.5223, -0.6638,  0.5615,  0.0685, -0.3002, -0.2196, -0.2999, -0.0876,\n",
      "          0.0354, -0.1711,  0.1991,  0.2038],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8388,  1.0000,\n",
      "         -0.5222, -0.6638,  0.5615,  0.0682, -0.3004, -0.2199, -0.3001, -0.0879,\n",
      "          0.0358, -0.1711,  0.1994,  0.2036],\n",
      "        [ 0.9986, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8826,  1.0000,\n",
      "         -0.5202, -0.6621,  0.5586,  0.0667, -0.3004, -0.2186, -0.2992, -0.0877,\n",
      "          0.0353, -0.1698,  0.1985,  0.2038],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8442,  1.0000,\n",
      "         -0.5227, -0.6636,  0.5620,  0.0696, -0.2999, -0.2195, -0.2999, -0.0870,\n",
      "          0.0349, -0.1710,  0.1985,  0.2041],\n",
      "        [ 0.9982, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8279,  1.0000,\n",
      "         -0.5229, -0.6624,  0.5636,  0.0701, -0.2995, -0.2190, -0.3005, -0.0869,\n",
      "          0.0345, -0.1711,  0.1983,  0.2046],\n",
      "        [ 0.9954, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7897,  1.0000,\n",
      "         -0.5254, -0.6652,  0.5643,  0.0697, -0.3011, -0.2207, -0.3017, -0.0871,\n",
      "          0.0361, -0.1722,  0.2001,  0.2034],\n",
      "        [ 0.9592, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8335,  1.0000,\n",
      "         -0.5249, -0.6588,  0.5669,  0.0686, -0.3015, -0.2188, -0.3028, -0.0872,\n",
      "          0.0358, -0.1717,  0.1984,  0.2034],\n",
      "        [ 0.9994, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7848,  1.0000,\n",
      "         -0.5239, -0.6642,  0.5661,  0.0729, -0.2993, -0.2192, -0.3013, -0.0863,\n",
      "          0.0335, -0.1718,  0.1989,  0.2051],\n",
      "        [ 0.9992, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7962,  1.0000,\n",
      "         -0.5241, -0.6645,  0.5654,  0.0708, -0.2999, -0.2199, -0.3011, -0.0871,\n",
      "          0.0351, -0.1720,  0.1994,  0.2043],\n",
      "        [ 0.9993, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8254,  1.0000,\n",
      "         -0.5234, -0.6645,  0.5636,  0.0697, -0.3002, -0.2201, -0.3006, -0.0873,\n",
      "          0.0355, -0.1717,  0.1992,  0.2039],\n",
      "        [ 0.9998, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8273,  1.0000,\n",
      "         -0.5230, -0.6643,  0.5633,  0.0696, -0.3001, -0.2198, -0.3006, -0.0871,\n",
      "          0.0354, -0.1713,  0.1991,  0.2039],\n",
      "        [ 0.9998, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7936,  1.0000,\n",
      "         -0.5238, -0.6648,  0.5657,  0.0707, -0.3004, -0.2201, -0.3014, -0.0872,\n",
      "          0.0352, -0.1721,  0.1997,  0.2041],\n",
      "        [ 0.9741, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8422,  1.0000,\n",
      "         -0.5240, -0.6589,  0.5653,  0.0707, -0.2998, -0.2179, -0.3010, -0.0864,\n",
      "          0.0340, -0.1712,  0.1971,  0.2046],\n",
      "        [ 0.9622, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8890,  1.0000,\n",
      "         -0.5237, -0.6551,  0.5635,  0.0674, -0.3000, -0.2176, -0.3005, -0.0874,\n",
      "          0.0361, -0.1709,  0.1961,  0.2035],\n",
      "        [ 0.9991, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8744,  1.0000,\n",
      "         -0.5209, -0.6635,  0.5605,  0.0662, -0.3007, -0.2197, -0.2996, -0.0884,\n",
      "          0.0367, -0.1705,  0.1996,  0.2031],\n",
      "        [ 0.9886, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8473,  1.0000,\n",
      "         -0.5232, -0.6615,  0.5641,  0.0693, -0.2999, -0.2190, -0.3007, -0.0870,\n",
      "          0.0350, -0.1711,  0.1981,  0.2041],\n",
      "        [ 0.9999, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8584,  1.0000,\n",
      "         -0.5218, -0.6637,  0.5614,  0.0675, -0.3005, -0.2198, -0.3000, -0.0878,\n",
      "          0.0361, -0.1708,  0.1991,  0.2034],\n",
      "        [ 0.9982, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8004,  1.0000,\n",
      "         -0.5235, -0.6647,  0.5679,  0.0693, -0.3007, -0.2206, -0.3029, -0.0875,\n",
      "          0.0348, -0.1718,  0.1999,  0.2042],\n",
      "        [ 0.9998, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7989,  1.0000,\n",
      "         -0.5240, -0.6634,  0.5664,  0.0714, -0.2995, -0.2197, -0.3014, -0.0867,\n",
      "          0.0349, -0.1718,  0.1991,  0.2045],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7632,  1.0000,\n",
      "         -0.5254, -0.6653,  0.5675,  0.0716, -0.3001, -0.2206, -0.3019, -0.0872,\n",
      "          0.0353, -0.1728,  0.2001,  0.2042],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8166,  1.0000,\n",
      "         -0.5223, -0.6652,  0.5639,  0.0675, -0.3012, -0.2205, -0.3012, -0.0884,\n",
      "          0.0365, -0.1717,  0.2005,  0.2032],\n",
      "        [ 0.9957, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7950,  1.0000,\n",
      "         -0.5245, -0.6647,  0.5660,  0.0701, -0.3008, -0.2204, -0.3018, -0.0875,\n",
      "          0.0355, -0.1723,  0.2000,  0.2038],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7598,  1.0000,\n",
      "         -0.5252, -0.6649,  0.5674,  0.0721, -0.2999, -0.2204, -0.3021, -0.0869,\n",
      "          0.0348, -0.1727,  0.1998,  0.2046],\n",
      "        [ 0.9602, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8474,  1.0000,\n",
      "         -0.5245, -0.6544,  0.5667,  0.0696, -0.2996, -0.2172, -0.3017, -0.0869,\n",
      "          0.0351, -0.1715,  0.1961,  0.2043],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8243,  1.0000,\n",
      "         -0.5233, -0.6632,  0.5636,  0.0694, -0.2998, -0.2198, -0.3004, -0.0876,\n",
      "          0.0359, -0.1716,  0.1994,  0.2040],\n",
      "        [ 0.9998, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8223,  1.0000,\n",
      "         -0.5237, -0.6648,  0.5636,  0.0690, -0.3005, -0.2206, -0.3007, -0.0876,\n",
      "          0.0360, -0.1719,  0.1996,  0.2036],\n",
      "        [ 0.9990, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8292,  1.0000,\n",
      "         -0.5235, -0.6634,  0.5638,  0.0702, -0.2998, -0.2197, -0.3005, -0.0870,\n",
      "          0.0350, -0.1714,  0.1986,  0.2042],\n",
      "        [ 0.9891, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8094,  1.0000,\n",
      "         -0.5255, -0.6629,  0.5663,  0.0715, -0.2997, -0.2197, -0.3015, -0.0863,\n",
      "          0.0344, -0.1719,  0.1983,  0.2044],\n",
      "        [ 0.9996, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.9016,  1.0000,\n",
      "         -0.5196, -0.6629,  0.5582,  0.0644, -0.3012, -0.2196, -0.2993, -0.0887,\n",
      "          0.0373, -0.1700,  0.1993,  0.2026]])\n",
      "tensor([[ 0.9998, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8165,  1.0000,\n",
      "         -0.5224, -0.6635,  0.5631,  0.0698, -0.3002, -0.2192, -0.3005, -0.0874,\n",
      "          0.0350, -0.1713,  0.1992,  0.2042],\n",
      "        [ 0.9823, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8013,  1.0000,\n",
      "         -0.5255, -0.6612,  0.5666,  0.0706, -0.2999, -0.2192, -0.3017, -0.0870,\n",
      "          0.0349, -0.1721,  0.1986,  0.2045],\n",
      "        [ 0.9947, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8228,  1.0000,\n",
      "         -0.5247, -0.6648,  0.5629,  0.0686, -0.3008, -0.2205, -0.3013, -0.0870,\n",
      "          0.0359, -0.1716,  0.1993,  0.2034],\n",
      "        [ 0.9999, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8413,  1.0000,\n",
      "         -0.5223, -0.6638,  0.5615,  0.0685, -0.3002, -0.2196, -0.2999, -0.0876,\n",
      "          0.0354, -0.1711,  0.1991,  0.2038],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8388,  1.0000,\n",
      "         -0.5222, -0.6638,  0.5615,  0.0682, -0.3004, -0.2199, -0.3001, -0.0879,\n",
      "          0.0358, -0.1711,  0.1994,  0.2036],\n",
      "        [ 0.9986, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8826,  1.0000,\n",
      "         -0.5202, -0.6621,  0.5586,  0.0667, -0.3004, -0.2186, -0.2992, -0.0877,\n",
      "          0.0353, -0.1698,  0.1985,  0.2038],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8442,  1.0000,\n",
      "         -0.5227, -0.6636,  0.5620,  0.0696, -0.2999, -0.2195, -0.2999, -0.0870,\n",
      "          0.0349, -0.1710,  0.1985,  0.2041],\n",
      "        [ 0.9982, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8279,  1.0000,\n",
      "         -0.5229, -0.6624,  0.5636,  0.0701, -0.2995, -0.2190, -0.3005, -0.0869,\n",
      "          0.0345, -0.1711,  0.1983,  0.2046],\n",
      "        [ 0.9954, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7897,  1.0000,\n",
      "         -0.5254, -0.6652,  0.5643,  0.0697, -0.3011, -0.2207, -0.3017, -0.0871,\n",
      "          0.0361, -0.1722,  0.2001,  0.2034],\n",
      "        [ 0.9592, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8335,  1.0000,\n",
      "         -0.5249, -0.6588,  0.5669,  0.0686, -0.3015, -0.2188, -0.3028, -0.0872,\n",
      "          0.0358, -0.1717,  0.1984,  0.2034],\n",
      "        [ 0.9994, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7848,  1.0000,\n",
      "         -0.5239, -0.6642,  0.5661,  0.0729, -0.2993, -0.2192, -0.3013, -0.0863,\n",
      "          0.0335, -0.1718,  0.1989,  0.2051],\n",
      "        [ 0.9992, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7962,  1.0000,\n",
      "         -0.5241, -0.6645,  0.5654,  0.0708, -0.2999, -0.2199, -0.3011, -0.0871,\n",
      "          0.0351, -0.1720,  0.1994,  0.2043],\n",
      "        [ 0.9993, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8254,  1.0000,\n",
      "         -0.5234, -0.6645,  0.5636,  0.0697, -0.3002, -0.2201, -0.3006, -0.0873,\n",
      "          0.0355, -0.1717,  0.1992,  0.2039],\n",
      "        [ 0.9998, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8273,  1.0000,\n",
      "         -0.5230, -0.6643,  0.5633,  0.0696, -0.3001, -0.2198, -0.3006, -0.0871,\n",
      "          0.0354, -0.1713,  0.1991,  0.2039],\n",
      "        [ 0.9998, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7936,  1.0000,\n",
      "         -0.5238, -0.6648,  0.5657,  0.0707, -0.3004, -0.2201, -0.3014, -0.0872,\n",
      "          0.0352, -0.1721,  0.1997,  0.2041],\n",
      "        [ 0.9741, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8422,  1.0000,\n",
      "         -0.5240, -0.6589,  0.5653,  0.0707, -0.2998, -0.2179, -0.3010, -0.0864,\n",
      "          0.0340, -0.1712,  0.1971,  0.2046],\n",
      "        [ 0.9622, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8890,  1.0000,\n",
      "         -0.5237, -0.6551,  0.5635,  0.0674, -0.3000, -0.2176, -0.3005, -0.0874,\n",
      "          0.0361, -0.1709,  0.1961,  0.2035],\n",
      "        [ 0.9991, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8744,  1.0000,\n",
      "         -0.5209, -0.6635,  0.5605,  0.0662, -0.3007, -0.2197, -0.2996, -0.0884,\n",
      "          0.0367, -0.1705,  0.1996,  0.2031],\n",
      "        [ 0.9886, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8473,  1.0000,\n",
      "         -0.5232, -0.6615,  0.5641,  0.0693, -0.2999, -0.2190, -0.3007, -0.0870,\n",
      "          0.0350, -0.1711,  0.1981,  0.2041],\n",
      "        [ 0.9999, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8584,  1.0000,\n",
      "         -0.5218, -0.6637,  0.5614,  0.0675, -0.3005, -0.2198, -0.3000, -0.0878,\n",
      "          0.0361, -0.1708,  0.1991,  0.2034],\n",
      "        [ 0.9982, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8004,  1.0000,\n",
      "         -0.5235, -0.6647,  0.5679,  0.0693, -0.3007, -0.2206, -0.3029, -0.0875,\n",
      "          0.0348, -0.1718,  0.1999,  0.2042],\n",
      "        [ 0.9998, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7989,  1.0000,\n",
      "         -0.5240, -0.6634,  0.5664,  0.0714, -0.2995, -0.2197, -0.3014, -0.0867,\n",
      "          0.0349, -0.1718,  0.1991,  0.2045],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7632,  1.0000,\n",
      "         -0.5254, -0.6653,  0.5675,  0.0716, -0.3001, -0.2206, -0.3019, -0.0872,\n",
      "          0.0353, -0.1728,  0.2001,  0.2042],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8166,  1.0000,\n",
      "         -0.5223, -0.6652,  0.5639,  0.0675, -0.3012, -0.2205, -0.3012, -0.0884,\n",
      "          0.0365, -0.1717,  0.2005,  0.2032],\n",
      "        [ 0.9957, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7950,  1.0000,\n",
      "         -0.5245, -0.6647,  0.5660,  0.0701, -0.3008, -0.2204, -0.3018, -0.0875,\n",
      "          0.0355, -0.1723,  0.2000,  0.2038],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.7598,  1.0000,\n",
      "         -0.5252, -0.6649,  0.5674,  0.0721, -0.2999, -0.2204, -0.3021, -0.0869,\n",
      "          0.0348, -0.1727,  0.1998,  0.2046],\n",
      "        [ 0.9602, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8474,  1.0000,\n",
      "         -0.5245, -0.6544,  0.5667,  0.0696, -0.2996, -0.2172, -0.3017, -0.0869,\n",
      "          0.0351, -0.1715,  0.1961,  0.2043],\n",
      "        [ 1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8243,  1.0000,\n",
      "         -0.5233, -0.6632,  0.5636,  0.0694, -0.2998, -0.2198, -0.3004, -0.0876,\n",
      "          0.0359, -0.1716,  0.1994,  0.2040],\n",
      "        [ 0.9998, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8223,  1.0000,\n",
      "         -0.5237, -0.6648,  0.5636,  0.0690, -0.3005, -0.2206, -0.3007, -0.0876,\n",
      "          0.0360, -0.1719,  0.1996,  0.2036],\n",
      "        [ 0.9990, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8292,  1.0000,\n",
      "         -0.5235, -0.6634,  0.5638,  0.0702, -0.2998, -0.2197, -0.3005, -0.0870,\n",
      "          0.0350, -0.1714,  0.1986,  0.2042],\n",
      "        [ 0.9891, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.8094,  1.0000,\n",
      "         -0.5255, -0.6629,  0.5663,  0.0715, -0.2997, -0.2197, -0.3015, -0.0863,\n",
      "          0.0344, -0.1719,  0.1983,  0.2044],\n",
      "        [ 0.9996, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  0.9016,  1.0000,\n",
      "         -0.5196, -0.6629,  0.5582,  0.0644, -0.3012, -0.2196, -0.2993, -0.0887,\n",
      "          0.0373, -0.1700,  0.1993,  0.2026]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "cumModel = hiddens[0][2]\n",
    "iter = 1\n",
    "for model in hiddens[1:]:\n",
    "    if model[1] != -1:\n",
    "        if iter == 0:\n",
    "            cumModel = model[2]\n",
    "        else:\n",
    "            cumModel = cumModel + model[2]\n",
    "        iter += 1\n",
    "    else:\n",
    "        print(model[0])\n",
    "        print(cumModel/iter)\n",
    "        print(model[2])\n",
    "        print(cumModel/iter - model[2])\n",
    "        iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c81689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "list = [0,1,2]\n",
    "print(list[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3503aa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# INDIVIDUAL OBU TEST SETUP\n",
    "testOBU = OBU(\n",
    "    inputSize = 7,  # Number of features per BSM\n",
    "    units = 20, # Number of hidden cells\n",
    "    motors = 8, # Number of motor neurons\n",
    "    outputs = 20, # Number of possible labels\n",
    "    epochs = 50,\n",
    "    lr = 0.01,\n",
    "    gpu = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5f3d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 78/78 [00:04<00:00, 19.00it/s, v_num=634, trainLoss=2.520]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 78/78 [00:04<00:00, 18.91it/s, v_num=634, trainLoss=2.520]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.5195, device='mps:0', grad_fn=<NllLoss2DBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TRAIN INDIVIDUAL OBU\n",
    "testOBU.fit(testingDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053d8e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model    | Modena           | 1.6 K  | train\n",
      "1 | lossFunc | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "264       Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/Kettering/lib/python3.13/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 10 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:   9%|▉         | 7/78 [00:00<00:03, 18.12it/s, v_num=595, trainLoss=1.800] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "testOBU.fit(testingDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1c4dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([124774, 10, 20])\n",
      "0.2970971516501835\n",
      "1.0\n",
      "Model got 370700/1247740 right.\n",
      "Accuracy: 0.2970971516501835, Precision: 0.2970971516501835, Recall: 1.0, F1 Score: 0.4580954499394479\n",
      "877040, 70.29028483498165% Zeroes, 370700 Non Zero entries.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Model got 370700/1247740 right. Accuracy: 0.2970971516501835, Precision: 0.2970971516501835, Recall: 1.0, F1 Score: 0.4580954499394479'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testOBU.test(testDataIn, testDataOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382a51c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "save = OBU(testOBU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b2a6e7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12480, 10, 20])\n",
      "Model got 6232/124800 right. Accuracy of 4.993589743589744%\n",
      "69.88782051282051% Zeroes.\n"
     ]
    }
   ],
   "source": [
    "# RUN TEST ON SMALL DATASET INDIVIDUAL MODEL\n",
    "_, _, perc, _ = testOBU.test(inTest, outTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c51f439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([196990, 10, 20])\n",
      "Model got 1159988/1969900 right. Accuracy of 58.88562871211737%\n",
      "40.353165135286055% Zeroes.\n"
     ]
    }
   ],
   "source": [
    "# RUN TEST ON LARGE DATASET INDIVIDUAL MODEL\n",
    "_, _, perc, _ = testOBU.test(testDataIn, testDataOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5f9608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19700, 10, 20])\n",
      "Model got 116065/197000 right. Accuracy of 58.91624365482233%\n",
      "41.08375634517766% Zeroes.\n"
     ]
    }
   ],
   "source": [
    "# TESTING COPY\n",
    "_, _, perc, _ = save.test(inTest, outTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a959600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "print(testOBU.getHidden() - save.getHidden())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f79ef7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "print(testOBU.model.fF.weight - save.model.fF.weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kettering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
